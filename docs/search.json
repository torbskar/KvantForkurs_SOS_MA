[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Forkurs for kvantitativ metode",
    "section": "",
    "text": "Forord\nDette materialet er beregnet på et forkurs for masterstudenter i sosiologi ved universitet i Oslo som skal ta emnet SOS4020 Kvantitative metoder. Forkurset dekker de mest sentrale elementene fra BA-nivået som trengs for å ta SOS4020.\nDet anbefales å repetere materiale fra kurs i kvantitative metoder på bachelornivå. Forkurset er en oppfrisker av det aller viktigste materialet fra SOSGEO1120.\nDe som lært annen statistikksoftware enn R på bachelornivå vil ha særlig nytte av dette kurset. I tillegg til programmeringsspråket skal du lære å lage en hensiktsmessig mappestruktur og lese inn datasett i R.\nDatasettet som skal brukes i SOS4020 er tilgangsbegrenset så det er litt formaliteter som må på plass først. Det skal vi gå på plass her slik at dere har lovlig tilgang til dataene. Men gjennomgangen og eksempler i det følgende vil basere seg på det samme datasett som brukes gjennomgående i SOSGEO1120. Til hvert kapittel er det oppgaver. Først og fremst skal dere kunne gjøre de samme operasjonene på egen datamaskin. Dernest skal dere bruke NorLAG til å gjøre noe mer selvstendige analyser med de samme teknikkene.\nLæringsmålene for forkurset er som følger:\n\nBli kjent med R og Rstudio, mappestruktur og jobbe med Rstudio projects\nKunne lese inn data i vanlige formater\nHa lest inn og bli kjent med datasettet som skal brukes videre i SOS4020\nKunne lage grunnleggende grafikk med ggplot\nKunne lage deskriptive tabeller med gtsummary (og litt andre funksjoner)\nKunne lage 3-veis krysstabeller\nKunne lage grafisk fremstilling av sammenheng mellom inntil 4 variable\nKunne beskrive sammenhengen mellom variable med lineær regresjon\nKjenne grunnleggende sammenhengen mellom hvordan dataene ble til og hvordan analysene kan tolkes\nKjenne til hva en samplingfordeling er og kunne tolke standardfeil, konfidensintervall og p-verdier\nKunne gjennomføre en t-test for gjennomsnitt og for regresjonsparametre\nKunne grunnleggende datahåndtering med tidyverse for å kunne gjøre selvstendige analyser senere\nKunne eksportere alle resultater fra R til Word på en effektiv måte"
  },
  {
    "objectID": "Installering.html#installasjon",
    "href": "Installering.html#installasjon",
    "title": "1  Installere R og Rstudio",
    "section": "1.1 Installasjon",
    "text": "1.1 Installasjon\nInstaller nyeste versjon av R herfra: https://cran.uib.no/ Du trenger det som heter «base» når man installerer for første gang. Hvis du har R installert på maskinen din fra før, sørg for at du har siste versjon installert. Siste versjon er 4.1.2. Versjon etter 4.0 bør gå bra, men tidligere versjoner vil kunne gi problemer. Installer nyeste versjon av RStudio (gratisversjon) herfra: https://rstudio.com/products/rstudio/download/ Viktig: du må installere R før du installerer Rstudio for Rstudio finner R på din datamaskin og vil gi feilmelding hvis den ikke finner R. Hvis du har en eldre datamaskin og du får feilmelding ved installasjon av RStudio kan du vurdere å installere forrige versjon av Rstudio herfra: https://www.rstudio.com/products/rstudio/older-versions/\nR og Rstudio er to programmer er integrert i hverandre og du åpner heretter R ved å åpne RStudio. Merk: R er navnet på programmeringsspråket og programmet som gjør selve utregningene. Det kjører fra en kommandolinje og er ikke veldig brukervennlig alene. RStudio er et “integrated development environment” (IDE) til R. Det integrerer R med en konsoll, grafikk-vindu og en del andre nyttige ting. Det gjør det lettere å bruke R.\nDet finnes også andre IDE for R, men vi skal bruke RStudio gjennomgående på dette kurset. (RStudio inneholder også masse annen funksjonalitet vi ikke trenger til dette kurset).\n\n1.1.1 Spesielt om Windows-maskiner: installer Rtools\nHvis du jobber på en Windows-maskin må du også installere Rtools herfra: https://cran.r-project.org/bin/windows/Rtools/\n\n\n1.1.2 Spesielt om Mac-maskiner\nR skal normalt installere på Mac uten problemer. Noen har fått beskjed om at de også trenger å installere XQuartz eller Xcode. I så fall installerer du de også. Se mer informasjon her: https://cran.r-project.org/bin/macosx/tools/\n\n\n1.1.3 Spesielt om Linux-maskiner\nHar du Linux vet du antakelig hva du driver med. Siste versjon av R og Rstudio kan antakeligvis installeres fra distroens repository.\n\n\n1.1.4 Spesielt om Chromebook\nChromebook kjører et annet operativsystem og R vil ikke uten videre fungere. Derimot kan man på de fleste slike maskiner åpne opp for å kjøre Linux og da kan man installere linux-versjon av R og Rstudio. https://blog.sellorm.com/2018/12/20/installing-r-and-rstudio-on-a-chromebook/ Eller se nedenfor hvordan du kan kjøre R i skyen."
  },
  {
    "objectID": "Installering.html#oppsett-og-forberedelser",
    "href": "Installering.html#oppsett-og-forberedelser",
    "title": "1  Installere R og Rstudio",
    "section": "1.2 Oppsett og forberedelser",
    "text": "1.2 Oppsett og forberedelser\nDette oppsettet gjelder både hvis du har en lokal installasjon og for skyløsninger. Utseendet spiller ingen rolle, og R kan også fungere uten å opprette «projects» som beskrevet her. Men det er lettere å bruke og du har bedre orden hvis du gjør dette.\n\n1.2.1 Utseende i Rstudio\nEndre gjerne på oppsettet i RStudio ved å gå til Tools og deretter Global options, så Pane Layout.\n\nDet spiller ingen rolle for funksjonaliteten hvor du har hvilken fane, men her er et forslag.\n\nDette kan også endres senere og har altså bare med hvordan Rstudio ser ut."
  },
  {
    "objectID": "Installering.html#rstudio-projects",
    "href": "Installering.html#rstudio-projects",
    "title": "1  Installere R og Rstudio",
    "section": "1.3 Rstudio projects",
    "text": "1.3 Rstudio projects\nNår du åpner Rstudio skal du alltid åpne som «project» (se video med instruksjon og i R4DS). Arbeidsområdet er da definert og du kan åpne data ved å bruke relative filbaner, dvs. at du oppgir hvor dataene ligger med utgangspunkt i prosjektmappen. Se kursvideo og instruksjoner i R4DS og gjør følgende:\nOpprettet mappestruktur med SOSGEO1120 som øverste nivå og egne undermapper for data, script, og output."
  },
  {
    "objectID": "Installering.html#åpne-rstudio-og-opprett-et-.rproject",
    "href": "Installering.html#åpne-rstudio-og-opprett-et-.rproject",
    "title": "1  Installere R og Rstudio",
    "section": "1.4 Åpne RStudio og opprett et .Rproject",
    "text": "1.4 Åpne RStudio og opprett et .Rproject\n\nBruk kommandoen getwd() og se at du har riktig filbane til arbeidsområdet. Hvis du ikke er sikker på hva det betyr, må du spørre noen eller finne det ut på annen måte!\nDet første dere må gjøre er å sørge for å ha orden i datasett, script og annet på din egen datamaskin. Å f.eks. lagre alle filer på skrivebordet bør du aldri gjøre, og særlig ikke i dette kurset eller når man jobber med større prosjekter og datasett. For dette kurset skal du ha en mappestruktur med en hovedmappe for SOSGEO1120 og tilhørende undermapper. Det spiller ingen rolle hvor på datamaskinen du legger disse mappene, men du må vite hvor det er. Lag første en mappe som heter SOSGEO1120, og innunder denne mappen lager du tre andre mapper med navnene data, output og script. Du kan ha andre mapper i tillegg ved behov. Det kan se slik ut:\n\nDu skal opprette et Rstudio-prosjekt for hele kurset. Dette er beskrevet nærmere i R4DS i kapittel 6. Når du har åpnet RStudio skal du aller først klikke New Project.\n\nDeretter klikker du du «Existing Directory»\n\nKlikk «Browse» og bla deg så frem til mappen du har laget for SOSGEO1120.\nRStudio-prosjektet ligger så i den mappen du har valgt. I filutforsker på datamaskinen vil nå disse to filene dukke opp:\n\nFor å starte R videre i dette kurset skal du dobbeltklikke det første ikonet, så vil R åpne seg med riktig arbeidsområde. Mappen .Rproj.user skal du ikke røre. I RStudio vil du se at prosjektet er åpnet ved at det i øvre høyre hjørne er dette ikonet:\n\nEn stor fordel med å bruke projects er at du kan flytte hele mappen til et annet sted, eller til en annen datamaskin og alt vil fungere akkurat som før. Hvis du bruker en skytjeneste (OneDrive, Dropbox etc) vil du kunne åpne Rstudio projects på samme måte fra flere maskiner."
  },
  {
    "objectID": "innlesning_data.html#generelt-om-ulike-dataformat",
    "href": "innlesning_data.html#generelt-om-ulike-dataformat",
    "title": "2  Innlesning av data",
    "section": "2.1 Generelt om ulike dataformat",
    "text": "2.1 Generelt om ulike dataformat\n\n2.1.1 rds\nRds-formatet er et format særlig egnet for R.\n\n\n2.1.2 Laste workspace med load()\nFiler av typen .Rdat eller .Rdata er egentlig ikke et dataformat, men brukes tidvis for å lagre datafiler. Man kan lagre en eller flere datafiler i samme .Rdat fil på disk.\nDu kan også lagre et “speilbilde” av hele ditt workspace på denne måten slik at du kan lukke R og så åpne R senere akkurat på det stedet du var i arbeidet. Det kan være kjekt, men forutsetter at du husker hva du drev med forrige gang. Den klare anbefalingen er derfor å ikke bruke dette rutinemessig.\n\n\n2.1.3 csv-filer\nSåkalte csv-format er ren tekstformat der verdiene i kollonnene har skilletegn. Skilletegnet er nesten alltid komma eller semikolon, men kan i prinsippet være hva som helst. Noen ganger vil slike\n\n\n2.1.4 Excel\nForbløffende mye data foreligger i Excel-format. Det finnes egne funksjoner for å jobbe direkte med excel-filer. Blant annet pakken readxl gir funksjoner til å lese inn denne typen filer. Her er et eksempel.\n\nlibrary(readxl)\nnorlag_xlsx <- read_excel(\"data/norlag_panel.xlsx\")\nglimpse(norlag_xlsx)\n\nRows: 20,892\nColumns: 12\n$ ref_nr  <dbl> 5, 5, 10, 10, 10, 12, 12, 15, 15, 18, 18, 22, 23, 23, 25, 27, …\n$ round   <dbl> 1, 2, 3, 2, 1, 3, 1, 1, 2, 3, 2, 1, 3, 1, 1, 3, 2, 1, 2, 1, 3,…\n$ ioalder <chr> \"68\", \"72\", \"59\", \"49\", \"44\", \"61\", \"47\", \"58\", \"63\", \"67\", \"5…\n$ iolandb <chr> NA, \"Norskfødt\", NA, \"Norskfødt\", NA, NA, NA, NA, \"Norskfødt\",…\n$ iokjonn <chr> \"Mann\", \"Mann\", \"Kvinne\", \"Kvinne\", \"Kvinne\", \"Kvinne\", \"Kvinn…\n$ pa001c  <chr> \"Ja\", \"Ja\", \"Ja\", \"Ja\", \"Nei\", \"Ja\", \"Ja\", \"Nei\", \"Nei\", \"Ja\",…\n$ pa300   <chr> \"Partner gjør mest\", NA, NA, NA, NA, NA, \"IO gjør mest\", NA, N…\n$ hc230   <chr> \"En gang i uken\", \"En gang i uken\", \"2-3 ganger i måneden\", \"E…\n$ hc231   <chr> \"2-3 ganger i måneden\", \"2-3 ganger i måneden\", NA, \"2-3 gange…\n$ va207   <chr> \"Ganske viktig\", \"Litt viktig\", \"Litt viktig\", \"Ikke viktig\", …\n$ hcMCS12 <chr> \"59.7766\", \"60.68044\", \"58.74768\", \"60.69717\", \"55.86777\", \"53…\n$ hcPCS12 <chr> \"54.83583\", \"51.03453\", \"55.92348\", \"55.25834\", \"55.91285\", \"5…\n\n\nMen Excel-filer kan ha en litt mer komplisert struktur enn dette eksempelet. Data kan ligge i ulike faner i Excel-filen, men det kan da håndteres med å legge til argumentet sheet = .... Hvis excel-arket inneholder mye tekst eller andre ting som gjør at de faktiske dataene kommer litt lengre ned, så kan det spesifiseres hvilket celleområde som det skal leses inn fra ved range = ... eller bare hoppe over noen rader med skip = ....\nPå dette kurset skal vi ikke bruke Excel-filer, men det er stor sannsynlighet for at du vil få bruk for dette senere en gang.\n\n\n2.1.5 Proprietære format: Stata, SPSS og SAS\n\n2.1.5.1 Stata\n\nnorlag_dta <- read_stata(\"data/norlag_panel.dta\")\nglimpse(norlag_dta)\n\nRows: 20,892\nColumns: 12\n$ ref_nr  <dbl> 5, 5, 10, 10, 10, 12, 12, 15, 15, 18, 18, 22, 23, 23, 25, 27, …\n$ round   <dbl> 1, 2, 3, 2, 1, 3, 1, 1, 2, 3, 2, 1, 3, 1, 1, 3, 2, 1, 2, 1, 3,…\n$ ioalder <dbl+lbl> 29, 33, 20, 10,  5, 22,  8, 19, 24, 28, 18, 24, 30, 16, 32…\n$ iolandb <dbl+lbl> NA,  1, NA,  1, NA, NA, NA, NA,  1, NA,  1, NA, NA, NA, NA…\n$ iokjonn <dbl+lbl> 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2…\n$ pa001c  <dbl+lbl> 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1…\n$ pa300   <dbl+lbl>  1, NA, NA, NA, NA, NA,  2, NA, NA, NA, NA,  3, NA, NA, NA…\n$ hc230   <dbl+lbl> 3, 3, 4, 3, 3, 9, 9, 1, 1, 9, 9, 1, 9, 3, 4, 3, 3, 4, 4, 3…\n$ hc231   <dbl+lbl>  4,  4, NA,  4,  3, NA,  9,  2,  1, NA,  9,  2, NA,  4,  5…\n$ va207   <dbl+lbl> 2, 3, 3, 4, 3, 5, 5, 3, 4, 5, 5, 1, 5, 3, 3, 2, 3, 3, 4, 4…\n$ hcMCS12 <dbl+lbl> 6350, 6647, 5994, 6650, 4891, 4121, 6672, 4736, 3529, 4632…\n$ hcPCS12 <dbl+lbl> 7085, 6420, 7258, 7149, 7255, 7544, 7355, 6956, 7368, 7342…\n\n\nLegg merke til at den andre kolonnen her viser hva slags variabeltype det er. <dbl> betyr at det er numerisk variabel^(Det finnes flere typer numeriske variable som vi for praktiske analyser sjelden behøver å forholde oss til. <dbl> står for Double som er et lagringsformat som kan ta svært mange desimaler. Det kan også stå <num> som håndterer færre desimaler. Det er også vanlig med <int> som står for Integer, altså heltall uten desimaler.) På noen variable står det også <dbl+lbl> der lbl står for labelled som betyr at det finnes såkalte labler tilhørende variabelen. Labler er vanlig å bruke i programmene Stata og SPSS, men er ikke noe som vanligvis brukes i R. Men R leser det inn og kan håndtere dette helt fint. Men som hovedregel er det bedre å rydde opp slik at dataene blir slik vi vanligvis bruker det i R. Dette er grunnen til at dere får en bearbeidet versjon av NorLAG datasettet!\nNeste kapittel er spesielt om NorLAG i formatet .rds. Hvordan effektivt lese inn fra Stata til R og gjøre om labler er dekket i et appendiks. De av dere som senere skal jobbe med data levert ut fra Sikt kan ha behov for dette, og da kan dere ta en nærmere titt på appedikset. For dette forkurset og SOS4020 vil dere ikke trenge kunne akkurat det.\n\n\n2.1.5.2 SPSS og SAS\nAndre vanlige dataformater er formater fra statistikkpakkene SPSS og SAS, med filhalene henholdsvis .sav og .sas7bdat. De leses inn på tilsvarende funksjoner tilpasset disse dataformatene. Her er eksempel for innlesning av SPSS-fil:\n\nnorlag_sav <- read_spss(\"data/norlag_panel.sav\")\n\nHer er eksempel for innlesning av SAS-fil:\n\nnorlag_sas <- read_sas(\"data/norlag_panel.sas7bdat\")\n\n\n\n\n2.1.6 Dataformater for store data\nDet finnes en hel rekke andre formater for spesielle formål, derav formater for store data. Med store data mener vi her enten at de er så store at det upraktisk lang tid å lese det inn - eller så store at det ikke er plass i minnet på datamaskinen. Formatene feather og parquet er varianter av det samme og håndteres med pakken Arrow. Det finnes også andre pakker for store data, men Arrow er nå den anbefalte. En annen grunn til det er at disse datasettene tillater sømløs bytte mellom programmeringsspråkene R og Python. Men det går laaaagt utenfor formålet med dette forkurset.\nFor mer spesielle behov går det også an å koble mot databaser som MySQL, Spark, Oracle eller noe helt annet, og en oversikt finnes her.\nEneste du trenger være klar over akkurat nå er at R kan håndtere svært mange forskjellige dataformater og koble mot andre løsninger. Kanskje vil du trenge det en gang - kanskje ikke."
  },
  {
    "objectID": "innlesning_data.html#oppgaver",
    "href": "innlesning_data.html#oppgaver",
    "title": "2  Innlesning av data",
    "section": "2.2 Oppgaver",
    "text": "2.2 Oppgaver\n\nExercise 2.1 Les inn datasettet… i rds-format\n\n\nExercise 2.2 Les inn datasettet… i xlsx-format\n\n\nExercise 2.3 Noen ganger vil datamaskiner være konfigurert slik at filhalene ikke synes. Det betyr jo ikke at de ikke er der, men du ser ikke umiddelbart hva slags fil det er. Finn ut hvordan du endrer dette på din datamaskin. Prøv å skru det av og på. For å finne det ut, søk på internett med søkestrengen “how to display file extension” eller tilsvarende."
  },
  {
    "objectID": "kort_intro_R.html#objektorientert",
    "href": "kort_intro_R.html#objektorientert",
    "title": "3  En veldig kjapp intro til R",
    "section": "3.1 Objektorientert",
    "text": "3.1 Objektorientert\nI de innledende kapitlene ble det vist hvordan man leser inn data i R og dataene ble lagt i et “objekt”. R er bygd opp rundt å bruke slike objekter i den forstand at alt man jobber med (typisk: datasett) ligger i objekter.\nDu kan tenke på objekter som en boks som det står et navn på. Ofte er det bare et datasett oppi boksen, men det kan også være flere ting. Det finnes derfor flere typer objekter. Vi skal primært jobbe med datasett, og slike objekter er av typen “data.frame”. De kan også være av typen “tibble”, men det er for alle praktiske formål på dette nivået akkurat det samme som “data.frame”. Men objekter kan også inneholde resultater fra analyser, som f.eks. grafikk, tabeller eller regresjonsresultater. Man kan også legge enkelttall, vektorer og tekststrenger i objekter.\nNoen ganger vil et objekt inneholde flere forskjellige ting. Et eksempel er resultat fra regresjonsmodeller som både vil inneholde koeffisienter, standardfeil, residualer, en del statistikker, men også selve datasettet. Men for å se på output er det funksjoner som trekker ut akkurat det vi trenger, så du trenger sjelden forholde deg til hvordan et slikt objekt er bygd opp. Men du kan tenke på det som en velorganisert boks med masse mindre rom oppi.\nMen poenget er: Alt du jobber med i R er objekter. Alle objekter har et navn som du velger selv. Du kan legge hva som helst i et objekt. Du kan ikke ha to objekter med samme navn, og hvis du lager et objekt med et navn som eksisterer fra før overskriver du det gamle objektet."
  },
  {
    "objectID": "kort_intro_R.html#funksjoner",
    "href": "kort_intro_R.html#funksjoner",
    "title": "3  En veldig kjapp intro til R",
    "section": "3.2 Funksjoner",
    "text": "3.2 Funksjoner\nAlt man gjør i R gjøres med “funksjoner”, og man bruker funksjonene på objekter eller deler av objekter. Funksjonenen har et navn og etterfulgt av en parentes slik som f.eks. dinfunksjon(...). Funksjonen starter og slutter med en parentes. Du kan tenke på funksjoner som en liten maskin der du putter noe inn, og så kommer noe annet ut. Det du putter inn skal står inni parentes. Det som kommer ut kan du enten legge i et eget objekt eller la det skrives til output-vinduet.\nDet du legger inn i funksjonen - altså inni parentesn - kalles “argumenter”. Hvert argument har et navn og du skal normalt oppgi i hvert fall hvilket datasett funksjonen skal brukes på. Argumentet for data er nettopp data = og så oppgis navnet på det objektet dataene ligger i. En god del slike argumenter har navn som er standardisert på tvers av funksjoner, og data = er et eksempel på dette.\nI tillegg kan det være en rekke andre argumenter som vi kommer tilbake til i de ulike funksjonene vi bruker. Et poeng er viktig å presisere: argumentene har også en forventet rekkefølge. Man kan også oppgi argumentene uten å angi navnet hvis de kommer i riktig rekkefølge. For eksempel vil en funksjon for regresjon ha den forventede rekkefølgen: 1) Spesifisering av utfallsvariabel og forklaringsvariable på en form som heter “formula”, deretter og 2) Angitt objektnavnet til dataene. Så kan det være andre argumenter i tillegg. Man kan godt oppgi argumentene i annen rekkefølge, men da er man nødt til å bruke argumentnavnet slik at R forstår hva som er hva."
  },
  {
    "objectID": "kort_intro_R.html#r-pakker",
    "href": "kort_intro_R.html#r-pakker",
    "title": "3  En veldig kjapp intro til R",
    "section": "3.3 R-pakker",
    "text": "3.3 R-pakker\nNår man installerer R har man svært mye funksjonalitet tilgjengelig uten videre. Dette kalles “base R”, altså basic installasjon og funksjonalitet. Men R er i praksis basert på å bruke såkalte “pakker”. Dette er funksjoner som utvider R sin funksjonalitet. Så mens “base R” tilbyr infrastrukturen, så er de ulike pakkene laget for spesifikke oppgaver.\nR-pakker er et helt økosystem av funksjonalitet som dekker det aller meste du kan finne på å gjøre, fra bittesmå oppgaver, til avansert statistikk og maskinlæring, til hele systemer for dataanalyse. Det finnes mange hundre R-pakker tilgjengelig, og disse ligger på en server som heter CRAN. Hvis du vil se på hva som finnes kan du se på oversikten over tilgjengelige pakker. For nye brukere av R vil dette fremstå som ganske kaotisk. Det finnes også oversikter der viktigste pakker innenfor ulike typer analyse er gruppert slik at man lettere skal kunne finne frem. Dette kalles Task Views. Men du trenger ikke forholde deg til slike oversikter på en god stund ennå. Du får beskjed om hvilke pakker du trenger fortløpende, og det er et begrenset antall.\nFor å installere en pakke må du vite hva pakken heter og datamaskinen din må være koblet til internett. Funksjonen install.packages:\n\ninstall.packages(\"pakkenavn\")\n\nDet hender at man får en feilmelding når man prøver installere en pakke. Det er noen veldig vanlige grunner til feilmeldinger som skal være rimelig enkle å finne ut av selv:\n\nDu har stavet navnet på pakken feil. Passe på særlig små og store bokstaver.\nPakken krever at du har noen andre pakker installert fra før. I så fall vil disse pakkenes navn står i feilmeldingen. Installer disse på samme måte først og prøv igjen.\nNoen andre pakker trengs å oppdateres for at den nye pakken skal virke. Oppdater alle pakker og prøv på nytt.\nDin R installasjon må oppdateres. Hvis det er lenge siden du installerte R, så installer på nytt og prøv igjen. Da må alle andre pakker også installeres på nytt.\n\nNår du installerer pakker får du noen ganger spørsmål om du vil installere “from source”. Som hovedregel kan du velge nei. “From source” betyr at det finnes en ny versjon som ikke er ferdig kvalitetssjekket på CRAN, men som er tilgjengelig. Du trenger neppe det aller, aller siste av funksjonalitet, så “nei” holder.\nNår en pakke er installert på datamaskinen din er disse funksjonalitetene tilgjengelig i R, men ikke helt automatisk. Pakkene ligger i en egen mappe i filstrukturen på datamaskinen og R vet selvsagt hvor dette er. For at pakkene skal være tilgjengelig for deg må du fortelle R at du skal bruke en slik pakke. Vi sier at vi “laster en pakke” (engelsk: “load”) og da er disse funksjonene tilgjengelig for deg i hele R-sesjonen. Hvis du restarter R, så må du laste pakkene på nytt før du kan fortsette der du slapp.\nDu laster en pakke med funksjonen library.\n\nlibrary(pakkenavn)\n\nHvis en kode ikke fungerer og du får feilmelding kan dette være grunnen: du har glemt å laste pakken eller pakken er ikke installert på maskinen din.\nEn annen grunn til at koden ikke fungerer kan være at det er “konflikt” mellom pakker du har lastet. Hvis du bare laster alle pakker du vet du bruker (og noen ekstra som noen på internett har foreslått), så kan det hende at disse pakkene skaper trøbbel for hverandre. Det er typisk at noen funksjoner har samme navn i ulike pakker, og R bruker da en annen funksjon enn du tror. Så da er rådet: ikke last masse pakker du ikke vet hva er. I det etterfølgende introduseres ulike pakker fortløpende og du får da vite hva de brukes til. Utvalget av pakker er dessuten slik at det ikke skal være noen slike konflikter. De pakkene vi skal bruke jobber veldig fint sammen. (Se avsnitt nedenfor om dialekter).\nMen det er altså et poeng at du må vite hva slags funksjonalitet de ulike pakkene har, og hvilke du faktisk trenger."
  },
  {
    "objectID": "kort_intro_R.html#r-dialekter",
    "href": "kort_intro_R.html#r-dialekter",
    "title": "3  En veldig kjapp intro til R",
    "section": "3.4 R-dialekter",
    "text": "3.4 R-dialekter\nDe funksjonene som følger med grunnleggende installasjon av R kalles altså “base R” eller bare “base”. Dette er grunnstrukturen for programmeringsspråket. Man kan gjøre svært mye analyser med bare bruk av base R, og en god del lærebøker i statistikk og dataanalyse er lagt opp til hovedsakelig bruk av base.\nNoen R-pakker inneholder ikke bare enkeltfunksjoner, men nesten et helt programmeringsspråk i seg selv. Noen slike pakker er egentlig en hel samling av veldig mange andre pakker som er integrert i hverandre og fungerer sømløst sammen. Det er lurt å holde seg innenfor samme “dialekt” da man ellers kan bli veldig forvirret. I det følgende skal vi holde oss til dialekten “Tidyverse”, som er en dominerende variant i R.\nMerk at det finnes altså flere dialekter som er spesialiserte for spesifikke formål. Et eksempel er {data.table} som er lynrask for store datasett, {caret} som gir et rammeverk for maskinlæring, og {lattice} som er et eget grafikk-system. Det finnes enda flere. Dette gjør at det kan være vanskelig å søke på nettet etter løsninger fordi du kan få svar (som funker!) i en annen dialekt enn den du kan."
  },
  {
    "objectID": "kort_intro_R.html#tidyverse",
    "href": "kort_intro_R.html#tidyverse",
    "title": "3  En veldig kjapp intro til R",
    "section": "3.5 Tidyverse",
    "text": "3.5 Tidyverse\nNår man laster pakken {tidyverse} laster man egentlig flere pakker som også kan lastes individuelt. Merk at “tidy” betyr jo “ryddig” og hensikten her er et språk som er så ryddig og logisk som mulig. Dette innebærer også at det er innarbeidet en del prinsipper for datastruktur og datahåndtering som hovedarkitekten bak har redegjort for i en egen artikkel. Full oversikt over pakkene som inngår i Tidyverse finner du på deres hjemmeside. Men du trenger ikke sette deg inn i alt det for å bruke softwaren.\n\n3.5.1 Datahåndtering: {dplyr}\nGrunnleggende datahåndtering inkluderer først og fremst å endre variable ved omkoding, utregninger eller transformasjoner. Pakken {dplyr} inneholder de nødvendige verktøy for dette.\nDe grunnleggende funksjonene vi bruker kan ordnes sekvensielt og bindes sammen med en “pipe”. Norsk oversettelse vil være “rørlegging”. Dette er litt rart og uvant, men i første omgang kan du se for deg at det er en flyt av data fra venstre side mot høyre side. Du kan altså gjøre noe med data og “deretter gjøre” noe mer med de dataene du har endret. Vi kommer tilbake til dette nedenfor.\nVi skal bruke et bittelite datasett for å demonstrere. Det er seks observasjoner og to variable. Observasjonene tilhører gruppe a, b, eller c, og variabelen “varA” har en tallverdi. Dataene ser ut som følger:\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.1     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n\n\ndinedata\n\n  gruppe varA\n1      a    3\n2      b    5\n3      b    2\n4      a    4\n5      c    3\n6      c    7\n\n\n\n3.5.1.1 Grunnleggende verb\nFor å endre variable brukes funksjonen mutate, som har to argumenter: hvilket datasett som skal endres på, og spesifikasjon av gitte variable.\nSyntaksen er slik at man starter med å angi objektnavnet med dataene, men her skal det ikke skrives data = av grunner vi kommer tilbake til straks. Deretter skriver man navnet på ny variabel “erlik” utregning av ny verdi. I det følgende lages en ny variabel “varB” som er 2 ganger varA:\n\nmutate(dinedata, varB = 2*varA)\n\n  gruppe varA varB\n1      a    3    6\n2      b    5   10\n3      b    2    4\n4      a    4    8\n5      c    3    6\n6      c    7   14\n\n\nMan kan også overskrive en eksisterende variabel på samme måte.\nVi kan også velge bort variable med select. Merk at det som ble gjort med mutate ovenfor ikke er lagt i et nytt objekt, så det er bare printet til konsollen. Objektet “dinedata” er altså ikke endret. I følgende kode bruker vi select til velge å bare beholde “varA”.\n\nselect(dinedata, varA)\n\n  varA\n1    3\n2    5\n3    2\n4    4\n5    3\n6    7\n\n\nVi kan slette variable ved å sette minustegn foran variabelnavnet som følger:\n\nselect(dinedata, -varA)\n\n  gruppe\n1      a\n2      b\n3      b\n4      a\n5      c\n6      c\n\n\n\n\n3.5.1.2 Pipe %>% med {magrittr}\nVi bruker en “pipe” for å få lettere lesbare koder og slippe å lage mange nye objekter hele tiden. Vi kan binde sammen flere verb i en arbeidsflyt der man kun angir objektnavnet én gang.\n\ndinedata %>% \n  mutate(varB = 2*varA) %>% \n  select(-varA)\n\n  gruppe varB\n1      a    6\n2      b   10\n3      b    4\n4      a    8\n5      c    6\n6      c   14\n\n\nOperatoren %>% betyr “gjør deretter”. Kode ovenfor kan dermed skrives i klartekst som følger:\n\nstart med datasettet dinedata og “gjør deretter:”\nlag en ny variabel med navn varB som er 2 ganger verdien av variabelen varA, og “gjør deretter:\nslett variabel varA\n\nHvis vi vil legge resultatet i et nytt objekt for å bruke det videre (og det vil vi nesten alltid!) så spesifiseres det med å sette nyttobjekt <- helt først som følger:\n\ndinedata2 <- dinedata %>% \n  mutate(varB = 2*varA) %>% \n  select(-varA)\n\n\n\n3.5.1.3 Logiske operatorer\nI mange sammenhenger setter man hvis-krav. F.eks. at man skal gi en ny variabel en verdi hvis en annen variabel har en bestemt verdig - og en annen verdi hvis ikke. Det kan også gjelde kombinasjoner av variable og verdier. Slike krav er da enten TRUE eller FALSE.\nHer er grunnleggende logiske operatorer.\n\n\n\nUttrykk\nKode\n\n\n\n\ner lik\n==\n\n\ner ikke lik\n!=\n\n\nog\n&\n\n\neller\n|\n\n\nstørre/mindre enn\n> eller <\n\n\nstørre/mindre enn eller er lik\n<= eller >=\n\n\n\nFor å kode om kategoriske variable trenger vi disse. La oss bruke mutate til å gruppere sammen gruppene “a” og “b” ved å gjøre om alle “a” til “b”. Da bruker vi funksjonen ifelse som har syntaksen: ifelse(krav, verdi hvis TRUE, verdi hvis FALSE). Altså: først kravet, og alle observasjoner som fyller dette kravet får en verdi, mens alle andre får en annen verdi. Her er en kode som sjekker hvem som er i gruppe “a”, og gjør alle disse om til “b”, og resten beholder verdiene fra variabelen “gruppe”.\n\ndinedata %>% \n  mutate(gruppe2 = ifelse(gruppe == \"a\", \"b\", gruppe))\n\n  gruppe varA gruppe2\n1      a    3       b\n2      b    5       b\n3      b    2       b\n4      a    4       b\n5      c    3       c\n6      c    7       c\n\n\nLogiske krav kan også kombineres med & og | og også med parenteser for mer kompliserte krav. Her er et eksempel som omkoder basert på verdier på to variable for å lage en tredje variabel:\n\ndinedata %>% \n  mutate(gruppe2 = ifelse(gruppe == \"a\" & varA < 5, \"a5\", \"andre\"))\n\n  gruppe varA gruppe2\n1      a    3      a5\n2      b    5   andre\n3      b    2   andre\n4      a    4      a5\n5      c    3   andre\n6      c    7   andre\n\n\n\n\n3.5.1.4 Flere verb\nLogiske operatorer brukes også til å filtrere dataene, altså å beholde eller slette rader som oppfyller visse krav. Her er en kode som beholder alle observasjoner om ikke tilhører gruppe “a”:\n\ndinedata %>% \n  filter(gruppe != \"a\")\n\n  gruppe varA\n1      b    5\n2      b    2\n3      c    3\n4      c    7\n\n\nsummarise aggregerer\n\ndinedata %>% \n  summarise(totalt = sum(varA), standardavvik = sd(varA))\n\n  totalt standardavvik\n1     24      1.788854\n\n\ngroup_by grupperer data slik at hvis vi kan gå grupperte verdier med mutate og summarise.\n\ndinedata %>% \n  group_by(gruppe) %>% \n  summarise(totalt = sum(varA), standardavvik = sd(varA))\n\n# A tibble: 3 × 3\n  gruppe totalt standardavvik\n  <chr>   <dbl>         <dbl>\n1 a           7         0.707\n2 b           7         2.12 \n3 c          10         2.83 \n\n\n\n\n\n3.5.2 Grafikk: {ggplot2}\n\n\n3.5.3 Import av data: {haven}\n\n\n3.5.4 Andre funksjoner"
  },
  {
    "objectID": "norlag.html#tilgang-og-lagring",
    "href": "norlag.html#tilgang-og-lagring",
    "title": "4  Datasettet NorLAG",
    "section": "4.1 Tilgang og lagring",
    "text": "4.1 Tilgang og lagring\nNorLAG er gule data og har restriksjoner på bruk og lagring. Du er pliktet til å sette deg inn i retningslinjene som du finner på denne siden.\nI denne sammenhengen betyr det i praksis at du bør jobbe på UiO-OneDrive. Altså: ikke lagre data på din personlige datamaskin og ikke skytjeneste med en personlig konto. Merk at det er forskjell på f.eks. OneDrive gjennom UiO og privat, og privat konto er ikke tillatt for slike data.\nFor å få tilgang på datasettet må du gjøre følgende:\n\nOppgi din uio-epostadresse i dette nettskjemaet. Emneansvarlig legge deg inn i systemet.\nDu får tilsendt en lenke fra Sikt med videre instruksjoner om hvordan du signerer en avtale. Les avtalen og signer digitalt.\nLast ned pdf-versjon av den signerte avtalen og behold den for senere referanse. Du kan også gjøre det senere ved å logge inn på Sikt sine sider for data access.\nLaster opp den signerte avtalen i dette skjemaet.\nEmneansvarlig vil dele en mappe med deg i Sharepoint der du kun har lesetilgang. Her ligger tilrettelagte versjoner av datasettet.1 Kopier alle filene over til en lokal mappe i din UiO-OneDrive (se ovenfor).\n\nOBS!! Dere signerer en avtale om bruk av data som er begrenset til å brukes til metodeundervisningen på master i sosiologi ved UiO. Den avtalen har også en begrensning i tid. Les avtalen nøye. Dere har et selvstendig ansvar for å overholde betingelsene, herunder at dataene skal slettes innen angitt dato. Det er fult mulig å bruke disse dataene til senere prosjekter, f.eks. til masteroppgave, men da må det søkes på nytt.2\n\n4.1.1 Innlesning av data\nDatasettet norlag.rds er altså konvertert til R-formatet rds. Når dette er gjort er du klar for både forkurset og SOS4020.\nNest økt vil omhandle innlesning av data: både rds og andre vanlige formater. For eksemplene her vil det brukes noen forenklede datasett med færre variable."
  },
  {
    "objectID": "oversikt_datasettet.html#sjekk-om-innlesning-ble-riktig",
    "href": "oversikt_datasettet.html#sjekk-om-innlesning-ble-riktig",
    "title": "5  Få oversikt over datasettet",
    "section": "5.1 Sjekk om innlesning ble riktig",
    "text": "5.1 Sjekk om innlesning ble riktig\nDet første man bør sjekke er jo om innlesning av datasettet ble riktig. Skjer det noe feil her, så blir selvsagt alt annet feil. Men det er lite som kan gå galt når man leser inn fra datasett. Et unntak er csv-filer som ikke har metadata inkludert.\nFunksjonen class() gir informasjon om hva slags objekt man har. Altså: etter at man har lest inn dataene og lagt det i et objekt. Her sjekkes objektet norlag:\n\nclass(norlag)\n\n[1] \"data.frame\"\n\n\nI dette tilfellet får vi tre beskjeder. Det er en kombinert objekttype av tibble og data.frame. Mens data.frame er standard datasett tilsvarende som et regneark, så er tibble en utvidelse med noen ekstra funksjoner som er nyttige for avanserte brukere, men er å regne som en utvidelse av data.frame. For vårt formål vil det i praksis være det samme. Et datasett som leses inn i R bør altså være av typen tbl eller data.frame. Data kan også ha andre typer strukturer og da vil class() rapportere noe annet.\nNår man bruker funksjoner i R, så vil noen ganger resultatet avhenge av hva slags type objekt det er.\nFor å vite hvor mange rader og kolonner det er i datasettet kan man bruke funksjonen dim() slik:\n\ndim(norlag)\n\n[1] 20892  2605\n\n\nHer får vi vite at det er 20892 rader (dvs. observasjoner) og 2605 kollonner (dvs. variable).\n\n5.1.1 Bruke View()\nSærlig når man er uvant med å jobbe i R vil man kunne ha behov for å se på dataene slik man er vant til fra regneark eller software som SPSS eller Stata. En mulighet er å bruke funksjonen View() så vil hele datafilen åpnes i eget vindu. Dette er kun egnet for å se på dataene og du kan lukke vinduet uten at det påvirker dataene. Dataene ligger fremdeles i det samme objektet på samme måte som før.\n\nView(norlag)\n\nHvis variablene ser ut til å ha forventede variabelnavn og verdier, så er det antakeligvis ok.\nEt slikt datasett tar imidlertid stor plass og det er vanligvis mer hensiktsmessige måter å se på dataene på som også gir mer informasjon. I R er det ikke meningen at du skal “sitte og se på dataene” på den måten mens man jobber. Men ta gjerne en titt for å få et bedre inntrykk av hvordan dataene ser ut.\nDu kan lukke det vinduet med dataene uten at det har noe å si for dataene, som fremdeles er tilgjengelig i minnet på datamaskinen på samme måte som før.\n\n\n5.1.2 Bruke head()\nFunksjonen head() skriver de første 6 observasjonenen til konsollen i Rstudio. Det gir et første inntrykk av datasettet med variabelnavn og de første verdiene uten å åpne hele datasettet. Hva som faktisk vises vil avhenge av hvor stor skjerm du har, men R vil bare vise de første variablene etter hva som er plass til på skjermen din. For datasett med mer enn noen få variable er ikke dette veldig nyttig, men noen ganger har man små datasett. Med en liten skjerm kan dette da se omtrent slik ut:\n\nhead(norlag)\n\n\nLegg merke til at under hvert variabelnavn er det en indikasjon på hva slags variabeltype det er. For eksempel betyr <dbl> at det er en numerisk variabel mens <dbl+lbl> indikerer at variabelen inneholder labels.\nDet er lite hensiktsmessig å vise alt i konsollen fordi det rett og slett ikke er plass. Nerst står det derfor angitt at det er flere variable som ikke vises og navnet på de første av disse.\n\n\n5.1.3 Subset med klammeparenteser\nEn enkel løsning er å bare se på noen få variable om gangen. Med klammeparentes kan vi angi hvilke radnummer og kolonnenummer vi ønsker se på med følgende syntax: datasett[rader, kolonner] der altså komma skiller mellom rader og kolonner. Følgende eksempel viser hvordan man kan bruke head() for å vise de første observasjonene i datasettet med bare de første 5 variablene (altså: kollonne nr 1-5).\n\nhead(norlag[, 1:5])\n\n  ref_nr         iodeltakelse iododaar iofodselsaar iokjonn\n1      5     Deltatt T1 og T2     <NA>         1934    Mann\n2      5     Deltatt T1 og T2     <NA>         1934    Mann\n3     10 Deltatt T1, T2 og T3     <NA>         1957  Kvinne\n4     10 Deltatt T1, T2 og T3     <NA>         1957  Kvinne\n5     10 Deltatt T1, T2 og T3     <NA>         1957  Kvinne\n6     12     Deltatt T1 og T3     <NA>         1955  Kvinne\n\n\nVi kan altså også angi både rader og kollonner på denne måten. Her er eksempel som viser første 3 rader og variabelnummer 40 til 44.\n\nhead(norlag[1:3, 40:44])\n\n  hc201 hc202 hc203 hc204 hc205\n1   176    85    Ja   Nei    Ja\n2   176    95    Ja   Nei    Ja\n3   168    64    Ja   Nei    Ja\n\n\nLegg merke til at under hvert variabelnavn står det en liten tekst, f.eks.  eller <S3: haven_labelled>. Det kan også stå andre ting. dbl betyr at det er en kontinuerlig variabel, mens haven_labelled betyr at det er labler til alle eller noe verdier i variabelen.\nVi skal primært jobbe med data som ikke er “labelled”, men du vil noen ganger komme borti dette, spesielt hvis du importerer data fra andre statistikksoftware.\n\n\n5.1.4 Bruke ‘glimpse()’\nI tidligere kurs skal dere ha lært å bruke funksjonen glimpse(), men også her blir det mest rotete fordi det er så mange variable. Det tar rett og slett veldig stor plass på skjermen.\nEn variant er å bruke glimpse() bare på et utvalg variable på tilsvarende måte. Her er et eksempel, men der vi ser på de 20 første variablene ved bruk av klammeparentes tilsvarende som vist over.\n\nglimpse(norlag[, 1:20])\n\nRows: 20,892\nColumns: 20\n$ ref_nr          <dbl> 5, 5, 10, 10, 10, 12, 12, 15, 15, 18, 18, 22, 23, 23, …\n$ iodeltakelse    <fct> \"Deltatt T1 og T2\", \"Deltatt T1 og T2\", \"Deltatt T1, T…\n$ iododaar        <fct> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2006, NA, …\n$ iofodselsaar    <dbl> 1934, 1934, 1957, 1957, 1957, 1955, 1955, 1944, 1944, …\n$ iokjonn         <fct> Mann, Mann, Kvinne, Kvinne, Kvinne, Kvinne, Kvinne, Kv…\n$ ionorlag1kohort <fct> Del av NorLAG1 kohort, Del av NorLAG1 kohort, Del av N…\n$ iopafyll        <fct> Ingen påfyll, Ingen påfyll, Ingen påfyll, Ingen påfyll…\n$ iovektnorlag2   <fct> 143, 143, 51, 51, 51, NA, NA, 195, 195, 215, 215, NA, …\n$ iovektnorlag3   <fct> NA, NA, 73, 73, 73, 135, 135, NA, NA, 227, 227, NA, 39…\n$ pr002c          <fct> 1905, 1905, 1933, 1933, 1933, 1918, 1918, 1918, 1918, …\n$ pr003c          <fct> 1991, 1991, NA, NA, NA, 2004, 2004, 1989, 1989, NA, NA…\n$ pr005c          <fct> 1905, 1905, 1933, 1933, 1933, 1915, 1915, 1909, 1909, …\n$ pr006c          <fct> 1996, 1996, NA, NA, NA, 1996, 1996, 1975, 1975, 1976, …\n$ pr007c          <fct> Grunnskole, Grunnskole, Videregående, Videregående, Vi…\n$ pr011c          <fct> Videregående, Videregående, Grunnskole, Grunnskole, Gr…\n$ round           <dbl> 1, 2, 3, 2, 1, 3, 1, 1, 2, 3, 2, 1, 3, 1, 1, 3, 2, 1, …\n$ ioalder         <fct> 68, 72, 59, 49, 44, 61, 47, 58, 63, 67, 57, 63, 69, 55…\n$ iointervjumnd   <fct> 5, 11, 5, 5, 5, 8, 5, 8, 3, 3, 5, 8, 5, 8, 2, 5, 9, 4,…\n$ iointervjuaar   <fct> 2002, 2007, 2017, 2007, 2002, 2017, 2002, 2002, 2007, …\n$ iolandb         <fct> NA, Norskfødt, NA, Norskfødt, NA, NA, NA, NA, Norskfød…\n\n\nI denne output’en er den første kollonnen altså variabelnavnene, deretter er det en kollonne som viser hva slags type variabel det er, og deretter de første observasjonene på hver variabel slik at man får et inntrykk av hvordan det ser ut. glimpse() gir altså omtrent samme informasjon som head(), men er nok mer hensiktsmessig hvis mange variable.\n\n\n5.1.5 Undersøke enkeltvariable med codebook() fra pakken {memisc}\nNoen ganger vil man ha litt mer informasjon om enkeltvariablene. Noen datasett vil komme med labler (omtalt annet sted) eller faktorvariable, som gjør at variablene inneholder både tallverdier og tekst.\nÅ få ut noe deskriptiv statistikk og se på fordelinger er da gjerne neste steg som vil bli behandlet i de etterfølgende kapitlene.\nMan vil klare seg greit med det vi har vist ovenfor. Men det finnes flere måter å gjøre det på. Pakken {memisc} inneholder en rekke funksjoner for å håndtere surveydata, som vi ikke skal gå nærmere inn på her. Men akkurat funksjonen codebook() gir litt mer informativt output enn look_for().\nFor å bruke denne må du installere pakken først. I eksempelet nedenfor er pakken ikke lastet med library(), men angitt pakken direkte med memisc:: først. Dette kan være nyttig hvis man ikke skal bruke noen andre funksjoner fra denne pakken.\n\nmemisc::codebook(norlag$iokjonn)\n\n================================================================================\n\n   norlag$iokjonn 'IOs kjønn'\n\n--------------------------------------------------------------------------------\n\n   Storage mode: integer\n   Factor with 2 levels\n\n   Levels and labels     N Valid\n                                \n   1 'Mann'          10244  49.0\n   2 'Kvinne'        10648  51.0\n\n\nPoenget her er altså bare å få en penere output og litt deskriptiv statistikk samtidig."
  },
  {
    "objectID": "oversikt_datasettet.html#søke-i-datasettet-etter-variable",
    "href": "oversikt_datasettet.html#søke-i-datasettet-etter-variable",
    "title": "5  Få oversikt over datasettet",
    "section": "5.2 Søke i datasettet etter variable",
    "text": "5.2 Søke i datasettet etter variable\nFor å se nærmere på en variabel går an å bruke funksjonen look_for(), som primært er en søke-funksjon, men det gir også informasjon om variabelen.\n\nlook_for(norlag, \"iokjonn\")\n\n pos variable label     col_type values\n 5   iokjonn  IOs kjønn fct      Mann  \n                                 Kvinne\n\n\nI output fremgår det at dette er den 10’ende variabelen, inneholder informasjonen “IOs kjønn”, er av typen numerisk med tilhørende labler, og verdiene er 1 = Mann og 2 = Kvinne.\nDet går også an å bare få ut variabel-label med funksjonen var_label() slik:\n\nvar_label(norlag$iokjonn)\n\n[1] \"IOs kjønn\"\n\n\nFor å se labels på verdiene bruk val_labels().\n\nval_labels(norlag$iokjonn)\n\nNULL\n\n\nAlle datasett skal komme med en dokumentasjon som sier hva hver variabel inneholder og hvilke verdier som finnes i hver variable, og hva de betyr. Dette leveres gjerne som en separat fil, ganske ofte i pdf eller html format. NSD/Sikt leverer dokumentasjonen for Norlag i html-format. (Ideelt burde det vært i et enkelt maskinlesbart format egnet til å bruke til omkoding og labler for de som ønsker det, men de har valgt en annen løsning).\nDu kan søke i dokumentasjonen på samme måte som i andre filer, men det kan være litt knotete. Et godt alternativ er å søke direkte i datasettet. Funksjonen look_for() søker både i variabelnavn, verdier og labler. Her er et eksempel for hvordan finne variabler som inneholder ordet “yrkesinntekt”. Du kan også søke på kortere eller lengre tekststrenger. (Søker du f.eks. bare på “innt” eller “yrke” så får du opp langt flere variable, så du må kanskje prøve deg litt frem).\n\nlook_for(norlag, \"Yrkesinntekt\")\n\nDet er to variable som inneholder teksten “yrkesinntekt”. Den første variabelen har posisjon 353 i datasettet og har variabelnavnet inwyrkinnt. Den andre variabelen har posisjon 371 og har navnet inpartwyrkinnt. Vi fokuserer på den første.\nMerk at når labelen avsluttes med ~ (uttales “tilde”) indikerer det at teksten er avkortet i outputvinduet. Du får opp hele teksten ved å bruke val_label() slik:\n\nvar_label(norlag$inwyrkinnt)\n\nNULL"
  },
  {
    "objectID": "grafikk.html#lagvis-grafikk",
    "href": "grafikk.html#lagvis-grafikk",
    "title": "6  Grafikk med ggplot",
    "section": "6.1 Lagvis grafikk",
    "text": "6.1 Lagvis grafikk\nI R er det mange funksjoner for å lage grafikk. Noen er spesialiserte og knyttet til spesielle analysemetoder og gir deg akkurat det du trenger. Vi skal her bruke et generelt system for grafikk som heter ggplot som kan brukes til all slags grafikk. Funksjonen ggplot er bygget opp som en gramatikk for grafisk fremstilling. Det ligger en teori til grunn som er utledet i boken ved omtrent samme navn: The grammar of graphics. Det er mye som kan sies om dette, men det viktige er at grafikken er bygget opp rundt noen bestanddeler. Når du behersker disse kan du fremstille nær sagt hva som helst av kvantitativ informasjon grafisk. Dette er altså et system for grafikk, ikke bare kommandoer for spesifikke typer plot. Vi skal likevel bare se på grunnleggende typer plot her.\nSystemet er bygd opp lagvis. Det gjelder selve koden, men også hvordan det ser ut visuelt. Man kan utvide plottet med flere lag i samme plot og det legges da oppå hverandre i den rekkefølgen som angis i koden.\nFor enkle plot som vi skal bruke her angir man i denne rekkefølgen og med en + mellom hver del (vanligvis per linje, men linjeskift spiller ingen rolle). Hver del av koden spesifiserer enten hva som skal plottes eller hvordan det plottes, mens andre deler kan kontrollere utseende på akser, fargeskalaer, støttelinjer eller andre ting som har med layout å gjøre.\n\nAngi data og hva som skal plottes med ggplot()\nAngi hvordan det skal plottes med geom_*()\nAngi andre spesifikasjoner (farger, titler, koordinatsystemer osv)\n\nDette blir tydeligere i eksemplene og forklares underveis.\n\nDet første argumentet i ggplot er data. Altså: hvilket datasett informasjonen hentes fra.\nInni ggplot() må det spesifiseres aes(), “aestethics”, som er hvilke variable som skal plottes. Først og fremst hva som skal på x-akse og y-akse (og evt. z-akse), men også spesifikasjon av om linjer (farge, linjetype) og fyllfarger, skal angis etter en annen variabel.\ngeom_* står for geometric og sier noe om hvordan data skal se ut. Det kan være punkter, histogram, stolper, linjer osv.\ncoord_* definerer koordinatsystemet. Stort sett blir dette bestemt av variablene. Men du kan også snu grafen eller definere sirkulært koordinatsystem, eller andre enklere ting.\nfacet_* definerer hvordan du vil dele opp grafikken i undergrupper"
  },
  {
    "objectID": "grafikk.html#kategoriske-variabel",
    "href": "grafikk.html#kategoriske-variabel",
    "title": "6  Grafikk med ggplot",
    "section": "6.2 Kategoriske variabel",
    "text": "6.2 Kategoriske variabel\n\n6.2.1 Stolpediagram\n\nlibrary(ggforce)\nggplot(abu89, aes(x = klasse89)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\nNoen ganger ønsker man å vise fordelingen for to ulike grupper, la oss si for kjønn. En mulighet er da å rett og slett lage to stolpediagram ved siden av hverandre. Til dette kan man spesifisere at dataene er gruppert etter variabelen female og at fyllfargen skal settes etter denne variablen med fill = factor(female). Merk bruken av factor(female) fordi variabelen er numerisk og det vil da ellers brukes en kontinuerlig fargeskale, mens å gjøre om variabelen til kategorisk brukes en annen fargeskala.\nI tillegg gjør vi her to ting til: setter et annet grafisk tema med theme_minimal() og snur plotvinduet slik at kategoriene er litt lettere å lese. Dette er smak og behag.\n\nggplot(abu89, aes(x = klasse89, group = female, fill = factor(female))) +\n  geom_bar(position=\"dodge\") +\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 90))+\n  coord_flip()\n\n\n\n\nEt alternativ er å plassere grafikken for menn og kvinner ved siden av hverandre. Å legge til facet_wrap() gjør dette.\n\nggplot(abu89, aes(x = klasse89)) +\n  geom_bar() +\n  facet_wrap(~factor(female)) +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\nEt automatisk forvalg for geom_bar() er hvordan gruppene plasseres som er position=\"stack\". Det betyr at gruppene stables oppå hverandre. Dette er godt egnet hvis poenget er å vise hvor mange av hvert kjønn som er i hver gruppe. Det er mindre egnet hvis du ønsker å sammenligne menn og kvinner. Da er alternativet å velge position=\"dodge\" som følger:\n\n\n6.2.2 Kakediagram\nGenerelt er ikke kakediagram å anbefale da korrekt tolkning involverer å tolke et areal som inneholder vinkel. Med få kategorier som er rimelig forskjellig kan det gi et ok inntrykk, men ofte ender man opp med å måtte skrive på tallene likevel. Vi tar det med her egentlig bare fordi mange insisterer på å bruke det. Så vet du at det er mulig.\nDet enkleste er å bruke funksjonen pie() som gir følgende resultat.\n\ntab <- table(abu89$klasse89) \ntab\n\n\n    I Øvre serviceklasse   II Nedre serviceklasse   III Rutinefunksjonærer \n                     328                     1181                     1248 \n V-VI Faglærte arbeidere VIIa Ufaglærte arbeidere \n                     648                      637 \n\npie(tab)\n\n\n\n\nMen hvis man skal bruke ggplot er det litt mer jobb. Fordelen med ggplot er at du har bedre kontroll for å lage publiserbar kvalitet. (Akkurat for kakediagram er det kanskje ikke så farlige, for du bør ikke bruke det i publikasjoner hvis du kan la være).\n\npc <- abu89 %>% \n  group_by(klasse89) %>% \n  summarise(n = n()) %>% \n  mutate(pct = n/sum(n)*100) %>% \n  ungroup()\n\nggplot(pc, aes(x = \"\", y = pct, fill = (klasse89))) +\n  geom_bar(stat=\"identity\", width=1) +\n  coord_polar(\"y\", start=0) +\n  theme_void()+\n  geom_text( aes(label = paste0( round(pct,1), \"%\"), x = 1.4), \n            position = position_stack(vjust=.5), check_overlap = F) +\n  labs(x = NULL, y = NULL, fill = NULL)+\n  theme(axis.line = element_blank(),\n          axis.text = element_blank(),\n          axis.ticks = element_blank()) +\n  scale_fill_brewer(palette=\"Blues\", direction = -1)"
  },
  {
    "objectID": "grafikk.html#kontinuerlige-variable",
    "href": "grafikk.html#kontinuerlige-variable",
    "title": "6  Grafikk med ggplot",
    "section": "6.3 Kontinuerlige variable",
    "text": "6.3 Kontinuerlige variable\n\n6.3.1 Histogram\n\nggplot(abu89, aes(x = time89)) +\n  geom_histogram()\n\n\n\n\nDet er også vanlig å fremstille det samme på en “tetthetsskala”, der arealet summeres til 1. Det betyr at arealet for hvert intervall tilsvarer en andel. Visuelt sett er det vel så mye arealet vi oppfatter som høyden på stolpene. Men det er bare skalaen på y-aksen som har endret seg. Visuelt sett, ser histogrammene helt like ut.\n\nggplot(abu89, aes(x = time89, y = ..density..)) +\n  geom_histogram()\n\n\n\n\n\n\n6.3.2 Density plot\nDensity plot er en måte å fremstille det samme på, men i stedet for å dele inn i intervaller som i histogram lager vi en glattet kurve. Det blir på skalaen “tetthet” som i histogrammet ovenfor.\n\nggplot(abu89, aes(x = time89)) +\n  geom_density()\n\n\n\n\n\nggplot(abu89, aes(x = time89)) +\n  geom_histogram(aes(y = ..density..), fill = \"lightgrey\", col = \"grey\") +\n  geom_density(col = \"red\", linewidth = 1) +\n  theme_minimal()\n\n\n\n\nEn fordel med denne fremstillingen er at det er lettere å sammenligne grupper. Her er et eksempel med density plot etter hvor mye man drikker.\n\nggplot(abu89, aes(x = time89, group = klasse89, linetype = klasse89)) +\n  geom_density(linewidth = 1)+\n  guides(fill = guide_legend(override.aes = list(shape = 1 ) ) ) +\n  theme_minimal()\n\n\n\n\n\nggplot(abu89, aes(x = time89)) +\n  geom_density(linewidth = 1)+\n  theme_minimal()+\n  facet_wrap(~klasse89, scales=\"free\")\n\n\n\n\n\nggplot(abu89, aes(x = time89, group = female,  fill = factor(female))) +\n  geom_density(alpha = .3)+\n  guides(fill=guide_legend(title=\"Kjønn\"))+\n  theme_minimal()\n\n\n\n\n\n\n6.3.3 Flere variable samtidig\n\n6.3.3.1 Boksplot\n\nggplot(abu89, aes(y = time89, group = klasse89)) +\n  geom_boxplot()+\n  theme_minimal()\n\n\n\n\n\n\n6.3.3.2 Scatterplot\n\nggplot(abu89, aes(x = age, y = time89)) +\n  geom_point(alpha=.3)+\n  theme_minimal()\n\n\n\n\n\nggplot(abu89, aes(x = age, y = time89)) +\n  geom_jitter(alpha=.1, width = .3)+\n  theme_minimal()\n\n\n\n\n\n\n6.3.3.3 Ridgeplot\nRidgeplot er en annen måte å sammenligne en kontinuerlig fordeling betinget på en gruppering.\n\nlibrary(ggridges)\nggplot( abu89,  aes(y = klasse89, x = time89)) +\n  geom_density_ridges()"
  },
  {
    "objectID": "grafikk.html#oppgaver",
    "href": "grafikk.html#oppgaver",
    "title": "6  Grafikk med ggplot",
    "section": "6.4 Oppgaver",
    "text": "6.4 Oppgaver\nSlå opp i boken R for data science hvis du står fast eller ikke skjønner hva koden betyr.\n\nExercise 6.1 Last ned datasettet abu89 fra angitt hjemmeside og les inn dataene til R som vist ovenfor. Lag den samme grafikken som vist her, gjør noen endringer på kodene for å endre utseendet på plottene. Det er et mål at du skal forstå hva hver enkelt kommando gjør.\n\n\nExercise 6.2 Last inn datasettet NorLAG i R. Velg noen variable som du selv tenker kan være informative å se nærmere på. Bruk de samme teknikkene på disse variablene."
  },
  {
    "objectID": "deskriptive_tabeller.html#quick-and-dirty-oppsummeringer",
    "href": "deskriptive_tabeller.html#quick-and-dirty-oppsummeringer",
    "title": "7  Deskriptive tabeller",
    "section": "7.1 Quick-and-dirty oppsummeringer",
    "text": "7.1 Quick-and-dirty oppsummeringer\nFørst og fremst har vi funksjonen summary(). Når denne brukes på et objekt vil hva slags output du får avhenge av objekttypen. Derfor vil summary() gi forskjellig output om det er en vektor, et datasett eller et regresjonsobjekt etc. Vi avgrenser oss til datasett her.\nHer er output for hele datasettet.\n\nsummary(abu89)\n\n     io_nr          time89             ed             age       \n Min.   :   3   Min.   : 25.00   Min.   : 0.00   Min.   :16.00  \n 1st Qu.:1542   1st Qu.: 71.00   1st Qu.: 1.00   1st Qu.:30.00  \n Median :3093   Median : 83.33   Median : 3.00   Median :39.00  \n Mean   :3105   Mean   : 90.15   Mean   : 2.69   Mean   :39.65  \n 3rd Qu.:4644   3rd Qu.:102.56   3rd Qu.: 3.00   3rd Qu.:48.00  \n Max.   :6258   Max.   :343.75   Max.   :11.00   Max.   :74.00  \n                NA's   :368                                     \n     female                           klasse89    promot          fexp       \n Min.   :0.0000   I Øvre serviceklasse    : 328   NEI:2568   Min.   :0.0000  \n 1st Qu.:0.0000   II Nedre serviceklasse  :1181   JA :1559   1st Qu.:0.2000  \n Median :0.0000   III Rutinefunksjonærer  :1248              Median :0.7000  \n Mean   :0.4686   V-VI Faglærte arbeidere : 648              Mean   :0.9451  \n 3rd Qu.:1.0000   VIIa Ufaglærte arbeidere: 637              3rd Qu.:1.4000  \n Max.   :1.0000   NA's                    :  85              Max.   :4.9000  \n                                                                             \n    private    \n Public :1602  \n Private:2525  \n               \n               \n               \n               \n               \n\n\nMerk at summary() rapporterer forskjellig basert på om variabelen er kontinuerlig eller kategorisk. For kontinuerlige variable gis min/max, kvartiler, median og gjennomsnitt. For kategoriske variable gis det antall i hver kategori. Hvis det er manglende verdier på en variabel står det oppført nederst som antall NA's.\nMerk her at variabelen female er definert som kontinuerlig selv om det bare er to verdier. Det ville være mer hensiktsmessig å gjøre om denne variabelen til kategorisk.\nMan kan også bruke summary() på enkeltvariable med bruk av $ som følger:\n\nsummary(abu89$time89)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  25.00   71.00   83.33   90.15  102.56  343.75     368 \n\n\nDa får man altså bare tallene for den variabelen man har angitt etter dollartegnet.\n\n7.1.1 Enkeltfunksjoner\nMan kan hente ut hvert av disse tallene spesifikt fremfor å bruke summary(). Det er egne funksjoner for dette, og de kan også brukes når man gjør databearbeiding for litt andre formål. Vi ser her på de viktigste.\nHva om man vil ha en kvartil som ikke er oppgitt i forvalget? Da kan man bruke funksjonen quantile(). Argumentene i denne funksjonen er hvilken variabel og hvilket prosentil. Som vi ovenfor inneholder time89 noen NA. Vi må i tillegg bestemme hva vi ønsker å gjøre med NA i beregningen, og vi vil her se bort fra disse ved å angi na.rm = TRUE. Ellers får man feilmelding.\nHer er eksempel med første kvartil som skal gi samme svar som ovenfor:\n\nquantile(abu89$time89, .25, na.rm = TRUE)\n\n25% \n 71 \n\n\nHer er en variant der man ber om 95-prosentilen:\n\nquantile(abu89$time89, .95, na.rm = TRUE)\n\n     95% \n148.0362 \n\n\nMan kan også be om flere prosentiler. Da listes disse opp innenfor en c() som følger. Her gis prosentilene for 5, 10, 90 og 95 prosent.\n\nquantile(abu89$time89, c(.05, .10, .90, .95), na.rm = TRUE)\n\n       5%       10%       90%       95% \n 54.91651  61.00000 127.77778 148.03618 \n\n\nGjennomsnittet av en variabel gis ved funksjonen mean():\n\nmean(abu89$time89, na.rm = TRUE)\n\n[1] 90.14948\n\n\nStandardavviket gis ved sd():\n\nsd(abu89$time89, na.rm = TRUE)\n\n[1] 30.31473\n\n\nMedianen kan angis med quantile(), men enklere med median():\n\nmedian(abu89$time89, na.rm = TRUE)\n\n[1] 83.33333\n\n\nVi trenger også ofte antall. nrow() gir antall rader, dvs. antall observasjoner i datasettet\n\nnrow(abu89)\n\n[1] 4127\n\n\nTilsvarende gir ncol() antall kolonner, mens dim() gir begge deler:\n\nncol(abu89)\n\n[1] 9\n\ndim(abu89)\n\n[1] 4127    9"
  },
  {
    "objectID": "deskriptive_tabeller.html#professjonelle-tabeller-med-gtsummary",
    "href": "deskriptive_tabeller.html#professjonelle-tabeller-med-gtsummary",
    "title": "7  Deskriptive tabeller",
    "section": "7.2 Professjonelle tabeller med gtsummary",
    "text": "7.2 Professjonelle tabeller med gtsummary\nFor å lage ordentlig professjonelle tabeller kreves det mer. For det første skal de se ordentlige ut, men de skal også kunne eksporteres til andre formater på en hensiktsmessig måte.\nI R finnes det en hel rekke slike funksjoner. Her har vi vektlagt pakken gtsummary fordi den gir gode tabeller fra helt enkle til ganske avanserte relativt lett. Det er også mange muligheter for å justere tabellene slik du vil. Dessuten kan resultatene eksporteres lett til de fleste aktuelle formater (Word, html, pdf, Excel, latex).\nAvanserte brukere vil muligens se begrensningene i denne pakken og foretrekke noe annet. De fleste vil kunne lage det aller meste med denne pakken.\nVi starter med en enkel oversiktstabell med alle variablene i datasettet. Men vi fjerner løpenummeret for person, nemlig variabelen io_nr fordi den ikke inneholder noe analyserbar informasjon.\n\nabu89 %>% \n  select(-io_nr) %>% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 4,1271\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n83 (71, 103)\n        Unknown\n368\n    År utdanning\n\n        0\n839 (20%)\n        1\n1,156 (28%)\n        3\n1,121 (27%)\n        5\n483 (12%)\n        7\n308 (7.5%)\n        9\n205 (5.0%)\n        11\n15 (0.4%)\n    Alder\n39 (30, 48)\n    Respondentens kjønn\n1,934 (47%)\n    Goldthorpe klasse 1989\n\n        I Øvre serviceklasse\n328 (8.1%)\n        II Nedre serviceklasse\n1,181 (29%)\n        III Rutinefunksjonærer\n1,248 (31%)\n        V-VI Faglærte arbeidere\n648 (16%)\n        VIIa Ufaglærte arbeidere\n637 (16%)\n        Unknown\n85\n    Noen gang forfremmet\n\n        NEI\n2,568 (62%)\n        JA\n1,559 (38%)\n    Bedriftserfaring\n0.70 (0.20, 1.40)\n    Privat sektor\n\n        Public\n1,602 (39%)\n        Private\n2,525 (61%)\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\nLegg merke til at tbl_summary gjør en del ting automatisk. Først og fremst er bruker den variabel label og factor levels i sidespalten. Ofte vil ikke variable ha slike labler, og da vil det vises variabelnavnene. Variabelen kjønn har ikke angitt factor levels, og variabelen har bare verdiene 0 og 1, og da rapporteres kun den ene kategorien (dvs. verdien 1). Vi kan legge til annen tekst hvis vi ønsker.\nDernest er det en forhåndsinnstilling som angir at det for kontinuerlige variable skal rapporteres median og interquartile range (IQR), dvs. nedre og øvre kvartil i parentes. Det gir en god beskrivelse av variablene, men vi skal endre dette nedenfor. For kategoriske variable rapporteres det antall observasjoner og andelen i prosent i parentes.\nMen merk at for antall år utdanning og kjønn, så er det rapportert som kategoriske variable selv om variabeltypen er kontinuerlig. tbl_summary gjør dette fordi det er relativt få kategorier slik at median og IQR ikke er så interessant uansett.\nLa oss først endre slik at det rapporteres gjennomsnitt og standardavvik i stedet. Det er mer vanlig å gjøre selv om det ikke er noen regel for dette. Funksjonen theme_gtsummary_mean_sd() endrer standardvalget for tbl_summary i alle etterfølgende tabeller. Dermed slipper du endre neste gang. Flere themes finner du på pakkens hjemmeside. For å gå tilbake til opprinnelig theme brukes funksjonen reset_gtsummary_theme().\nVi kan endre andre ting ved tabellen med noen enkle grep. Alle variable kan endre navn i forspalten med å legge til argumentet label =. Nedenfor er to variable endret for å vise hvordan man endrer flere variable. Når det er flere variable må de spesifiseres innenfor argumentet list() som nedenfor. Her endrer vi også label for variabelen female og klasse89.\nNoen ganger kan man også ønske å endre hvordan en variabel presenteres. Et vanlig behov er å presisere hvilken type en variabel er. I dette tilfellet er utdanning antall år etter obligatorisk skolenivå, så det er egentlig en kontinuerlig variabel selv om antall verdier er få. Vi kan velge å presisere at denne er av typen continuous. Nedenfor presiserer vi også at female er kategorisk, dichotomous, selv om denne ble presentert riktig uansett. Vi bruker argumentet type = og flere variable må oppgis innenfor list().\nEn siste ting vi kan endre er å ikke rapportere NA. Det er ikke oppgitt timelønn for alle, så antall NA er rapportert for seg. Det kan være fint, men kan også hende vi ikke ønsker det. Nedenfor er det derfor også lagt til missing = \"no\".\n\ntheme_gtsummary_mean_sd()\nabu89 %>% \n  select(-io_nr) %>% \n  tbl_summary(label = list(female ~ \"Kjønn\", klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\", female ~ \"dichotomous\"), \n              missing = \"no\")\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 4,1271\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n90 (30)\n    År utdanning\n2.69 (2.56)\n    Alder\n40 (12)\n    Kjønn\n1,934 (47%)\n    Klasse\n\n        I Øvre serviceklasse\n328 (8.1%)\n        II Nedre serviceklasse\n1,181 (29%)\n        III Rutinefunksjonærer\n1,248 (31%)\n        V-VI Faglærte arbeidere\n648 (16%)\n        VIIa Ufaglærte arbeidere\n637 (16%)\n    Noen gang forfremmet\n\n        NEI\n2,568 (62%)\n        JA\n1,559 (38%)\n    Bedriftserfaring\n0.95 (0.91)\n    Privat sektor\n\n        Public\n1,602 (39%)\n        Private\n2,525 (61%)\n  \n  \n  \n    \n      1 Mean (SD); n (%)\n    \n  \n\n\n\n\nOfte vil vi ha en tabell som ikke bare viser univariat fordeling, men bi-variate, altså fordelt på to eller flere grupper. Det er f.eks. ganske vanlig å vise tabeller fordelt på kjønn. Det kan vi også gjøre her ved å legge til argumentet by = female. Nedenfor er det også forenklet argumentene for label = og type =. I slike tilfeller vil vi ofte ha totalen i tillegg til per gruppe, og det gjør vi ved å legge til funksjonen add_overall().\nFor de kontinuerlige variablene får vi ikke antallet som inngår i beregningene. Vi vil gjerne vise antall ikke-missing verdier - særlig fordi vi tok vekk NA som egen rad ovenfor. Dette gjør vi ved å legge til funksjonen add_n().\n\nabu89 %>% \n  select(-io_nr) %>% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %>% \n    tbl_summary(by = female, \n                label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %>% \n  add_overall() %>% \n  add_n()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N\n      Overall, N = 4,1271\n      Kvinner, N = 1,9341\n      Menn, N = 2,1931\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n3,759\n90 (30)\n79 (24)\n100 (32)\n    År utdanning\n4,127\n2.69 (2.56)\n2.38 (2.40)\n2.96 (2.66)\n    Alder\n4,127\n40 (12)\n40 (13)\n40 (12)\n    Klasse\n4,042\n\n\n\n        I Øvre serviceklasse\n\n328 (8.1%)\n74 (3.9%)\n254 (12%)\n        II Nedre serviceklasse\n\n1,181 (29%)\n555 (29%)\n626 (29%)\n        III Rutinefunksjonærer\n\n1,248 (31%)\n986 (52%)\n262 (12%)\n        V-VI Faglærte arbeidere\n\n648 (16%)\n46 (2.4%)\n602 (28%)\n        VIIa Ufaglærte arbeidere\n\n637 (16%)\n244 (13%)\n393 (18%)\n    Noen gang forfremmet\n4,127\n\n\n\n        NEI\n\n2,568 (62%)\n1,308 (68%)\n1,260 (57%)\n        JA\n\n1,559 (38%)\n626 (32%)\n933 (43%)\n    Bedriftserfaring\n4,127\n0.95 (0.91)\n0.83 (0.81)\n1.05 (0.97)\n    Privat sektor\n4,127\n\n\n\n        Public\n\n1,602 (39%)\n1,016 (53%)\n586 (27%)\n        Private\n\n2,525 (61%)\n918 (47%)\n1,607 (73%)\n  \n  \n  \n    \n      1 Mean (SD); n (%)\n    \n  \n\n\n\n\nMen vi kan lage mer kompliserte tabeller også. La oss si at vi ønsker å lage den samme tabellen som over, men fordelt på to grupper. Det kan være relevant å sammenligne offentlig og privat sektor. En mulighet er å lage en ny grupperingsvariabel ved å slå sammen kjønn og sektor slik at vi får fire kategorier. Men vi får et bedre resultat ved å lage en stratifisert tabell med funksjonen tbl_strata(). Det er litt kryptisk syntaks, men det viktige er å angi hvilken variabel det skal stratifiseres etter med argumentet strata = etterfulgt av .tbl_fun = ~ .x %>%, så kommer tble_summary etter dette. Her er det også lagt til en ekstra header med antall observasjoner.\n\nabu89 %>% \n  select(-io_nr) %>% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %>% \n  tbl_strata(strata = private, \n             .tbl_fun = \n               ~ .x %>%\n               tbl_summary(by = female, \n              label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %>%\n               add_n(),\n    .header = \"**{strata}**, N = {n}\"\n    )\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      \n        Public, N = 1602\n      \n      \n        Private, N = 2525\n      \n    \n    \n      N\n      Kvinner, N = 1,0161\n      Menn, N = 5861\n      N\n      Kvinner, N = 9181\n      Menn, N = 1,6071\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n1,403\n82 (23)\n100 (28)\n2,356\n76 (24)\n100 (33)\n    År utdanning\n1,602\n2.88 (2.67)\n4.22 (3.12)\n2,525\n1.82 (1.92)\n2.50 (2.31)\n    Alder\n1,602\n42 (12)\n43 (11)\n2,525\n37 (13)\n39 (12)\n    Klasse\n1,592\n\n\n2,450\n\n\n        I Øvre serviceklasse\n\n55 (5.4%)\n150 (26%)\n\n19 (2.1%)\n104 (6.7%)\n        II Nedre serviceklasse\n\n340 (34%)\n196 (34%)\n\n215 (24%)\n430 (28%)\n        III Rutinefunksjonærer\n\n507 (50%)\n64 (11%)\n\n479 (54%)\n198 (13%)\n        V-VI Faglærte arbeidere\n\n5 (0.5%)\n114 (20%)\n\n41 (4.6%)\n488 (31%)\n        VIIa Ufaglærte arbeidere\n\n104 (10%)\n57 (9.8%)\n\n140 (16%)\n336 (22%)\n    Noen gang forfremmet\n1,602\n\n\n2,525\n\n\n        NEI\n\n696 (69%)\n318 (54%)\n\n612 (67%)\n942 (59%)\n        JA\n\n320 (31%)\n268 (46%)\n\n306 (33%)\n665 (41%)\n    Bedriftserfaring\n1,602\n0.93 (0.85)\n1.15 (0.94)\n2,525\n0.72 (0.74)\n1.01 (0.98)\n  \n  \n  \n    \n      1 Mean (SD); n (%)\n    \n  \n\n\n\n\nDet går også an å lage langt mer avanserte tabeller enn dette, og alle deler kan modifiseres. Men vi går ikke inn på dette her. Ved behov finner du instruksjoner på pakkens hjemmeside.\n\n7.2.1 Eksport av tabeller\nDu skal aldri bruke “klipp og lim” for å få en tabell over i et tekstbehandlingsprogram. Trikset er å konvertere tabellen til gt-format som har en eksportfunksjon til MS Word.\nFørst lagres tabellen i et eget objekt.\n\nfintabell <- abu89 %>% \n  select(-io_nr) %>% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %>% \n  tbl_strata(strata = private, \n             .tbl_fun = \n               ~ .x %>%\n               tbl_summary(by = female, \n              label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %>%\n               add_n(),\n    .header = \"**{strata}**, N = {n}\"\n    )\n\nSå kan tabellen eksporteres til Word, og evt. redigeres videre der hvis det trengs. På dette nivået kan det være mer tidsbesparende å gjøre siste justeringer i Word fremfor å lære alle triks for å lage tabellen fiks ferdig i R. (Skal du lage mange tabeller kan det likevel lønne seg å gjøre mest mulig i R).\n\nfintabell %>% \n  as_gt() %>% \n  gt::gtsave(filename = \"output/fintabell.docx\")\n\nMerk at eksport til docx-formatet krever at du har en relativt ny installasjon av pakkene {gt} og {gtsummary}. Filhalen “.docx” innebærer at filen lagres i dette formatet. Tilsvarende kan du lagre i .html, .pdf, .rtf, .png, .tex eller .ltex bare ved å endre filhalen.\nEn tilsvarende variant som noen av dere har lært på sosgeo1120 er å bruke as_flextable og en tilsvarende eksportfunksjon. Det er selvsagt også helt ok. En tidligere versjon av {gt} kunne som sagt ikke eksportere til Word, så da var {flextable} beste løsning. Men pakken {flextable} har vist seg å være litt trøblete å installere på noen pc’er, så da er det bedre å bruke {gt}."
  },
  {
    "objectID": "deskriptive_tabeller.html#manuelle-tabeller",
    "href": "deskriptive_tabeller.html#manuelle-tabeller",
    "title": "7  Deskriptive tabeller",
    "section": "7.3 Manuelle tabeller",
    "text": "7.3 Manuelle tabeller\nNoen ganger trenger man å lage ganske spesifikke ting.\n\n7.3.1 For datasettet totalt\n\n\n7.3.2 Grupperte statistikker"
  },
  {
    "objectID": "deskriptive_tabeller.html#oppgaver",
    "href": "deskriptive_tabeller.html#oppgaver",
    "title": "7  Deskriptive tabeller",
    "section": "7.4 Oppgaver",
    "text": "7.4 Oppgaver\nSlå opp i boken R for data science hvis du står fast eller ikke skjønner hva koden betyr.\n\nExercise 7.1 Bruk datasettet abu89 og lag de samme tabellene som vist her, gjør noen endringer på kodene for å endre utseendet på tabellene. Det er et mål at du skal forstå hva hver enkelt kommando gjør.\n\n\nExercise 7.2 Last inn datasettet NorLAG i R. Velg noen variable som du selv tenker kan være informative å se nærmere på. Bruk de samme teknikkene på disse variablene."
  },
  {
    "objectID": "linearRegresjon.html#scatterplot",
    "href": "linearRegresjon.html#scatterplot",
    "title": "8  Regresjon: Sammenheng mellom variable",
    "section": "8.1 Scatterplot",
    "text": "8.1 Scatterplot\nBivariat regresjon beskriver sammenhengen mellom to variable. En naturlig start er å se på et scatterplot. Her er en figur som viser hvordan timelønn varierer med alder. I det nedenforstående er det brukt jitter og gjennomsiktig farge for å håndtere overplotting.\nI tillegg er det tegnet inn en linje som illustrerer trenden i gjennomsnittlig lønn med alder. Denne linjen skrår svakt oppover, som altså betyr at gjennomsnittlig lønn øker noe med alder. Vi ser med det blotte øyet at en rett linje ikke beskriver denne sammenhengen perfekt. Først og fremst er det en stor variasjon rundt denne linjen, så det er mye annet som påvirker lønna enn alder. Det er også verd å legge merke til at i de yngste aldersgruppene er lønna en god del lavere - og kanskje litt lavere i eldste aldersgrupper også. Så en rett linje er kanskje ikke optimalt i utgangspunktet. Fordelen med en rett linje er at vi kan si noe slikt som at “gjennosmsnittslønna øker med x antall kroner for hvert år eldre man blir”. Hvis linja er kurvlineær blir det litt mer komplisert. Så et første poeng er at en slik linje er en forenkling, og det er en tilsiktet forenkling.\n\nggplot(abu89, aes(x =age, y = time89))+\n  geom_jitter(alpha = .2)+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nDet er en viss tendens til at lønnen øker med alder, men det er ikke helt lett å si hvor mye. Poenget med lineær regresjon er å beskrive en gjennomsnittlig trend.\n\nggplot(abu89, aes(x =age, y = time89))+\n  geom_jitter(alpha = .2)+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nDenne trendlinja er hva vi vanligvis kaller regresjonslinje."
  },
  {
    "objectID": "linearRegresjon.html#regresjonslinja",
    "href": "linearRegresjon.html#regresjonslinja",
    "title": "8  Regresjon: Sammenheng mellom variable",
    "section": "8.2 Regresjonslinja",
    "text": "8.2 Regresjonslinja\nRegresjonslinja kan beskrives med et stigningstall, som sier hvor bratt linjen er. Substansielt sett betyr det hvor mye utfallsvariabelen (y-aksen) endres med økning i forklaringsvariabelen (x-aksen). I tillegg trenger vi også vite hvor høyt/lavt linjen ligger. 1. Til det bruker vi startpunktet for linjen, der hvor \\(x\\) har verdien 0. Dette må regnes ut, og det er akkurat dette estimering av lineær regresjon gir oss.\nUtregningen av regresjonslinja går vi ikke inn på her, men intuitivt sett ønsker vi jo den beste linja og ikke en hvilken som helst omtrentlig linje. Datapunktene (de svarte punktene i grafen) er spredt rundt linja, og avstanden mellom linje og punkt kalles residualer. Summen av disse residualene er grunnlaget for mål på hvor godt regresjonslinja beskriver de faktiske dataene. Den beste linja er definert som den som minimerer residualene. Det er dette som kalles “minste kvadraters metode”.\nI R estimeres regresjonsmodeller med funksjonen lm. Første argument er en formel på formen utfallsvariabel ~ forklaringsvariabel. Rekkefølgen variablene oppgis i er altså viktig. Dernest må det spesifiseres hvilket datasett som skal brukes med data =. 2.\nLegg alltid resultatene i et eget objekt med et navnt som er rimelig enkelt å forstå hva er. I følgende kode legges resultatet i en nytt objekt lm_est1. Deretter bruker kan man hente ut de delene av resultatet vi er interessert i. I aller første omgang er bare interessert i regresjonslinjas konstantledd (startpunktet) og stigningstall. Disse kaller vi vanligvis regresjonskoeffisienter. Det kan vi få ut ved å bruke funksjonen coef.\n\nlibrary(equatiomatic)\n\nlm_est1 <- lm(time89 ~ age, data = abu89)\nsummary(lm_est1)\n\n\nCall:\nlm(formula = time89 ~ age, data = abu89)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-69.287 -19.131  -6.304  12.864 255.258 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 71.11019    1.62232   43.83   <2e-16 ***\nage          0.48284    0.03926   12.30   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 29.73 on 3757 degrees of freedom\n  (368 observations deleted due to missingness)\nMultiple R-squared:  0.0387,    Adjusted R-squared:  0.03844 \nF-statistic: 151.2 on 1 and 3757 DF,  p-value: < 2.2e-16\n\ncoef(lm_est1)\n\n(Intercept)         age \n 71.1101883   0.4828415 \n\n\nRegresjonslingningen kan skrives på formel der \\(\\alpha\\) er konstantleddet og \\(\\beta\\) er stigningstallet slik:\n\nextract_eq(lm_est1, use_coefs = FALSE)\n\n\\[\n\\operatorname{time89} = \\alpha + \\beta_{1}(\\operatorname{age}) + \\epsilon\n\\]\n\n\nNår vi setter inn de estimerte koeffisientene inn i ligningen får vi følgende:\n\nextract_eq(lm_est1, use_coefs = TRUE)\n\n\\[\n\\operatorname{\\widehat{time89}} = 71.11 + 0.48(\\operatorname{age})\n\\]\n\n\nTolkningen her er at gjennomsnittlig forskjell i timelønn mellom grupper der aldersforskjellen er ett år er 0.48 kroner i favør av den eldre gruppen.3 Merk enheten her: stigningstallet tolkes på den skalaen utfallsvariabelen er på, i dette tilfellet kroner. Det er også uttrykt endring ved at forklaringsvariabelen endres med nøyaktig 1.\nVi sier gjerne at regresjonslinjen er estimert, og det innebærer at det er usikkerhet i estimatene. Vi kommer tilbake til dette, men en vanligere output fra regresjonsmodeller er å bruker summary som følger:\n\nsummary(lm_est1)\n\n\nCall:\nlm(formula = time89 ~ age, data = abu89)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-69.287 -19.131  -6.304  12.864 255.258 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 71.11019    1.62232   43.83   <2e-16 ***\nage          0.48284    0.03926   12.30   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 29.73 on 3757 degrees of freedom\n  (368 observations deleted due to missingness)\nMultiple R-squared:  0.0387,    Adjusted R-squared:  0.03844 \nF-statistic: 151.2 on 1 and 3757 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "linearRegresjon.html#dummy-variable",
    "href": "linearRegresjon.html#dummy-variable",
    "title": "8  Regresjon: Sammenheng mellom variable",
    "section": "8.3 Dummy-variable",
    "text": "8.3 Dummy-variable\nHvis en forklaringsvariabel har kun to verdier vil vi typisk gi den ene kategorien verdien 0 og den andre kategorien 1. Dette kalles en «dummy variabel» eller en «indikator variabel». For eksempel vil et datasett ofte ha en variabel for kjønn med verdiene «Mann» og «Kvinne». Da kan vi la mann få verdien 0 og kvinne verdien 1. Ofte vil man da gi variabelen et navn som indikerer hvilken verdi som er 1. Så i dette eksempelet er det hensiktsmessig å gi den nye variabelen navnet «Kvinne». I dette eksempelet vil man også kunne si at variabelen er en «dummy for kvinne» (altså: den kategorien som får verdien 1).\nDet spiller ingen rolle hvilken kategori som får verdien 0 og 1. I dette eksempelet kunne man like gjerne gjort det motsatt, og latt det være en «dummy for mann». Da ville det være naturlig å kalle variabelen «mann» i stedet for «kvinne». Som vi skal se nedenfor vil det bare påvirke fortegnet når vi bruker variabelen i en regresjonsanalyse.\nI datasettet abu89 er variabelen “female” en slik variabel som har verdiene 0 eller 1, og der 0 betyr “mann” og 1 betyr “kvinne”.\n\n\n\nKjønn\nFemale\n\n\n\n\nMann\n0\n\n\nKvinne\n1\n\n\nKvinne\n1\n\n\nMann\n0\n\n\nKvinne\n1\n\n\nKvinne\n1\n\n\nKvinne\n1\n\n\nMann\n0\n\n\n\nI R vil vi ofte ha slike variable som factor-variable. Da er variabelen definert som kategorisk og selv om det er tekst-verdier i variabelen, så vil R automatisk behandle den som om verdiene var 0 og 1 i estimeringen av regresjonsmodellen.\n\ntheme_gtsummary_mean_sd()\nabu89 %>% \n  select(female, time89) %>% \n  tbl_summary(by = female) \n\n\n\n\n\n  \n    \n    \n      Characteristic\n      0, N = 2,1931\n      1, N = 1,9341\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n100 (32)\n79 (24)\n        Unknown\n190\n178\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\nVi ser altså at menn hadde i gjennomsnitt høyere timelønn enn kvinner, nærmere bestemt 21 kroner mer. Dette kan vi også undersøke med lineær regresjon som følger:\n\nlm_est_i <- lm(time89 ~ female , data = abu89)\n\ncoef(lm_est_i)\n\n(Intercept)      female \n   99.84382   -20.75229 \n\n\nRegresjonskoeffisenten for variabelen female uttrykker nettopp differansen mellom menn og kvinner, som er 21 kroner. Husk at \\(\\beta\\) er hvor mye \\(y\\)-variabelen endres når man sammenligner \\(x\\)-variabelen med akkurat 1 enhets forskjell. Her er mann 0 og kvinner 1, så da er dette faktisk 1 enhets forskjell. Altså: når \\(x\\) går fra 0 til 1, så reduseres \\(y\\) med 21. Derfor negativt fortegn.\nI R vil vi ofte gjøre om kategoriske variable til såkalte factor-variable. En factor-variabel vil håndtere kategoriske variable som tekst, men med en underliggende numerisk verdi. Da kan man bruke factor-variable i alle standard analysemetoder. I regresjon vil R automatisk bruke den første kategorien som referansekategori.\nVi kan gjøre den samme analysen med kjønn som en factor variabel og få de samme resultatene som ovenefor.\n\nabu89 <- abu89 %>%\n  mutate(sex = factor(ifelse(female == 1, \"Female\", \"Male\"), levels = c(\"Male\", \"Female\"))) %>% \n  filter(!is.na(time89))\n\nlm_est2 <- lm(time89 ~ female , data = abu89)\n\ncoef(lm_est2)\n\n(Intercept)      female \n   99.84382   -20.75229 \n\n\n\n8.3.1 Dummy-variable med mer enn en kategori\nNoen ganger har vi forklaringsvariable med flere enn to kategorier. Det kan vi løse på en tilsvarende måte ved å lage flere dummy-variable. Et eksempel kan være sosial klasse. I datasettet abu89 er det fem kategorier.\nEn dummy-variabel har bare to kategorier: 0 og 1, men vi kan lage flere dummy-variable. Vi kan lager en ny variabel «klasse II» som har verdien 1 hvis personen tilhører denne klassen og 0 ellers. Altså en dummy. Så kan vi lage en ny variabel «Klasse III» som har verdien 1 hvis personen tilhører denne klassen og 0 ellers. Slik kan man lage en dummy-variabel for hver av kategoriene. Da har vi altså flere dummy-variable som til sammen fanger opp informasjonen i den opprinnelige variabelen.\n\n\n\nUtdanning\nKlasse II\nKlasse III\nKlasse V-VI\nKlasse VII\n\n\n\n\nKlasse I\n0\n0\n0\n0\n\n\nKlasse II\n1\n0\n0\n0\n\n\nKlasse III\n0\n1\n0\n0\n\n\nKlasse V-VI\n0\n0\n1\n0\n\n\nKlasse VII\n0\n0\n0\n1\n\n\n\nMerk at her er det ingen dummy for “Klasse I”. Denne gruppen brukes som referansekategori slik at estimatene for de andre dummyene blir tolkbare som forskjellen til denne referansekategorien. Mer om det siden, men man kan velge å bruke en annen referansekategori hvis man vil.\nLa oss først se på et plot. Her er det brukt en jitter-plot. Den røde linjen viser endring i gjennomsnitt mellom de kategoriene. En regresjonsanalyse vil gi slike estimater på differanser, men det er enklest hvis alle endringene er i forhold til samme referansekategori.\n\n\n\n\nggplot( abu89x, aes(x =klasse89, y = time89))+\n  geom_jitter(alpha = .3, width = .2)+\n  geom_point(aes(y=gr_snitt), col = \"red\", size = 3)+\n  #geom_hline(yintercept = mean(abu89x$time89, na.rm = TRUE))+\n  geom_line(aes(x = as.numeric(klasse89), y = smooth), col = \"red\", linewidth = 1) \n\n\n\n\nDen generelle regresjonsligningen skrives som \\(y=a+bx\\), der \\(x\\) er forklaringsvariabelen. Regresjonskoeffisienten, \\(b\\), tolkes som hvor forskjellen i gjennomsnittet på utfallsvariabelen, \\(y\\), mellom de som er en enhets forskjell på \\(x\\)-variabelen.\n\nlm(time89 ~ klasse89, data = abu89) %>% \n  summary()\n\n\nCall:\nlm(formula = time89 ~ klasse89, data = abu89)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-78.908 -15.460  -4.601  10.026 225.351 \n\nCoefficients:\n                                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                       118.399      1.575  75.176  < 2e-16 ***\nklasse89II Nedre serviceklasse    -14.491      1.782  -8.133 5.65e-16 ***\nklasse89III Rutinefunksjonærer    -42.898      1.765 -24.300  < 2e-16 ***\nklasse89V-VI Faglærte arbeidere   -29.688      1.917 -15.489  < 2e-16 ***\nklasse89VIIa Ufaglærte arbeidere  -36.952      1.921 -19.232  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 26.91 on 3675 degrees of freedom\n  (79 observations deleted due to missingness)\nMultiple R-squared:  0.2133,    Adjusted R-squared:  0.2124 \nF-statistic: 249.1 on 4 and 3675 DF,  p-value: < 2.2e-16\n\n\nHvert estimat for kategori for klasse sammenlignes med den første kategorien (altså den som mangler): klasse I. Det betyr at klasse VII (ufaglærte arbeidere) har en timelønn på 37 kroner mindre enn klasse I (øvre serviceklasse). Mens klasse II (nedre serviceklasse) tjener 14 kroner mindre enn klasse I.\nForskjellen mellom andre grupper er således differansen mellom disse estimatene. Altså: klasse VII tjener mindre enn klasse V-VI: \\(36.9 - 29.7 = 7.2\\) kroner. Se på plottet over, så ser du at disse tallene ser riktige ut."
  },
  {
    "objectID": "linearRegresjon.html#flere-variable",
    "href": "linearRegresjon.html#flere-variable",
    "title": "8  Regresjon: Sammenheng mellom variable",
    "section": "8.4 Flere variable",
    "text": "8.4 Flere variable\nDet er ikke så ofte vi bruker regresjon med bare en forklaringsvariabel, såklat “enkel lineær regresjon”.4 Langt mer vanlig er å bruke flere variable samtidig i det vi kaller “multippel regresjon”.5 I multippel regresjon kan man altså beskrive mer kompliserte mønstre i dataene.\nVi fortsetter med eksempelet om lønn og alder, men utvider med en dimensjon til, nemlig kjønn. La oss først se på kjønnsforskjellene i gjennomsnittlig timelønn.\n\nabu89 <- abu89 %>%\n  mutate(sex = factor(ifelse(female == 1, \"Female\", \"Male\"), levels = c(\"Male\", \"Female\"))) %>% \n  filter(!is.na(time89))\n\nabu89 %>% \n  select(sex, time89) %>% \n  tbl_summary(by = sex) \n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Male, N = 2,0031\n      Female, N = 1,7561\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n100 (32)\n79 (24)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\nVi ser altså at menn hadde i gjennomsnitt høyere timelønn enn kvinner, nærmere bestemt 21 kroner mer. Dette kan vi også undersøke med lineær regresjon som følger:\n\nlm_est2 <- lm(time89 ~ sex , data = abu89)\n\ncoef(lm_est2)\n\n(Intercept)   sexFemale \n   99.84382   -20.75229 \n\n\nDet er altså slik at koeffisienten, \\(\\beta\\), gir den samme differansen som en enkel sammenligning av to gjennomsnitt.\nVi har allerede sett på alder og lønn, så vi kan utvide dette til å inkludere kjønn samtidig i et scatterplot.\nGrafisk er det da greit å bruke farger og slik vise for menn og kvinner for seg. I ggplot spesifiseres da group = sex og at fargene skal settes etter sammen grupperingen col = sex slik:\n\nggplot(abu89, aes(x = age, y = time89, group = sex, col = sex)) +\n  geom_jitter(alpha = .4)\n\n\n\n\n\nlm_est3 <- lm(time89 ~ sex + age, data = abu89)\n\nsummary(lm_est3)\n\n\nCall:\nlm(formula = time89 ~ sex + age, data = abu89)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-72.37 -17.12  -4.90  10.99 247.94 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  81.10147    1.58497   51.17   <2e-16 ***\nsexFemale   -20.62511    0.91186  -22.62   <2e-16 ***\nage           0.47380    0.03684   12.86   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 27.89 on 3756 degrees of freedom\nMultiple R-squared:  0.1539,    Adjusted R-squared:  0.1535 \nF-statistic: 341.7 on 2 and 3756 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "linearRegresjon.html#pene-tabeller-og-eksport-til-fil",
    "href": "linearRegresjon.html#pene-tabeller-og-eksport-til-fil",
    "title": "8  Regresjon: Sammenheng mellom variable",
    "section": "8.5 Pene tabeller og eksport til fil",
    "text": "8.5 Pene tabeller og eksport til fil\nSlik resultatene ser ut med bruk av summary er forsåvidt fint, og du får den informasjonen du trenger. Men det er ikke særlig presentabelt som ferdig produkt i en analyse. Du trenger typisk to ting: 1) Samle flere regresjonsmodeller i samme tabell, og 2) gjøre tabellene penere og lettere å lese, og 3) eksportere til det tekstbehandlingsprogrammet du bruker, typisk Microsoft Word.\nR har en hel rekke funksjoner for dette. Det spiller ingen rolle hvilke funksjoner du bruker da det er noe smak og behag her, så det viktigste er at det fungerer rimelig greit for deg. Nedenfor presenteres tre pakker for dette formålet. Velg én av dem. Alle disse funksjonene håndterer svært mange typer modeller, gir gode muligheter for å ferdigstille tabellene fullstendig før eksport, og eksporterer til de formatene som er mest aktuelle. De har også mer avansert funksjonalitet som f.eks. å rapportere robuste standardfeil (av forskjellig type) i stedet for vanlige standardfeil (dette er pensum på SOS4020).\nVi vil som regel ha behov for å flytte resultatene over til et tekstbehandlingsprogram. En strategi som går ut på “klipp og lim” eller skjermbilde etc er uaktuelt og må unngås for nærmest enhver pris.6 Resultatene skal skrives til en fil på en effektiv måte. Det er en fordel om tabellene da ser ganske ok ut i utgangspunktet og du kan bruke samme prosedyre for å eksportere til flere typer format hvis behovet skulle melde seg. Det er jo MS Word som er viktigst for de fleste, mens de øvrige formatene nedenfor er for spesielt interessert - men noen av dere vil kanskje bli det på et senere tidspunkt. De viktigste formatene som er:\n\nMS Word - det vanligste tekstbehandlingsprogrammet som de aller fleste av dere bruker.\nrtf - rikt tekstformat. Er et enklere format som fungerer på tvers av de fleste programmer. Kan brukes i Word også.\nhtml - for websider\nlatex - for mer tekniske dokumenter, særlig hvis du har mye formler og stæsj\nMarkdown/Quarto - for dynamiske dokumenter med integrert R-kode og tekst, og kan eksportere ferdig dokument til alle ovennevnte formater7 Det som fungerer med Markdown fungerer også med Quarto for samme formål.\n\n\n8.5.1 Alt 1: Bruke modelsummary()\nEksporterer til bl.a. følgende formater: Word, rtf, html, latex, markdown\nFordel: Gir pene og oversiktlige tabeller med enkel kode, og relativt enkelt å modifisere videre. Eksporterer direkte til alle viktigste formater. Kan også lett integreres med andre eksterne verktøy, først og fremst “grammar of tables” i pakket {gt} Ulempe:\nHer er kode for en enkel tabell med to regresjonsmodeller som vist ovenfor. Merk at objektene med regresjonsresultatene må legges inni funksjonen list().\n\nlibrary(modelsummary)\nmodelsummary(list(lm_est2, lm_est3))\n\n\n\n \n  \n      \n     (1) \n      (2) \n  \n \n\n  \n    (Intercept) \n    99.844 \n    81.101 \n  \n  \n     \n    (0.637) \n    (1.585) \n  \n  \n    sexFemale \n    -20.752 \n    -20.625 \n  \n  \n     \n    (0.932) \n    (0.912) \n  \n  \n    age \n     \n    0.474 \n  \n  \n     \n     \n    (0.037) \n  \n  \n    Num.Obs. \n    3759 \n    3759 \n  \n  \n    R2 \n    0.117 \n    0.154 \n  \n  \n    R2 Adj. \n    0.116 \n    0.153 \n  \n  \n    AIC \n    35854.9 \n    35694.9 \n  \n  \n    BIC \n    35873.6 \n    35719.8 \n  \n  \n    Log.Lik. \n    -17924.434 \n    -17843.437 \n  \n  \n    F \n    496.278 \n    341.699 \n  \n  \n    RMSE \n    28.49 \n    27.88 \n  \n\n\n\n\n\nDenne tabellen inneholder mer enn du er interessert i. Nedre del av tabellen inneholder “goodness of fit” statistikker, altså mål på hvordan modellen passer til dataene. Det finnes mange slike, men ingen grunn til å gå seg vill i disse her. De kan fjernes med argumentet gof_omit = og så angis statistikkene med de navnene du ser i tabellen. Det skrives på en spesiell måte: som en tekststreng angitt med anførselstegn rundt, og | mellom hver. I koden nedenfor beholdes kun antall observasjoner, \\(r^2\\) og \\(F\\).8\nVi gjør et par andre justeringer samtidig for å demonstrere noe funksjonalitet. I stedet for å oppgi estimatet og standardfeil på forskjellig linje kan vi spesifisere å ha det på samme linje med argumentet estimate =. Merk at den statistikken du vil rapportere settes i parentes {…} og mellomrom og parentes er ellers som det står. Man har også andre valg, derav det vanligste i bruk er å angi p-verdier eller stjerner for å vise disse på en forenklet måte. Det angis ved {p.value} eller {stars} på tilsvarende måte.\nI stedet for standardfeil på egen linje er det her angitt konfidensintervall på neste linje. For konfidensintervall vil det som forvalg være 95%, men vi kan angi f.eks. 99% konfidensintervall i stedet ved conf_level =. Hvis man ikke vil ha noe på neste linje kan man angi statistic = NULL i stedet. Man kan også velge å sette inn p.value eller stars på denne linjen.\nMerk at utfallsvariabelen i modellene er timelønn i kroner. I forrige tabell ble estimatene gitt med tre desimaler. Det er i overkant mange desimaler. En desimal er mer passende og nedenfor endres dette med fmt =.\n\nmodelsummary(list(lm_est2, lm_est3), \n             fmt = 1,\n             estimate = \"{estimate} ({std.error})\",\n             statistic = 'conf.int', \n             conf_level = .99, \n             gof_omit = 'DF|Deviance|R2 Adj.|AIC|BIC|Log.Lik.|RMSE')\n\n\n\n \n  \n      \n     (1) \n      (2) \n  \n \n\n  \n    (Intercept) \n    99.8 (0.6) \n    81.1 (1.6) \n  \n  \n     \n    [98.2, 101.5] \n    [77.0, 85.2] \n  \n  \n    sexFemale \n    -20.8 (0.9) \n    -20.6 (0.9) \n  \n  \n     \n    [-23.2, -18.4] \n    [-23.0, -18.3] \n  \n  \n    age \n     \n    0.5 (0.0) \n  \n  \n     \n     \n    [0.4, 0.6] \n  \n  \n    Num.Obs. \n    3759 \n    3759 \n  \n  \n    R2 \n    0.117 \n    0.154 \n  \n  \n    F \n    496.278 \n    341.699 \n  \n\n\n\n\n\nTo siste ting å ta med her er å endre navn på variablene til noe mer presentabelt og eksportere til Word. Med argumentet coef_rename = angis variabelen slik den ser ut i output og spesifiserer hva du vil skal stå. Koden nedenfor viser eksempel.\nFor å eksportere til Word settes output = med filbane og filnavn, og der filhalen .docx angir Word format. Du kan eksportere til annet format ved å angi annen filhale f.eks. .rtf eller .html.\n\n#|echo: false\nmodelsummary(list(lm_est2, lm_est3), \n             fmt = 1,\n             estimate = \"{estimate} ({std.error})\",\n             statistic = 'conf.int', \n             conf_level = .99, \n             gof_omit = 'DF|Deviance|R2 Adj.|AIC|BIC|Log.Lik.|RMSE', \n             coef_rename = c(\"sexFemale\" = \"Kvinne\", \n                                   \"age\" = \"Alder\", \n                                  \"(Intercept)\" = \"Konstant\")) \n\n\n\n \n  \n      \n     (1) \n      (2) \n  \n \n\n  \n    Konstant \n    99.8 (0.6) \n    81.1 (1.6) \n  \n  \n     \n    [98.2, 101.5] \n    [77.0, 85.2] \n  \n  \n    Kvinne \n    -20.8 (0.9) \n    -20.6 (0.9) \n  \n  \n     \n    [-23.2, -18.4] \n    [-23.0, -18.3] \n  \n  \n    Alder \n     \n    0.5 (0.0) \n  \n  \n     \n     \n    [0.4, 0.6] \n  \n  \n    Num.Obs. \n    3759 \n    3759 \n  \n  \n    R2 \n    0.117 \n    0.154 \n  \n  \n    F \n    496.278 \n    341.699 \n  \n\n\n\n\n\n\nmodelsummary(list(lm_est2, lm_est3), \n             fmt = 1,\n             estimate = \"{estimate} ({std.error})\",\n             statistic = 'conf.int', \n             conf_level = .99, \n             gof_omit = 'DF|Deviance|R2 Adj.|AIC|BIC|Log.Lik.|RMSE', \n             coef_rename = c(\"sexFemale\" = \"Kvinne\", \n                                   \"age\" = \"Alder\", \n                                  \"(Intercept)\" = \"Konstant\"), \n             output = \"output/reg_table.docx\")\n\nMerk at Word vil vise tabellen med de fonter etc som er forvalgt for Word. Dette kan du endre i Word etterpå. Det er en rekke funksjoner i Word for å formattere tabeller som du kan bruke.\nPakken {modelsummary} har også en rekke andre funksjoner for å redigere tabeller som du kan utforske ved behov. For avanserte brukere kan man også gjøre om tabellen til et gt-objekt og redigere videre med pakken {gt} eller tilsvarende med pakken {flextable}. Det er altså tilnærmet uendelige muligheter for avanserte tabeller. Dette går imidlertid langt utenfor hva de fleste av dere vil trenge. {modelsummary} har egen hjemmeside med mer detaljer og instruksjoner.\n\n\n8.5.2 Alt 2: Bruke {stargazer}\nMange R-brukere foretrekker pakken {stargazer}. Dette er en noe eldre funksjon og er derfor godt etablert.\nEksporterer til bl.a. følgende formater: rtf, html, latex, markdown\nFordel: Er en stand-alone pakke men gir enkelt veldig fine tabeller som antakeligvis er det du trenger Ulempe: Eksport til Word er ikke den beste, men god nok.\nStargazer lager tabeller i kun tre formater: latex, html, og ren tekst. Vi velger derfor type = \"text\" for at det skal se ok ut her.\n\nlibrary(stargazer)\nstargazer(lm_est2, lm_est3, type = \"text\")\n\n\n=======================================================================\n                                    Dependent variable:                \n                    ---------------------------------------------------\n                                          time89                       \n                               (1)                       (2)           \n-----------------------------------------------------------------------\nsexFemale                  -20.752***                -20.625***        \n                             (0.932)                   (0.912)         \n                                                                       \nage                                                   0.474***         \n                                                       (0.037)         \n                                                                       \nConstant                    99.844***                 81.101***        \n                             (0.637)                   (1.585)         \n                                                                       \n-----------------------------------------------------------------------\nObservations                  3,759                     3,759          \nR2                            0.117                     0.154          \nAdjusted R2                   0.116                     0.153          \nResidual Std. Error    28.495 (df = 3757)        27.891 (df = 3756)    \nF Statistic         496.278*** (df = 1; 3757) 341.699*** (df = 2; 3756)\n=======================================================================\nNote:                                       *p<0.1; **p<0.05; ***p<0.01\n\n\nVi kan modifisere tabellen tilsvarende som vi gjorde med {modelsummary}. Forklaringer av de enkelte argumenter finnes i manualen for stargazer.\ncovariate.labels = Angir teksten for variabelnavn. Merk at det oppgis i den rekkefølgen det skal stå, så være veldig nøye hvis du har mange variable! report = angir hva som skal inngå i tabellen, der hver bokstav viser til spesifikke deler: v = variabelnavn, c = koeffisient/estimat, s = standardfeil. single.row = setter statistikkene på samme linje fremfor under hverandre. keep.stat = angir hvilke “model fit statistics” som skal rapporteres. Hvis du skriver “all” her får du en lang remse tilsvarende vi fikk med {modelsummary}. digits = angir antall desimaler\n\nstargazer(lm_est2, lm_est3, \n          type = \"text\", \n          covariate.labels = c(\"Kvinne\", \"Alder\", \"Konstant\"),\n          report = \"vcs\",\n          single.row = TRUE, \n          keep.stat = c(\"n\",\"rsq\", \"ser\"),\n          digits = 1)\n\n\n=====================================================\n                           Dependent variable:       \n                    ---------------------------------\n                                 time89              \n                          (1)              (2)       \n-----------------------------------------------------\nKvinne                -20.8 (0.9)      -20.6 (0.9)   \nAlder                                   0.5 (0.04)   \nKonstant               99.8 (0.6)       81.1 (1.6)   \n-----------------------------------------------------\nObservations             3,759            3,759      \nR2                        0.1              0.2       \nResidual Std. Error 28.5 (df = 3757) 27.9 (df = 3756)\n=====================================================\nNote:                     *p<0.1; **p<0.05; ***p<0.01\n\n\nFor å eksportere til Word kan man bruke rikt tekstformat (.rtf) eller html. rtf-formatet er som navnet tilsier ren tekst og selv om det ser greit ut, så er videre redigering i et tekstbehandlingsprogram krøkete. (Prøv og se selv). Bruk heller html fordi da beholdes tabell-strukturen. Du kan åpne html-tabeller fra Word og redigere videre der ved behov.\n\nstargazer(lm_est2, lm_est3, \n          type = \"text\",\n          covariate.labels = c(\"Kvinne\", \"Alder\", \"Konstant\"),\n          report = \"vcs\",\n          single.row = TRUE, \n          keep.stat = c(\"n\",\"rsq\", \"ser\"),\n          digits = 1, \n          out = \"output/reg_starg.html\")\n\nMer detaljer finner du i {stargazer} sin vignette.\n\n\n8.5.3 Alt 3: Bruke {gtsummary}\nVi har tidligere brukt {gtsummary} for å lage deskriptive tabeller, som er det pakken er best til. Men den kan også lage gode regresjonstabeller. Det er imidlertid en stor ulempe for nybegynnere i R: det er ganske krøkete å sette sammen flere regresjonsmodeller i en samlet tabell. Derfor er rådet å ikke bruke denne pakken med mindre du har veldig lyst til å prøve.\nFordel med å bruke denne pakken er at man slipper å lære enda en ny pakke og slik sett ha ett sett med konsistent syntaks. En mulighet er selvsagt å ikke lage tabellene så ferdig i R, men eksportere til Word og redigere ferdig der mer manuelt.\n{gtsummary} kan eksportere til følgende formater: Word, rtf, html, latex og markdown. Resultatene kan også lett integreres med andre funksjoner, først og fremst “grammar of tables” i pakket {gt} og {flextable} - altså for mer avanserte ting som vi ikke dekker her.\nPrinsippet er å lage hver tabell for seg og så slå dem sammen med tbl_merge etterpå. Det innebærer en del mer kode, rett og slett. I utgangspunktet virker det ganske greit, men det er alltid en del småting som krever litt mer.\nFølgende kode lager først en ryddig tabell for hver regresionsmodell og så kobler sammen disse to tabellene.\n\nlm_tab1 <- tbl_regression(lm_est2, intercept = T, \n                          estimate_fun = function(x) style_number(x, digits = 1),\n                          show_single_row = \"sex\",\n                          label = list(sex ~ \"Kvinne\")) %>% \n    add_glance_table(include = c(nobs, r.squared, sigma))\n                     \nlm_tab2 <- tbl_regression(lm_est3, intercept = T,\n                          estimate_fun = function(x) style_number(x, digits = 1), \n                          show_single_row = \"sex\",\n                          label = list(age ~ \"Alder\", sex ~ \"Kvinne\")) %>% \n    add_glance_table(include = c(nobs, r.squared, sigma)\n  )\n\n\ntbl_merge(tbls = list(lm_tab1, lm_tab2)) %>% \n  modify_table_body(\n    ~.x %>% \n      dplyr::arrange(\n        row_type == \"glance_statistic\", # sort glance table to bottom\n        var_label                       # sort by the variable label (a hidden column) \n      )\n  )\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      \n        Table 1\n      \n      \n        Table 2\n      \n    \n    \n      Beta\n      95% CI1\n      p-value\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n99.8\n98.6, 101.1\n<0.001\n81.1\n78.0, 84.2\n<0.001\n    Alder\n\n\n\n0.5\n0.4, 0.5\n<0.001\n    Kvinne\n-20.8\n-22.6, -18.9\n<0.001\n-20.6\n-22.4, -18.8\n<0.001\n    No. Obs.\n3,759\n\n\n3,759\n\n\n    R²\n0.117\n\n\n0.154\n\n\n    Sigma\n28.5\n\n\n27.9\n\n\n  \n  \n  \n    \n      1 CI = Confidence Interval"
  },
  {
    "objectID": "linearRegresjon_kat.html#dummy-som-utfallsvariabel",
    "href": "linearRegresjon_kat.html#dummy-som-utfallsvariabel",
    "title": "9  Lineær sannsynlighetsmodell",
    "section": "9.1 Dummy som utfallsvariabel",
    "text": "9.1 Dummy som utfallsvariabel\nI samfunnsvitenskapen er utfallsvariabelen ganske ofte kategorisk. I en regresjon vil vi behandle kategoriske variable dem som om de er tall på kontinuerlig akse, også der det typisk bare finnes to verdier: 0 og 1. Dette kalles en dummyvariabel eller en indikatorvariabel.\nNår man bruker kategoriske variable i en lineær regresjon er det derfor ikke egentlig noe nytt. Det som står i boken om kontinuerlige variable gjelder også for kategoriske variable (i hvert fall for alle praktiske formål som dekkes for dette kurset).\nHusk at tolkningen av regresjonskoeffisienten, \\(b\\), tolkes på den skalaen \\(y\\)-variabelen er på. Altså: hvis utfallsvariabelen er i kroner, så er tolkningen av \\(b\\) i måleenheten kroner. Hvis y-variabelen er i antall timer, så er tolkningen av \\(b\\) i antall timer, osv. Husk også at vi estimerer endring i gjennomsnitt.\nNår utfallsvariabelen er en dummy, så har den verdiene 0 eller 1. Da er gjennomsnittet det samme som en andel. For eksempel: hvis utfallet er om man er i jobb eller ikke, og koder å være i jobb som 1 og 0 ellers. Hvis man har 5 personer, derav 3 er i jobb får man så: \\(\\bar{y} = \\frac{(0+0+1+1+1)} {5} = \\frac{3}{5}=0.6\\) som er det samme som 60%.\nI regresjon med slike variable er dermed utfallet en andel og dette kalles derfor ofte en «lineær sannsynlighetsmodell». Men det er egentlig en helt vanlig regresjonsmodell. Vi tolker fremdeles på den skalaen y-variabelen er på, som altså er en andel. (Vi skal forresten senere omtale andeler som estimater på sannsynligheter). En økning i \\(x\\)-variabelen tilsvarer altså en endring, b, i andelen med den egenskapen som er kodet 1 på \\(y\\)-variabelen.\nLa oss si at vi er interessert i å beskrive kjønnsforskjell i hvorvidt menn og kvinner jobber i privat vs offentlig sektor. Variabelen “private” er en factor-variabel der første kategori er “public”, som da blir referansekategorien. R regner da privat sektor som 1 mens offentlig sektor er 0. Koeffisientene vil da uttrykke forskjell i sannsynlighet for å være i privat sektor.\n\nlm(private ~ female + ed + age, data = abu89)\n\n\nCall:\nlm(formula = private ~ female + ed + age, data = abu89)\n\nCoefficients:\n(Intercept)       female           ed          age  \n   2.167030    -0.287998    -0.049017    -0.007274  \n\n\nVi ser her at sannsynligheten for at kvinner jobber i privat sektor er 0.28 lavere enn for menn, dvs. 28 prosentpoeng lavere. Dette er da kontrollert for utdanning og alder, slik at vi kan se bort fra at utdanningsnivå og forskjell i aldersfordeling i dataene kan være grunnen til forskjellene."
  },
  {
    "objectID": "grunnleggendeDesign.html#tre-nivåer-av-regresjonanalyse",
    "href": "grunnleggendeDesign.html#tre-nivåer-av-regresjonanalyse",
    "title": "10  Design og tolkning",
    "section": "10.1 Tre nivåer av regresjonanalyse",
    "text": "10.1 Tre nivåer av regresjonanalyse\nRichard Berk beskriver i sin lærebok tre nivåer av regresjonsanalyse basert på hvordan dataene ble til. Dette er et godt utgangspunkt som burde klargjøre betydelig, i hvert fall som et først skritt.\n\n10.1.1 Nivå I: Ikke tilfeldig utvalg fra en veldefinert populasjon\nGrunnlaget for statistisk tolkning (sannsynligheter, p-verdier og sånn) er at dataene er en tilfeldig realisering av en underliggende sann verdi. Typisk betyr dette bare at man har trukket et tilfeldig utvalg fra en populasjon. Da vil man få et godt mål på f.eks. gjennomsnittsverdi i populasjonen, men på grunn av tilfeldighet vil det være en feilmargin på denne målingen.\nDet avgjørende er altså at det finnes en veldefinert populasjon som det kan generaliseres til. Grunnen til å bruke begrepet veldefinert er at det må være rimelig spesifisert.\nHvis dataene ikke er fra en veldefinert populasjon kalles dette noen ganger for convenience sample. Altså, at man gjorde et uttrekk av beleilighetsgrunner, men uten at det var en veldefinert populasjon.\nEt eksempel kan være en arbeidsmiljøundersøkelse i en bestemt bedrift. Det skal litt til at disse resultatene skal gjelde utover denne bedriften. Man kan selvsagt argumentere for at erfaringene gjelder med generelt, men en slik slutning vil da hvile først og fremst på disse argumentene - ikke på statistiske utregninger.\nDet kan være veldig nyttig å analysere slike data, og det kan bringe innsikt og kunnskaper. Men med slike data gir det ikke mye mening å regne på statistisk usikkerhet. Hvis man ikke skal si noe utover de dataene man har (ikke generalisere), så er det heller ikke denne typen usikkerhet i målingene.\nSlike ikke-tilfeldige utvalg kan betraktes nærmest som case-studier. En dataanalyse vil gi oss kunnskaper om de erfaringene som gjøre akkurat der. Størrelsen på datasettet kan gi oss mer pålitelig informasjon om dette caset, men hjelper ikke for å generalisere utover caset.\n\n\n10.1.2 Nivå II: Tilfeldig utvalg fra en veldefinert populasjon\nTilfeldig utvalg er akkurat det det høres ut som, og er den foretrukne metoden for alle surveyundersøkelser. Teorien bak er at utvalget vil gjenspeile populasjonen, og avvik fra “de sanne verdiene” skyldes tilfeldigheter. Disse tilfeldighetene er grunnlaget for statistisk tolkning ved at vi kan si noe om samplingfordelingen (se annet kapittel) og dermed har grunnlag for å regne på standardfeil og p-verdier osv. Med andre ord: generalisering til populasjonen.\nSå er det viktig å påpeke at forutsetningen her er at det må være et utvalg fra en veldefinert populasjon. Hvis vi ikke vet hvem resultatene generaliserer til, så blir det jo tullete, og vi er egentlig på nivå 1.\n\n\n10.1.3 Nivå III: Estimering av kausale effekter\nFra et teknisk perspektiv er det ingenting som skiller studier av eksperimenter fra observasjonsstudier. De samme regresjonsmodellene kan estimeres og de samme utregningene av usikkerhet. Hva som bestemmer tolknigen (og hvorvidt modellspesifikasjonen er rimelig etc) avhenger av forskningsdesignet. Kort sagt kreves det et eksperiment. Hvis man har en treatment-gruppe og en kontrollgruppe, så vil \\(\\beta\\) beskrive forskjellen mellom disse gruppene som i andre typer data. Det som gir \\(\\beta\\) en kausal tolkning er om dataene tilfredsstiller kravene til et eksperiment.\nVi kan også regne inn kvasi-eksperimentelle studier eller naturlige eksperimenter her. Enten er disse studiene gode nok til å kvalifisere til å tolke som kausaleffekter - eller så er de det ikke, men da hører de hjemme på nivå II.\n\n\n10.1.4 Mot et nivå IV?\nI Berk sin fremstilling av de tre nivåene får man en følelse av at den vitenskapelige verdien øker ved hvert nivå. Mange vil da også mene akkurat det. Men logisk sett er det litt mer tvetydig enn som så.\nVi har snakket om to dimensjoner: kausalitet (ja/nei) og generalisering (ja/nei). Dette gir fire logisk mulige kombinasjoner.\n\n\n\nTable 10.1: Nivåer av regresjonsanalyse og hvor vanlige de er\n\n\n\n\n\n\n\n\nIkke tilfeldig utvalg fra veldefinert populasjon\nTilfeldig utvalg fra veldefinert populasjon\n\n\n\n\nDeskriptiv\nOverraskende mange\nDet aller meste\n\n\nKausal\nMye, men burde nok vært mer\nGanske sjelden\n\n\n\n\nJeg har ingen empiri for å si hvor vanlig hver enkelt type analyse er. Men jeg tror det nokså omtrentlige angivelsen i tabellen er ganske riktig, basert på egen erfaring fra studier jeg har lest og presentasjoner jeg har sett.\nI Berk sin fremstilling er Nivå III hele nederste rad, men da er det altså ikke gjort skille mellom om resultatene kan generaliseres videre eller ikke. Et slik skille bør man nok gjøre.\nEksperimenter omtales noen ganger - og i noen fagmiljøer - som gullstandarden. Men altså: ethvert eksperiment kan ikke være en gullstandard, ikke engang når formålet er å estimere kausaleffekter. Nivå IV er i så fall det vi ser etter, da nivå III har begrenset gyldighet. I tilsvarende ånd omtaler Berk eksperimenter som bronsestandarden, med den begrunnelse at det i praksis ikke er noe på palleplassene sølv og gull."
  },
  {
    "objectID": "grunnleggendeDesign.html#hva-er-poenget-her-egentlig",
    "href": "grunnleggendeDesign.html#hva-er-poenget-her-egentlig",
    "title": "10  Design og tolkning",
    "section": "10.2 Hva er poenget her, egentlig?",
    "text": "10.2 Hva er poenget her, egentlig?\nPoenget er at tolkning av resultatene handler vel så mye om hvordan dataene har blitt til som hvordan de er analysert. Hvis du har data på nivå I, så finnes det ingen statistiske krumspring du kan gjøre som løfter det til et annet nivå. Det samme gjelder nivå II og nivå III. Du kan fremdeles gjøre svært så nyttige og informative analyser på det nivået du har data på. De statistiske analyseteknikkene er det ellers ikke så stor forskjell på."
  },
  {
    "objectID": "grunnleggendeDesign.html#hva-med-sosiologisk-teori",
    "href": "grunnleggendeDesign.html#hva-med-sosiologisk-teori",
    "title": "10  Design og tolkning",
    "section": "10.3 Hva med sosiologisk teori?",
    "text": "10.3 Hva med sosiologisk teori?\nVi bruker kvantitative metoder til å beskrive statistiske sammenhenger. Men vi er jo ikke interessert i variablene som sådan. Poenget er å beskrive sosiale fenomener. Å si hva det betyr krever imidlertid en teoretisk tolkning. Å teste om et estimat er statistisk signifikant er ikke det samme som å teste en teori, selv om begge deler kan omtales med ordet “test”.\n\nGitt et fenomen (beskrevet med statistikk), hvordan kan vi forklare det?\nHva skjer med fenomenet vi er interessert i hvis vi gjør en intervensjon?\nGitt en teori, er observasjonsdata (dvs. statistikk) konsistent med teorien?\nGitt en teori, kan vi sjekke om observasjonsdata (dvs. statistikk) ikke er konsistent med teorien?\n\nDen første varianten handler om å først beskrive - gjerne eksplorerende - og så bruke teori til å forklare hvorfor det er slik. Det følger gjerne flere analyser som gjør beskrivelsen mer nyanserte og utforsker ulike muligheter.\nDen andre varianten handler om å måle effekter, gjerne et naturlig eksperiment eller et felteksperiment. Hvis man ønsker å vite hva effekten av et tiltak er, så må man endre noe slik at man kan observere resultatet. Randomisering handler om å håndtere seleksjon.\nDen tredje varianten er en konfirmerende strategi: En teori bør jo være konsistent med hvordan verden ser ut. Det er viktig å sjekke at dette er tilfellet. Hvis det er konsistent vet man jo det, men det er ikke en test av noe som helst fordi det kan jo være alternative teorier som forklarer minst like godt.\nDen fjerde varianten krever at teorien gir en empirisk forventning - helst som er motstridende med en annen teori. Hvis det kan vises empiriske mønster som er inkonsistente med teori, så må teorien enten forkastes eller i det minste justeres. Hvor mye vil være helt avhengig av den teoretiske påstanden.\nStatistiske tester, med p-verdier og konfidensintervaller, brukes til å skille mellom tilfeldig variasjon og systematisk variasjon på en tilsvarende måte for alle strategier."
  },
  {
    "objectID": "statistiskTolkning.html#tilfeldigheter-og-systematikk",
    "href": "statistiskTolkning.html#tilfeldigheter-og-systematikk",
    "title": "11  Statistisk tolkning",
    "section": "11.1 Tilfeldigheter og systematikk",
    "text": "11.1 Tilfeldigheter og systematikk\nStandardfeilen er ikke det samme som standardavviket, og det er viktig at du vet forskjellen på disse.\n\nStandardavvik: beskriver variasjonen rundt gjennomsnittet i utvalget, altså i dataene du har. Det er litt omtrentlig sagt et mål på hvor langt fra gjennomsnittet datapunktene ligger.\n\nStandardfeilen: beskriver en hypotetisk fordeling av hvordan man kan regne med at mulige estimater kan være fordelt rundt den sanne verdien. Denne fordelingen kalles en samplingfordeling og krever litt mer forklaring - men standardfeilen er estimatet på standardavviket i samplingfordelingen.\n\nHvis du synes at denne forklaringen ikke hjalp, så er det med god grunn. Det er nemlig vanskelig å forstå. Det har en begrunnelse i sannsynlighetsteori som vi ikke skal gå veldig i dypbden på her. Men du trenger å forstå hva samplingfordeling er, og så gir sentralgrenseteoremet det vi trenger for å regne ut slike ting som p-verdier og konfidensintervall.\n\n11.1.1 Samplingfordeling og sentralgrenseteoremet\n\n11.1.1.1 Samplingfordeling\n\n\n11.1.1.2 Sentralgrenseteoremet\n\n\n\n11.1.2 Standardfeil\nStandardfeilen uttrykker usikkerheten ved estimatet. La oss si at du ønsker å si noe om gjennomsnittet i populasjonen, men har bare data om et tilfeldig utvalg fra denne populasjonen. Når du da regner ut gjennomsnittet i utvalget er det din beste gjetning på hva gjennomsnittet er i populasjonen. En slik gjetning kaller vi et estimat. Standardfeilen til estimatet er et mål på usikkerheten ved målemetoden. Usikker målemetode gjør at feilen kan være større.\n\n\n11.1.3 Er man “95% sikker”?\nDet sies ofte at feilmarginen uttrykker hvor sikker man er. Det er jo ikke helt riktig - eller det er riktig under noen spesielle forutsetninger om hva man mener med “sikker”. La oss derfor ta dette med en gang og starter med konfidensintervallet.\nEt 95% konfidensintervall er vårt anslag på hvor god vår målemetode er. Vi har jo regnet ut f.eks. et gjennomsnitt og det er jo greit nok. Usikkerheten kommer fra utvalgsprosedyren og variasjonen i data.\nVi vet ikke hvorvidt vårt estimat ligger nærme eller langt unna den sanne verdien. Det vi derimot vet noe om er påliteligheten i den metoden vi har brukt. Det viktigste her er altså tilfeldig utvalg, og hvis utvalget ikke er tilnærmet tilfeldig trukket, så bryter det hele sammen.\nNår man sier at konfidensintervallet uttrykker at man er “95% sikker” på at den sanne verdien ligger i det intervallet mener man da følgende: Man har brukt en metode (dvs utvalg og utregninger og det hele) som har en feilmargin. Denne feilmarginen er slik at hvis man gjorde estimeringen (altså nytt utvalg hver gang) på samme måte svært mange ganger (f.eks. uendelig mange ganger), så ville 95% av resultatene ligget innenfor et slikt intervall."
  },
  {
    "objectID": "statistiskTolkning.html#konfidensintervaller",
    "href": "statistiskTolkning.html#konfidensintervaller",
    "title": "11  Statistisk tolkning",
    "section": "11.2 Konfidensintervaller",
    "text": "11.2 Konfidensintervaller"
  },
  {
    "objectID": "statistiskTolkning.html#t-test-og-p-verdier",
    "href": "statistiskTolkning.html#t-test-og-p-verdier",
    "title": "11  Statistisk tolkning",
    "section": "11.3 T-test og p-verdier",
    "text": "11.3 T-test og p-verdier\nT-testen er i prinsippet en sammenligning mellom estimatets størrelse og standardfeilen til estimatet.\n\\[\n\\frac{\\mu}{SE(\\mu)} = t\n\\]\nEller sagt på en annen måte: \\[\n\\frac{estimat}{standardfeil} = t\n\\]\nDet betyr at \\(t\\) uttrykker forholdstallet mellom estimatet og standardfeilen. Intuitivt kan man vel forstå at hvis usikkerheten bør være mindre enn estimatet. Men hvor mye mindre?\nFra samplingfordelingen og sentralgrenesteoremet ved vi jo at \\(1.96 \\times SE(\\mu)\\)\nTolkningen av p-verdien er i hvilken grad det er sannsynlig å få det observerte resultatet ved en tilfeldighet hvis NULL-hypotesen er riktig. Dette høres ganske pussig ut. Tanken er at man nesten alltid vil observere noe forskjell fra null, og det kan skje ved en tilfeldighet. Hvis null-hypotesen er riktig er det mindre sannsynlig at vi observerer en veldig stor forskjell. Men hvor stor forskjell er det, egentlig? Løsningen er å se avstanden fra null i lys av standardfeilen. Hvis man bruker en usikker målemetode, så er det mer sannsynlig å observere en stor forskjell ved tilfeldigheter enn om man bruker en veldig nøyaktig målemetode.\nI praksis: Tenk at du observerer en stor forskjell mellom to grupper. Med “stor” mener vi f.eks. at forskjellen er over dobbelt så stor som standardfeilen. Da får vi en p-verdi som er \\(p < 0.05\\). Da kan vi si at hvis nullhypotesen er sann, så er det lite sannsynlig at vi ville fått et slikt resultat på grunn av tilfeldigheter.^(Hvis vi ønsker være pinlig korrekte kan vi også si noe slikt som at hvis man gjorde målingen tusenvis av ganger, så ville 5% av resultatene ligge så langt unna null (eller lengre).)\nSå er logikken videre at vi som hovedregel ikke tror på resultater som er usannsynlige. Så i stedet for å holde fast på nullhypotesen velger vi i stedet å tro på den alternative hypotesen."
  },
  {
    "objectID": "statistiskTolkning.html#statistiske-tester-generelt",
    "href": "statistiskTolkning.html#statistiske-tester-generelt",
    "title": "11  Statistisk tolkning",
    "section": "11.4 Statistiske tester generelt",
    "text": "11.4 Statistiske tester generelt\nDet finnes en hel haug av statistiske tester. Prinsippet er gjerne variasjoner av t-testen og har disse komponentene:\n\nen nullhypotese og et alternativ\nen statistikk, altså et måltall som er et avstandsmål mellom observert resultat og hva man forventer under nullhypotesen\nen statistisk modell for samplingfordelingen som sier noe om fordelingen av tilfeldige feil\nen uttalt beslutningsregel for konklusjonen. Et vanlig mål er at hvis p < 0.05, så forkastes nullhypotesen."
  },
  {
    "objectID": "tidyverse.html#lage-ny-variabel-mutate",
    "href": "tidyverse.html#lage-ny-variabel-mutate",
    "title": "13  Datahåndtering med Tidyverse",
    "section": "13.1 Lage ny variabel: mutate",
    "text": "13.1 Lage ny variabel: mutate\nAlle verbene i tidyverse starter med å angi hvilket objekt man skal gjøre noe med, altså datasettet.\nHer er et eksempel der man lager en ny variable som summen av eksisterende variablene x og z.\n\nnyttobjekt <- mutate(dinedata, nyvariabel = x + z)\n\nHer er et eksempel der man lager to variable samtidig der den andre er x delt på z.\n\nnyttobjekt <- mutate(dinedata, nyvariabel = x / z,\n                     nyvariabel2 = x + z)"
  },
  {
    "objectID": "tidyverse.html#rørlegging-hva-i-alle-dager-betyr",
    "href": "tidyverse.html#rørlegging-hva-i-alle-dager-betyr",
    "title": "13  Datahåndtering med Tidyverse",
    "section": "13.2 Rørlegging: Hva i alle dager betyr %>% ??",
    "text": "13.2 Rørlegging: Hva i alle dager betyr %>% ??\nSymbolet %>% kalles in “pipe” eller på norsk: rørlegging. Det betyr at det som står til venstre flyttes over til høyre. Eller sagt på en annen måte betyr det: “Gjør deretter følgende”. Vi vil bruke denne syntaxen konsekvent fra nå når vi introduserer de ulike “verbene”.\n\nnyttobjekt <- dinedata %>% \n  mutate(nyvariabel = x / z,\n         nyvariabel2 = x + z)\n\nDenne koden sier følgende, linje for linje:\n\nlag en kopi av dinedata og lagre det i nyttobjekt ^deretter gjør du følgende:^\nlag de nye variablene nyvariabel som får verdier fra variablene x delt på y\nog nyvariabel2som summen av x og z"
  },
  {
    "objectID": "tidyverse.html#beholde-og-slette-variable-select",
    "href": "tidyverse.html#beholde-og-slette-variable-select",
    "title": "13  Datahåndtering med Tidyverse",
    "section": "13.3 Beholde og slette variable: select",
    "text": "13.3 Beholde og slette variable: select"
  },
  {
    "objectID": "tidyverse.html#aggregere-summarise",
    "href": "tidyverse.html#aggregere-summarise",
    "title": "13  Datahåndtering med Tidyverse",
    "section": "13.4 Aggregere: summarise",
    "text": "13.4 Aggregere: summarise"
  },
  {
    "objectID": "tidyverse.html#grupperte-utregninger-group_by",
    "href": "tidyverse.html#grupperte-utregninger-group_by",
    "title": "13  Datahåndtering med Tidyverse",
    "section": "13.5 Grupperte utregninger: group_by",
    "text": "13.5 Grupperte utregninger: group_by"
  },
  {
    "objectID": "tidyverse.html#sette-det-hele-sammen",
    "href": "tidyverse.html#sette-det-hele-sammen",
    "title": "13  Datahåndtering med Tidyverse",
    "section": "13.6 Sette det hele sammen",
    "text": "13.6 Sette det hele sammen"
  },
  {
    "objectID": "omkode_factor.html#endre-variabelnavn-med-rename-og-mutate",
    "href": "omkode_factor.html#endre-variabelnavn-med-rename-og-mutate",
    "title": "14  Omkoding av variable",
    "section": "14.1 Endre variabelnavn med rename og mutate",
    "text": "14.1 Endre variabelnavn med rename og mutate"
  },
  {
    "objectID": "omkode_factor.html#kontinuerlige-variable",
    "href": "omkode_factor.html#kontinuerlige-variable",
    "title": "14  Omkoding av variable",
    "section": "14.2 Kontinuerlige variable",
    "text": "14.2 Kontinuerlige variable\nÅ omkode kontinuerlige variable er i utgangspunktet det enkleste. Dette er tall og man kan gjøre normale regneoperasjoner på dem."
  },
  {
    "objectID": "omkode_factor.html#tekstvariable-strings",
    "href": "omkode_factor.html#tekstvariable-strings",
    "title": "14  Omkoding av variable",
    "section": "14.3 Tekstvariable (strings)",
    "text": "14.3 Tekstvariable (strings)"
  },
  {
    "objectID": "omkode_factor.html#factorvariable",
    "href": "omkode_factor.html#factorvariable",
    "title": "14  Omkoding av variable",
    "section": "14.4 Factorvariable",
    "text": "14.4 Factorvariable\nR har en egen variabeltype for kategoriske variable som kalles “factor”. I utgangspunktet er kategoriske variable mer å regne som tekstvariable enn som tall, men i en del beregninger vil softwaren bruke numeriske verdier uansett. Hvis man gjør om en tekst-variabel til en factor-variabel beholdes teksten, men kategoriene numeriske verdier 1, 2, 3, … osv. Disse tallene kan du tenke på som rekkefølgen på kategoriene. For kategoriske variable er det jo ikke noen egentlig rekkefølge, men det kan være grunner til å foretrekke rekkfølgen av andre grunner som vi kommer tilbake til.\nHvis variabelen er ordnet f.eks. på en skala fra 1 til 5 eller annen naturlig rekkefølge1, så kan man også angi dette.\n\n14.4.1 Få oversikt over factor-levels med levels()\n\n\n14.4.2 Enkel omkoding med fct_recode() og fct_collapse()\n\n\n14.4.3 Endre rekkefølgen på faktorene med fct_reorder()"
  },
  {
    "objectID": "omkode_factor.html#betinget-omkoding-med-ifelse-og-case_when",
    "href": "omkode_factor.html#betinget-omkoding-med-ifelse-og-case_when",
    "title": "14  Omkoding av variable",
    "section": "14.5 Betinget omkoding med ifelse() og case_when()",
    "text": "14.5 Betinget omkoding med ifelse() og case_when()\nDu kan lære mer om effektiv håndtering av kategoriske variable med forcats-pakken, som er en del av “tidyverse”."
  },
  {
    "objectID": "omkode_factor.html#factorvariable-med-skikkelig-lang-tekst",
    "href": "omkode_factor.html#factorvariable-med-skikkelig-lang-tekst",
    "title": "14  Omkoding av variable",
    "section": "14.6 Factorvariable med skikkelig lang tekst",
    "text": "14.6 Factorvariable med skikkelig lang tekst\n\nnorlag <- read_stata(\"data/norlag_panel2022.dta\") %>% \n    mutate(across( where(is.labelled) ,  ~replace(., \n                                        . %in% c(997, 998, 999, 99999, 999999), \n                                        NA))) %>%\n  # For hele datasettet fjernes ikke-brukte labler \n  drop_unused_value_labels() %>% \n  # Så gjør alle variable om til mer ordinære R-format. Dvs. gjøre labler om til factor\n  unlabelled()\n\nNoen ganger har man et datasett som allerede er omgjort med factor-variable. Eller du har en eller annen grunn til å ikke gå tilbake til et tidligere steg for å omkode. Men du har factor-levels med skikkelig lang tekst kan det være noe drit å kode om. Kan man gjøre dette på en lurere måte? Minst mulig tårer? Ja, selvsagt.\nI NorLAG er variabelen wr117zz svar på et spørsmål om “Mulighet for å redusert arbeidstid (deltid)”. Når denne variabelen er gjort om til factor kan man se hvilke verdier variabelen har med bruke av funksjonen levels() slik:\n\nlevels(norlag$wr117zz)\n\n[1] \"Nei\"                                                               \n[2] \"Ja\"                                                                \n[3] \"filter: jobber deltid\"                                             \n[4] \"filter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet)\"\n[5] \"filter: ikke i arbeid\"                                             \n\ntable(norlag$wr117zz)\n\n\n                                                               Nei \n                                                              1360 \n                                                                Ja \n                                                              4146 \n                                             filter: jobber deltid \n                                                              1964 \nfilter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet) \n                                                              1171 \n                                             filter: ikke i arbeid \n                                                              6238 \n\n\nLa oss si at vi vil kode om slik at vi får en variabel som bare er om vedkommende har mulighet til å jobbe deltid eller ikke. De som allerede jobber deltid har jo åpenbart mulighet til det, så de skal kodes om til “Ja”. De andre kategoriene er egentlig grunner til at det mangler data, så de skal settes til NA. En mulighet er da å omkode som følger:\n\nnorlag_omkodet <- norlag %>%\n  mutate(redarbtid = replace(wr117zz, wr117zz == \"filter: jobber deltid\", \"Ja\"), \n         redarbtid = replace(redarbtid, redarbtid == \"filter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet)\", NA), \n         redarbtid = replace(redarbtid, redarbtid == \"filter: ikke i arbeid\", NA), \n         redarbtid = replace(redarbtid, redarbtid == \"vil ikke svare\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"vet ikke\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"mangler data\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"Deltok ikke i runden\", NA)) %>% \n  droplevels()\n\nDette funker, men blir ganske mye tekst å skrive, og da kan man også lett gjøre skrivefeil. Husk at faktornivåene må angis helt nøyaktig slik de er skrevet! Merk at den siste funksjone, droplevels(), bare fjerner faktor-levels som ikke er i bruk.\nI output for faktor-levels angir klammeparentesen gir rekkefølgen på disse verdiene. Vi kan bruke denne informasjonen direkte i omkodingen for å unngå å skrive så veldig mye. Når man bruker levels() får man en liten vektor med verdier, og disse kan man altså henvise til med rekkefølgen. Her er et eksempel for bare å bytte ut de som jobber deltid til “Ja”:\n\nnorlag_omkodet <- norlag %>%\n  mutate(redarbtid = replace(wr117zz, wr117zz == levels(wr117zz)[3], \"Ja\")) %>% \n  droplevels()\n\nTrikset her er altså å bruke levels() og vise til hvilket nummer i rekkefølgen. Da unngår vi også faren for skrivefeil.\nVi vil også kode om alle de andre verdiene, nummer 4-9 til NA. Det kan vi gjøre på samme måte, men vi behøver ikke skrive en ny linje for hver verdi. Den logiske operatoren == kan man bruke når man skal sjekke om to verdier er like. Hvis vi skal se om en verdi er lik en av flere mulige kan vi bruke %in% og så en liste med verdier. levels() gir en liste med verdier, så da kan vi angi den direkte og alle verdiene 4 til 9 ved å skrive 4:9. Samlet blir det da slik:\n\nnorlag_omkodet <- norlag %>%\n  mutate(redarbtid = replace(wr117zz, wr117zz == levels(wr117zz)[3], \"Ja\"), \n         redarbtid = replace(redarbtid, redarbtid %in% levels(wr117zz)[4:9], NA)) %>% \n  droplevels()\n\nmemisc::codebook(norlag_omkodet$redarbtid)\n\n================================================================================\n\n   norlag_omkodet$redarbtid\n\n--------------------------------------------------------------------------------\n\n   Storage mode: integer\n   Factor with 2 levels\n\n   Levels and labels     N Valid Total\n                                      \n    1 'Nei'           1360  18.2   4.1\n    2 'Ja'            6110  81.8  18.5\n   NA                25614        77.4"
  },
  {
    "objectID": "omkode_factor.html#spesielle-problemstillinger-ved-veldig-mange-kategorier",
    "href": "omkode_factor.html#spesielle-problemstillinger-ved-veldig-mange-kategorier",
    "title": "14  Omkoding av variable",
    "section": "14.7 Spesielle problemstillinger ved veldig mange kategorier",
    "text": "14.7 Spesielle problemstillinger ved veldig mange kategorier\nFor disse eksemplene skal vi bruke et litt annet datasett, nemlig et lite uttrekk fra European Social Survey. Her er det 3 variable: yrkeskode, kjønn og politisk interesse.\n\npolit <- read.csv2(\"data/politics.csv\", colClasses = \"character\")\n\nglimpse(polit)\n\nRows: 49,519\nColumns: 3\n$ isco08  <chr> \"3333\", \"7122\", \"4221\", \"4311\", \"6130\", \"7212\", \"5131\", \"5223\"…\n$ gndr    <chr> \"1\", \"1\", \"2\", \"1\", \"2\", \"1\", \"1\", \"2\", \"1\", \"2\", \"1\", \"2\", \"1…\n$ polintr <chr> \"3\", \"2\", \"4\", \"3\", \"2\", \"2\", \"4\", \"3\", \"3\", \"4\", \"2\", \"2\", \"1…\n\n\nVi kan sjekke hvor mange kategorier det er ved å lage en tabell over kodene og se hvor mange det er. Det er imidlertid upraktisk da den tabellen tar veldig mye plass. Koden nedenfor gjør en enklere opptelling ved å trekke ut unike verdier og telle hvor mange det er:\n\nantall_koder <- polit %>%  \n  pull(isco08) %>%   # trekker ut en vektor med kun en variabel \n  unique() %>%       # beholder kun unike verdier \n  length()           # lengden på gjenværende vektor \n\nantall_koder\n\n[1] 561\n\n\nDet er altså 561 unike yrkeskoder i datasettet.\n\n14.7.1 Hierarkisk strukturerte tall som tekststrenger\nNoen ganger er det hundrevis av verdier. Et slik eksempel er yrkesklassifisering der hver type yrke har en spesifikk kode. Det finnes mange typer yrker, så det er omlag 800 koder. For de fleste typer analyser er dette altfor detaljert og du trenger å gruppere til færre kategorier. SSB har en kodeliste offentlig tilgjengelig. Kort fortalt er det en kode med 4 siffer, der det første sifferet er en grov gruppering, og de etterfølgende sifrene innebærer en økt detaljeringsgrad innenfor grupperingen angitt ved første siffer.\nHvis du skulle omkodet yrker slik som forklart i et tidligere avsnitt om omkoding ville det tatt veldig lang tid, men det ville også være veldig lett å gjøre feil. Det vil rett og slett være et mareritt å de-bugge koden for å finne feil eller kvalitetssjekke. Altså: en slik tilnærming er helt uaktuelt. En langt bedre tilnærming er å bare trekke ut det første sifferet fra koden. Funksjonen str_sub() gjør akkurat slike ting ved å angi hvilken del av tekststrengen du vil trekke ut, angitt ved posisjonen du starter ved og slutter ved. Her er det altså første posisjon.\n\npolit <- polit %>% \n  mutate(occupation = str_sub(isco08, start = 1, end = 1)) \n\npolit %>% \n  select(gndr, occupation) %>% \n  tbl_summary(by = gndr)\n\nRegistered S3 method overwritten by 'sass':\n  method    from  \n  print.css memisc\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1, N = 23,0201\n      2, N = 26,4991\n    \n  \n  \n    occupation\n\n\n        \n1,847 (8.0%)\n2,947 (11%)\n        0\n5 (<0.1%)\n1 (<0.1%)\n        1\n2,185 (9.5%)\n1,350 (5.1%)\n        2\n3,665 (16%)\n5,018 (19%)\n        3\n2,736 (12%)\n3,250 (12%)\n        4\n1,071 (4.7%)\n2,862 (11%)\n        5\n2,418 (11%)\n5,569 (21%)\n        6\n704 (3.1%)\n445 (1.7%)\n        7\n4,162 (18%)\n1,158 (4.4%)\n        8\n2,495 (11%)\n966 (3.6%)\n        9\n1,732 (7.5%)\n2,933 (11%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n14.7.2 Bruke kataloger for kodeverk\nSometimes, such long list of unique codes have a standard grouping that are not hierarchical. One such example is the ordc class schema as developed by the HISTCLASS-project homepage. This is a coding schema for isco-codes to classes, and a catalogue is available from the homepage. As there are about 800 unique values and they are stored in Excel-format with corresponding grouping for each code. The first lines in Excel-file looks lik this:\n\nThis file can be read into R using read_excel(), where the first line is typically read as variable names. But the first lines are not to be used, and neither are several columns.\nTo read it into R, we need to skip the lines not needed and change the variable names. In this example, we only need the isco-kodes and the ordc_yrk codes. Variable names should not include spaces, so we include an argument for ensuring universal valid variable names. That substitutes white space with punctuation. We also specify col_types = \"text\" to avoid the values being interpreted as numeric.\n\nisco <- readxl::read_excel(path = \"data/3_codes_isco88_ordc.xlsx\", skip = 4, .name_repair = \"universal\", col_types = \"text\") %>% \n  select(2,9) \nhead(isco)\n\n# A tibble: 6 × 2\n  ISCO.88.code ORDC_YRK\n  <chr>        <chr>   \n1 1237         1       \n2 2141         1       \n3 2310         1       \n4 2351         1       \n5 2442         1       \n6 2443         1       \n\n\nNow, we can merge the data with this catalogue. So that every record in the catalogue is merged to each record with the same code. To do this, we use left_join(), and store in a new object.\n\nisco <- isco %>% \n  rename(isco08 = ISCO.88.code)\n\npolit2 <- left_join(polit, isco, by = \"isco08\")\n\nhead(polit2)\n\n  isco08 gndr polintr occupation ORDC_YRK\n1   3333    1       3          3     <NA>\n2   7122    1       2          7       10\n3   7122    1       2          7       10\n4   4221    2       4          4        8\n5   4311    1       3          4     <NA>\n6   6130    2       2          6       12\n\n\nWhat happened here is that the recoding happened almost automatically by adding a new column with the new variable.\nNow, you can make e.g. a cross-tabulation of social class by gender.\n\npolit2 %>% \n  select(ORDC_YRK, gndr) %>% \n  tbl_summary(by = gndr)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1, N = 29,2851\n      2, N = 33,9501\n    \n  \n  \n    ORDC_YRK\n\n\n        1\n448 (2.4%)\n364 (2.0%)\n        10\n5,887 (32%)\n3,222 (17%)\n        11\n3,757 (20%)\n5,563 (30%)\n        12\n1,222 (6.6%)\n1,187 (6.4%)\n        2\n1,367 (7.4%)\n1,333 (7.1%)\n        3\n30 (0.2%)\n13 (<0.1%)\n        4\n561 (3.0%)\n1,251 (6.7%)\n        5\n2,000 (11%)\n2,669 (14%)\n        6\n1,681 (9.1%)\n1,850 (9.9%)\n        7\n180 (1.0%)\n267 (1.4%)\n        8\n1,129 (6.1%)\n726 (3.9%)\n        9\n134 (0.7%)\n105 (0.6%)\n        996\n84 (0.5%)\n109 (0.6%)\n        997\n5 (<0.1%)\n1 (<0.1%)\n        Unknown\n10,800\n15,290\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "omkode_factor.html#gjøre-samme-ting-med-mange-variable-med-across",
    "href": "omkode_factor.html#gjøre-samme-ting-med-mange-variable-med-across",
    "title": "14  Omkoding av variable",
    "section": "14.8 Gjøre samme ting med mange variable med across()",
    "text": "14.8 Gjøre samme ting med mange variable med across()"
  },
  {
    "objectID": "import_metadata.html#håndtering-av-user-nas",
    "href": "import_metadata.html#håndtering-av-user-nas",
    "title": "Appendix A — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "A.1 Håndtering av user-NAs",
    "text": "A.1 Håndtering av user-NAs\nFor disse dataene vil det være ulike sett av missing-verdier for de ulike variablene. Dette kan helt fint håndteres manuelt variabel for variabel. Men for å ha ordentlig kontroll på at det blir riktig bør det automatiseres. Logikken i denne delen går et stykke utover hva vi forventer at den jevne sosiologistudent skal lære.\nEn første sted er å lese inn dokumentasjonsrapporten fra en html-fil slik den leveres fra Sikt og gjør det om til et håndterbart oppslags-datasett. Dette er beskrevet i eget appendix. Det følgende tar utgangspunkt i at en slik oppslagsfil finnes.\nDet er noen verdier som i dokumentasjonen er spesifisert som spesielle typer missing. Disse skal vi kode om til NA. Disse verdiene har labler som starter med “filter:” eller “vil ikke svare” etc. Disse danner basis for omkoding til NA.\nFunksjonen nedenfor skal brukes innenfor et steg der man går gjennom alle variablene en om gangen. For hver variabel slås det opp de aktuelle missing-verdiene som gjelder for denne og bruker replace() til å omkode til NA for disse verdiene. Når denne funksjonen kalles for hver variabel senere, så brukes det altså ulike definisjoner av missing-verdier for hver variabel.^(Basert på kode fra https://tim-tiefenbach.de/post/2023-recode-columns/ )\n\n# leser inn kodeliste/dokumentasjon\ndat_dict <- readRDS(\"data/dat_dict.rds\")\n\n# velger kun missing-lablene\ndat_dict_na <- dat_dict %>% \n  filter(str_sub(tolower(label), 1, 7) == \"filter:\" | \n           tolower(label) %in% c(\"vil ikke svare\",\n                                 \"deltok ikke i runden\",\n                                  \"mangler data\")) \n\n# Funksjon for å recode som har gitte user-NA.\n# (Må brukes innenfor `across()` nedenfor)\nrecode_col_na <- function(x, dict) {\n  recode_vec <- dict %>%\n    filter(col_nm == cur_column()) %>%\n    mutate(value = as.numeric(value)) %>% \n    pull(value)\n  replace(x, x %in% recode_vec, NA)\n}"
  },
  {
    "objectID": "import_metadata.html#innlesning-av-data",
    "href": "import_metadata.html#innlesning-av-data",
    "title": "Appendix A — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "A.2 innlesning av data",
    "text": "A.2 innlesning av data\n\n\n\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(labelled)\n\n\n# data\nfaste <- read_stata( paste0(infilbane, \"NorLAG-lengde-faste.dta\"), encoding = \"utf-8\")\nlang <- read_stata( paste0(infilbane, \"NorLAG-lengde-intervju.dta\"), encoding = \"utf-8\")\n\n\nnorlag <- merge(faste, lang, by = \"ref_nr\") %>% \n  filter(iodeltakelse == 1 |  \n           iodeltakelse == 2 & round %in% c(1, 3) | \n           iodeltakelse == 3 & round %in% c(2, 3) |\n           iodeltakelse == 4 & round %in% c(1) |\n           iodeltakelse == 5 & round %in% c(1, 2) |\n           iodeltakelse == 6 & round %in% c(2)\n  ) \n\n# vektorer av variable som skal omkodes\ncols_vec_all <- unique(dat_dict$col_nm)\nvars <- unique(names(norlag))\ncols_vec <- cols_vec_all[cols_vec_all %in% vars]\ncols_vec_na <- cols_vec[(cols_vec %in% unique(dat_dict_na$col_nm))]\n\nnorlag <- norlag %>% \n  mutate(across(all_of(cols_vec_na), \n              \\(x,dic) recode_col_na(x, .env$dat_dict_na))) %>% \n  mutate(across(where(is.labelled), ~as_factor(.))) %>% \n  mutate(across(where(is.factor), ~fct_drop(.)))\n\nI tilegg skal vi lage en variabel for det vi kan kalle hovedaktivitet som sysselsettingsstatus. Det er om man er yrkesaktiv, arbeidsledig, student eller annet. I hver runde av NorLAG ble svarkategoriene utformet litt forskjellig, så derfor er svarene fordelt over tre variable. Nedenfor samles disse sammen og kodes om basert på tekststrenger.\n\n## Omkoder hovedaktivitet \nfs <- lvls_union( list(norlag$wr001, norlag$wr002, norlag$wr003c)) %>% tolower() %>% unique()\n\nnorlag <- norlag %>% \n  mutate(across(wr001:wr003c, ~factor(tolower(.), levels=fs))) %>% \n  mutate(hovedaktivitet = case_when(round == 1 ~ wr001, \n                                    round == 2 ~ wr002, \n                                    round == 3 ~ wr003c) ) %>% \n  mutate(hovedaktivitet2 = case_when( str_sub(hovedaktivitet, 1, 5) == \"yrkes\" ~ \"Yrkesaktiv\", \n                                      str_detect(hovedaktivitet, \"arbeidsledig\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_detect(hovedaktivitet, \"student\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_detect(hovedaktivitet, \"trygd\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_detect(hovedaktivitet, \"annet\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_sub(hovedaktivitet,1,6)   == \"hjemme\" ~ \"hjemmeværende/husmor\", \n                                      str_detect(hovedaktivitet, \"pensjonist\") ~ \"pensjonist\", \n                                      is.na(hovedaktivitet) ~ \"Trygdet/arbeidsledig/stud/annet\") %>% as_factor())\n\n\n\n\n\n\n\nOg dermed har vi et datasett i et svært så ryddig R-format."
  },
  {
    "objectID": "import_metadata.html#hvordan-fungerer-koden-ovenfor-en-intro-til-mer-avansert-databehandling",
    "href": "import_metadata.html#hvordan-fungerer-koden-ovenfor-en-intro-til-mer-avansert-databehandling",
    "title": "Appendix A — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "A.3 Hvordan fungerer koden ovenfor?? En intro til mer avansert databehandling",
    "text": "A.3 Hvordan fungerer koden ovenfor?? En intro til mer avansert databehandling\n\nA.3.1 Sjekk datastruktur og bruk av filter\n\n\nA.3.2 Omkode bruker-spesifiserte missing-verdier til NA\n\n\nA.3.3 Kode om på tvers av mange variable med across\n\n\nA.3.4 Fjerne nivåer som ikke brukes: drop_unused_value_labels\n\n\nA.3.5 Gjør om til factor med unlabelled"
  },
  {
    "objectID": "import_metadata.html#for-spesielt-interesserte-jobbe-med-labelled-data",
    "href": "import_metadata.html#for-spesielt-interesserte-jobbe-med-labelled-data",
    "title": "Appendix A — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "A.4 For spesielt interesserte: jobbe med labelled-data",
    "text": "A.4 For spesielt interesserte: jobbe med labelled-data"
  },
  {
    "objectID": "createDictionary.html#lese-inn-html-dokumentasjonen",
    "href": "createDictionary.html#lese-inn-html-dokumentasjonen",
    "title": "Appendix B — Lage dictionary-fil",
    "section": "B.1 Lese inn html-dokumentasjonen",
    "text": "B.1 Lese inn html-dokumentasjonen\nFørste sted er å lese inn html-filen. Funksjonen read_html() gjør dette. For å skjønne litt mer av hvordan dette ser ut kan du åpne den opprinnelige html-filen i ren tekst, f.eks. med bruk av Notepad. Det er dette som leses inn. Jeg legger det i et nytt objekt som jeg har kalt cb (forkortelse for codebook).\n\n#library(XML)\n\n# read html file\nu <- \"C:/Users/torbskar/OneDrive - Universitetet i Oslo/Dokumenter/Undervisning/SOS4020_forkurs/data2023/data_tilDeling/Kodebok.html\"\n\ncb <- read_html(u)\n\nFor NorLAG er dokumentasjonsdokumentet inndelt i flere deler, og det er bare den siste delen som inneholder kodeskjemaene. Det er denne siste delen vi trenger, så første utfordring er å plukke ut denne delen.\nEn html-fil er strukturert innenfor “noder” som har en start og en slutt. Et avsnitt starter med en kode <a> og avsluttes med </a>. Tilsvarende koder finnes for tabeller og andre elementer. Disse delene har er oftest gitt et navn som man kan identififiseres og brukes til lage lenker til spesifikke deler av siden (jf. innholdsfortegnelsen). Vi bruker denne til å filtrere filen.\nI akkurat denne filen trenger vi informasjonen som ligger etter overskriften “Variables Description”. For å finne navnet på dette avsnittet kan man undersøke lenken i innholdsfortegnelsen der det fremkommer som #variables. Eller man kan åpne html-filen i et tekstdokument og søke opp tittelen, så finner man koden name='variables innenfor det avsnittet.\nVi bruker html_nodes til å trekke ut bare dette avsnittet som følger.\n\n# Find the specific heading\nvariables <- cb %>% \n  html_nodes(\"a[name='variables']\")\n\nI denne dokumentasjonen er hver variabel lagret i en egen tabell. I html-kode angis begynnelsen av en tabell med <table> og denne brukes til å trekke ut bare tabellene.\n\ntables <- variables %>% \n    #html_node(xpath = \"//a[@name='variables']\") %>% \n    html_nodes(xpath = \"./following::table\")\n\nSå kan vi bruke funksjonen html_table til å trekke ut hver enkelt tabell i en struktur som er lettere å jobbe med, nemlig en “data.frame”, altså en rektangulær struktur med rader og kolonner slik datasett vanligvis ser ut. Hver tabell blir et eget data.frame-objekt, og når man legger dette i et nytt objekt blir det av typen “list”. En “list” er en samling objekter som har hver sin plass i det samme objektet. (Du kan tenke på det som en eske med flere mindre ekster oppi). Vi kommer tilbake til hvordan de slås sammen.\n\ntable_data <- html_table(tables)\n\n\nB.1.1 Legge det hele i en funksjon\n\n# Check if the heading exists\nif (length(variables) > 0) {\n  # Find the tables after the heading\n  tables <- variables %>% \n    html_node(xpath = \"//a[@name='variables']\") %>% \n    html_nodes(xpath = \"./following::table\")\n  \n  # Extract the table data\n  table_data <- html_table(tables)\n  } else {\n  cat(\"The specified heading was not found.\")\n}\n\n\ntbslist <- list()\nfor(i in 1:length(table_data)){ \n  if(\"X2\" %in% names(table_data[[i]]) & \n     \"X3\" %in% names(table_data[[i]]) & \n     !(\"X4\" %in% names(table_data[[i]])) ){\n    \n    tbslist[[i]] <- table_data[[i]] %>% \n      mutate(col_nm = strsplit(as.character(.[1,1]), split = \":\")[[1]][1],\n             spm = strsplit(as.character(.[1,1]), split = \":\")[[1]][2]) %>% \n      rename( value = X2, \n              label = X3) %>%\n      filter( str_detect(X1, \"Values and categories\")) %>% \n      filter( !is.na(value)) %>% \n      select(-X1)\n  }\n  else{\n    if(i==1){\n      teller <- 0\n      }\n    teller <- teller + 1 \n  }\n  if(i == length(table_data)){\n    print(paste(\"Antall variable som ikke har omkodinger: \", teller)) \n  }\n}\n\n[1] \"Antall variable som ikke har omkodinger:  1\"\n\ndat_dict <- bind_rows(tbslist) %>% \n  select(col_nm, value, label, spm)"
  }
]