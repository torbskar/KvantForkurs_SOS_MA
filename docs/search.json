[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Forkurs for kvantitativ metode",
    "section": "",
    "text": "Forord\nDette materialet er beregnet på et forkurs for masterstudenter i sosiologi ved universitet i Oslo som skal ta emnet SOS4020 Kvantitative metoder. Forkurset dekker de mest sentrale elementene fra BA-nivået som trengs for å ta SOS4020.\nDet anbefales å repetere materiale fra kurs i kvantitative metoder på bachelornivå. Forkurset er en oppfrisker av det aller viktigste materialet fra SOSGEO1120.\nDe som lært annen statistikksoftware enn R på bachelornivå vil ha særlig nytte av dette kurset. Har man tatt bachelorgrad annet sted enn ved UiO kan man ha lært å bruke Stata, SPSS eller noe slikt. Da trenger du en introduksjon til R, men hva vi skal gjøre vil være tilsvarende.\nEn av de store forskjellene fra SPSS og Stata er at R ikke har muligheten for menybaserte analyser. Du kan altså ikke gjøre analyser med “pek-og-klikk”! Det bør du jo egentlig uansett ikke gjøre i annen software heller. R er altså et programmeringsspråk, og det er viktig å lære å skrive kode både for databehandling og analyse. I tillegg til programmeringsspråket skal du lære å lage en hensiktsmessig mappestruktur og lese inn datasett i R.\nDatasettet som skal brukes i SOS4020 er tilgangsbegrenset så det er litt formaliteter som må på plass først. Det skal vi gå på plass her slik at dere har lovlig tilgang til dataene. Men gjennomgangen og eksempler i det følgende vil basere seg på det samme datasett som brukes gjennomgående i SOSGEO1120. Til hvert kapittel er det oppgaver. Først og fremst skal dere kunne gjøre de samme operasjonene på egen datamaskin. Dernest skal dere bruke NorLAG til å gjøre noe mer selvstendige analyser med de samme teknikkene.\nDette heftet inneholder også bittelitt mer informasjon enn du trenger (f.eks. appendiks), men som du kan ha bruk for hvis du skal gjøre mer selvstendige analyser senere."
  },
  {
    "objectID": "index.html#målsettinger-for-forkurset",
    "href": "index.html#målsettinger-for-forkurset",
    "title": "Forkurs for kvantitativ metode",
    "section": "Målsettinger for forkurset",
    "text": "Målsettinger for forkurset\nOverordnet sett skal du denne uken bli kjent med hvordan du bruker R til dataanalyse og repetert grunnleggende statistikk. Du jobber i eget tempo. Bruk tid på det som er krevende og hopp gjerne over deler du synes er enkelt. Så ber du om hjelp når du trenger det. Lærere er tilstede to timer på starten av dagen, og stikker antakeligvis innom en tur på slutten av dagen også. Bruk oss!\nHusk at det er ingen eksamen og krav på et slikt forkurs, så det er opp til deg å bruke tiden som er best for deg. Det blir vesentlig enklere å ta kurset SOS4020 hvis du har det grunnleggende rimelig på plass først.\nHer er en tentativ plan for hva du bør gjennom disse dagene:\nDag 1\n\nR og Rstudio er installert riktig på egen maskin.\nMappestruktur og opprettet Rstudio-project.\nTilgang til NorLAG og avtale for bruk, regler for datalagring\nInnlesning av data i .rds og .dta format\nStartet med praktisk grafikk\n\nDag 2\n\nGrafikk og tabeller.\nGrunnleggende om objekter og dplyr-verb, inkludert pipe-operator.\n\nDag 3\n\nGrunnleggende regresjon.\nSannsynlighet: standardfeil, p-verdier og konfidensintervall\n\nDag 4\n\nSannsynlighet (forts.)\nAnvende standardfeil, p-verdier og konfidensintervall sammen med teknikker gjennomgått første dag (tabeller og regresjon)"
  },
  {
    "objectID": "oppgaver.html#gjør-det-på-egen-datamaskin",
    "href": "oppgaver.html#gjør-det-på-egen-datamaskin",
    "title": "1  Oppgaver",
    "section": "1.1 Gjør det på egen datamaskin",
    "text": "1.1 Gjør det på egen datamaskin\nHeftet bruker gjennomgående et enkelt datasett abu89 og viser R-koden illustrerer dermed hvordan ting gjøres. Det første du skal gjøre er dermed å gjøre det samme på egen datamaskin og sjekke at du får samme resultat. Dette kan gjøres som en enkel “klipp-og-lim” som du neppe lærer så veldig mye av hvis du ikke tenker litt samtidig, men du får i hvert fall sjekket at koden fungerer. For hver operasjon bør du gjøre noen endringer i koden og se hva som skjer. I kapittelet om grafikk kan du f.eks. eksperimentere med å bytte om på variable, endre farger og annet. Slik får du en bedre forståelse av hva de ulike funksjonene og argumentene betyr. En god måte å finne ut av hvordan ting fungerer er å gjøre endringer og se hva som skjer."
  },
  {
    "objectID": "oppgaver.html#gjør-tilsvarende-med-datasettet-norlag",
    "href": "oppgaver.html#gjør-tilsvarende-med-datasettet-norlag",
    "title": "1  Oppgaver",
    "section": "1.2 Gjør tilsvarende med datasettet NorLAG",
    "text": "1.2 Gjør tilsvarende med datasettet NorLAG\nJo mer du tenker aktivt selv, jo mer lærer du. Bruk et annet datasett og gjør tilsvarende operasjoner som er vist med abu89. Dere får tilgang til et stort datasett fra undersøkelsen NorLAG og kan da undersøke mange muligheter.\nDu kan gjerne prøve å replikere noen tidligere studier som du finner i denne publikasjonslista.1 Variabelliste med dokumentasjon finner du filen “Kodebok.html” når du har fått tilgang til delt mappe ."
  },
  {
    "objectID": "oppgaver.html#bruk-helt-andre-datasett",
    "href": "oppgaver.html#bruk-helt-andre-datasett",
    "title": "1  Oppgaver",
    "section": "1.3 Bruk helt andre datasett",
    "text": "1.3 Bruk helt andre datasett\nDet er en god del innebygde datasett i R og i ulike R-pakker. Du kan få en oversikt over tilgjengelig datasett ved funksjonen data() som lister opp de dataene som er tilgjengelig i de pakkene du har lastet for øyeblikket.\n\ncausaldata: en pakke med diverse datasett brukt i lærebøker for kausalanalyse. Tilgang: install.packages(\"causaldata\"). For en oversikt, se pakkes dokumentasjon.\ngapminder: en pakke med utdrag av Gapminder-data med ulike lands levealder, befolkningsstørrelse og brutto nasjonalprodukt over mange år. Tilgang: install.packages(\"gapminder\")\n\nNår en pakke, f.eks. gapminder, er lastet har du automatisk tilgang til dataene ved å bruke navnet på datasettet i en funksjon som følger:\n\nlibrary(gapminder)\nsummary(gapminder)\n\n        country        continent        year         lifeExp     \n Afghanistan:  12   Africa  :624   Min.   :1952   Min.   :23.60  \n Albania    :  12   Americas:300   1st Qu.:1966   1st Qu.:48.20  \n Algeria    :  12   Asia    :396   Median :1980   Median :60.71  \n Angola     :  12   Europe  :360   Mean   :1980   Mean   :59.47  \n Argentina  :  12   Oceania : 24   3rd Qu.:1993   3rd Qu.:70.85  \n Australia  :  12                  Max.   :2007   Max.   :82.60  \n (Other)    :1632                                                \n      pop              gdpPercap       \n Min.   :6.001e+04   Min.   :   241.2  \n 1st Qu.:2.794e+06   1st Qu.:  1202.1  \n Median :7.024e+06   Median :  3531.8  \n Mean   :2.960e+07   Mean   :  7215.3  \n 3rd Qu.:1.959e+07   3rd Qu.:  9325.5  \n Max.   :1.319e+09   Max.   :113523.1"
  },
  {
    "objectID": "oppgaver.html#footnotes",
    "href": "oppgaver.html#footnotes",
    "title": "1  Oppgaver",
    "section": "",
    "text": "OBS! Å replikere andres studier nøyaktig er langt mer krevende enn man skulle tro. Normalt trenger du at forfatter deler originalt script, men det er ikke alltid lett tilgjengelig, skrevet i et annet programmeringsspråk, inkluderer langt mer avanserte teknikker enn du har lært om, eller bare er generelt uryddig. Så ikke sett det som ambisjon, men få heller inspirasjon til å finne et tema som er litt interessant og søk opp aktuelle variable.↩︎"
  },
  {
    "objectID": "Installering.html#installasjon",
    "href": "Installering.html#installasjon",
    "title": "2  Installere R og Rstudio",
    "section": "2.1 Installasjon",
    "text": "2.1 Installasjon\nInstaller nyeste versjon av R herfra: https://cran.uib.no/ Du trenger det som heter «base» når man installerer for første gang. Hvis du har R installert på maskinen din fra før, sørg for at du har siste versjon installert. Siste versjon er 4.1.2. Versjon etter 4.0 bør gå bra, men tidligere versjoner vil kunne gi problemer. Installer nyeste versjon av RStudio (gratisversjon) herfra: https://rstudio.com/products/rstudio/download/ Viktig: du må installere R før du installerer Rstudio for Rstudio finner R på din datamaskin og vil gi feilmelding hvis den ikke finner R. Hvis du har en eldre datamaskin og du får feilmelding ved installasjon av RStudio kan du vurdere å installere forrige versjon av Rstudio herfra: https://www.rstudio.com/products/rstudio/older-versions/\nR og Rstudio er to programmer er integrert i hverandre og du åpner heretter R ved å åpne RStudio. Merk: R er navnet på programmeringsspråket og programmet som gjør selve utregningene. Det kjører fra en kommandolinje og er ikke veldig brukervennlig alene. RStudio er et “integrated development environment” (IDE) til R. Det integrerer R med en konsoll, grafikk-vindu og en del andre nyttige ting. Det gjør det lettere å bruke R.\nDet finnes også andre IDE for R, men vi skal bruke RStudio gjennomgående på dette kurset. (RStudio inneholder også masse annen funksjonalitet vi ikke trenger til dette kurset).\n\n2.1.1 Spesielt om Windows-maskiner: installer Rtools\nHvis du jobber på en Windows-maskin må du også installere Rtools herfra: https://cran.r-project.org/bin/windows/Rtools/\n\n\n2.1.2 Spesielt om Mac-maskiner\nR skal normalt installere på Mac uten problemer. Noen har fått beskjed om at de også trenger å installere XQuartz eller Xcode. I så fall installerer du de også. Se mer informasjon her: https://cran.r-project.org/bin/macosx/tools/\n\n\n2.1.3 Spesielt om Linux-maskiner\nHar du Linux vet du antakelig hva du driver med. Siste versjon av R og Rstudio kan antakeligvis installeres fra distroens repository.\n\n\n2.1.4 Spesielt om Chromebook\nChromebook kjører et annet operativsystem og R vil ikke uten videre fungere. Derimot kan man på de fleste slike maskiner åpne opp for å kjøre Linux og da kan man installere linux-versjon av R og Rstudio. https://blog.sellorm.com/2018/12/20/installing-r-and-rstudio-on-a-chromebook/ Eller se nedenfor hvordan du kan kjøre R i skyen.\n\n\n2.1.5 Rstudio workbench i UiO-skyen\nHvis du opplever uløselige problemer med å kjøre R og Rstudio på din datamaskin, så finnes det en krise-løsning. Rstudio har også en versjon som kjører i skyen via nettleser. UiO har en slik versjon installert på sine servere som vi kan bruke. Du logger da inn på Rstudio Workbench med ditt Feide brukernavn og passord. (Det er sendt inn beskjed om at alle på SOS4020 skal ha tilgang, og håper det er i orden nå eller veldig snart).\nRstudio workbench fungerer på samme måte som Rstudio ellers, men du kan ikke installere pakker selv. Det viktigste er tilgjengelig allerede, så det burde gå fint. I fanen “Files” kan du lage en mappestruktur og laste opp/ned filer etter behov.\nOBS! Workbench-løsningen har et helt trivilet sikkerhetsnivå for data. Den er kun godkjent for å bruke grønne data. Det betyr at du ikke kan jobbe med NorLAG eller andre data som ikke er åpne med denne løsningen."
  },
  {
    "objectID": "Installering.html#oppsett-og-forberedelser",
    "href": "Installering.html#oppsett-og-forberedelser",
    "title": "2  Installere R og Rstudio",
    "section": "2.2 Oppsett og forberedelser",
    "text": "2.2 Oppsett og forberedelser\nDette oppsettet gjelder både hvis du har en lokal installasjon og for skyløsninger. Utseendet spiller ingen rolle, og R kan også fungere uten å opprette «projects» som beskrevet her. Men det er lettere å bruke og du har bedre orden hvis du gjør dette.\n\n2.2.1 Utseende i Rstudio\nEndre gjerne på oppsettet i RStudio ved å gå til Tools og deretter Global options, så Pane Layout.\n\nDet spiller ingen rolle for funksjonaliteten hvor du har hvilken fane, men her er et forslag.\n\nDette kan også endres senere og har altså bare med hvordan Rstudio ser ut."
  },
  {
    "objectID": "Installering.html#rstudio-projects",
    "href": "Installering.html#rstudio-projects",
    "title": "2  Installere R og Rstudio",
    "section": "2.3 Rstudio projects",
    "text": "2.3 Rstudio projects\nNår du åpner Rstudio skal du alltid åpne som «project» (se video med instruksjon og i R4DS). Arbeidsområdet er da definert og du kan åpne data ved å bruke relative filbaner, dvs. at du oppgir hvor dataene ligger med utgangspunkt i prosjektmappen. Se kursvideo og instruksjoner i R4DS og gjør følgende:\nOpprettet mappestruktur med SOSGEO1120 som øverste nivå og egne undermapper for data, script, og output."
  },
  {
    "objectID": "Installering.html#åpne-rstudio-og-opprett-et-.rproject",
    "href": "Installering.html#åpne-rstudio-og-opprett-et-.rproject",
    "title": "2  Installere R og Rstudio",
    "section": "2.4 Åpne RStudio og opprett et .Rproject",
    "text": "2.4 Åpne RStudio og opprett et .Rproject\n\nBruk funksjonen getwd() og se at du har riktig filbane til arbeidsområdet. Hvis du ikke er sikker på hva det betyr, må du spørre noen eller finne det ut på annen måte!\nDet første dere må gjøre er å sørge for å ha orden i datasett, script og annet på din egen datamaskin. Å f.eks. lagre alle filer på skrivebordet bør du aldri gjøre, og særlig ikke i dette kurset eller når man jobber med større prosjekter og datasett.\nFor dette kurset skal du ha en mappestruktur med en hovedmappe for SOSGEO1120 og tilhørende undermapper. Det spiller ingen rolle hvor på datamaskinen du legger disse mappene, men du må vite hvor det er. Lag første en mappe som heter SOSGEO1120, og innunder denne mappen lager du tre andre mapper med navnene data, output og script. Du kan ha andre mapper i tillegg ved behov. Det kan se slik ut:\n\nDu skal opprette et Rstudio-prosjekt for hele kurset. Dette er beskrevet nærmere i R4DS i kapittel 6. Når du har åpnet RStudio skal du aller først klikke New Project.\n\nDeretter klikker du du «Existing Directory»\n\nKlikk «Browse» og bla deg så frem til mappen du har laget for SOSGEO1120.\nRStudio-prosjektet ligger så i den mappen du har valgt. I filutforsker på datamaskinen vil nå disse to filene dukke opp:\n\nFor å starte R videre i dette kurset skal du dobbeltklikke det første ikonet, så vil R åpne seg med riktig arbeidsområde. Mappen .Rproj.user skal du ikke røre. I RStudio vil du se at prosjektet er åpnet ved at det i øvre høyre hjørne er dette ikonet:\n\nEn stor fordel med å bruke projects er at du kan flytte hele mappen til et annet sted, eller til en annen datamaskin og alt vil fungere akkurat som før. Hvis du bruker en skytjeneste (OneDrive, Dropbox etc) vil du kunne åpne Rstudio projects på samme måte fra flere maskiner."
  },
  {
    "objectID": "kort_intro_R.html#objektorientert",
    "href": "kort_intro_R.html#objektorientert",
    "title": "3  En veldig kjapp intro til R",
    "section": "3.1 Objektorientert",
    "text": "3.1 Objektorientert\nI de innledende kapitlene ble det vist hvordan man leser inn data i R og dataene ble lagt i et “objekt”. R er bygd opp rundt å bruke slike objekter i den forstand at alt man jobber med (typisk: datasett) ligger i objekter.\nDu kan tenke på objekter som en boks som det står et navn på. Ofte er det bare et datasett oppi boksen, men det kan også være flere ting. Det finnes derfor flere typer objekter. Vi skal primært jobbe med datasett, og slike objekter er av typen “data.frame”. De kan også være av typen “tibble”, men det er for alle praktiske formål på dette nivået akkurat det samme som “data.frame”. Men objekter kan også inneholde resultater fra analyser, som f.eks. grafikk, tabeller eller regresjonsresultater. Man kan også legge enkelttall, vektorer og tekststrenger i objekter.\nNoen ganger vil et objekt inneholde flere forskjellige ting. Et eksempel er resultat fra regresjonsmodeller som både vil inneholde koeffisienter, standardfeil, residualer, en del statistikker, men også selve datasettet. Men for å se på output er det funksjoner som trekker ut akkurat det vi trenger, så du trenger sjelden forholde deg til hvordan et slikt objekt er bygd opp. Men du kan tenke på det som en velorganisert boks med masse mindre rom oppi.\nMen poenget er: Alt du jobber med i R er objekter. Alle objekter har et navn som du velger selv. Du kan legge hva som helst i et objekt. Du kan ikke ha to objekter med samme navn, og hvis du lager et objekt med et navn som eksisterer fra før overskriver du det gamle objektet."
  },
  {
    "objectID": "kort_intro_R.html#funksjoner",
    "href": "kort_intro_R.html#funksjoner",
    "title": "3  En veldig kjapp intro til R",
    "section": "3.2 Funksjoner",
    "text": "3.2 Funksjoner\nAlt man gjør i R gjøres med “funksjoner”, og man bruker funksjonene på objekter eller deler av objekter. Funksjonenen har et navn og etterfulgt av en parentes slik som f.eks. dinfunksjon(...). Funksjonen starter og slutter med en parentes. Du kan tenke på funksjoner som en liten maskin der du putter noe inn, og så kommer noe annet ut. Det du putter inn skal står inni parentes. Det som kommer ut kan du enten legge i et eget objekt eller la det skrives til output-vinduet.\nDet du legger inn i funksjonen - altså inni parentesn - kalles “argumenter”. Hvert argument har et navn og du skal normalt oppgi i hvert fall hvilket datasett funksjonen skal brukes på. Argumentet for data er nettopp data = og så oppgis navnet på det objektet dataene ligger i. En god del slike argumenter har navn som er standardisert på tvers av funksjoner, og data = er et eksempel på dette.\nI tillegg kan det være en rekke andre argumenter som vi kommer tilbake til i de ulike funksjonene vi bruker. Et poeng er viktig å presisere: argumentene har også en forventet rekkefølge. Man kan også oppgi argumentene uten å angi navnet hvis de kommer i riktig rekkefølge. For eksempel vil en funksjon for regresjon ha den forventede rekkefølgen: 1) Spesifisering av utfallsvariabel og forklaringsvariable på en form som heter “formula”, deretter og 2) Angitt objektnavnet til dataene. Så kan det være andre argumenter i tillegg. Man kan godt oppgi argumentene i annen rekkefølge, men da er man nødt til å bruke argumentnavnet slik at R forstår hva som er hva."
  },
  {
    "objectID": "kort_intro_R.html#r-pakker",
    "href": "kort_intro_R.html#r-pakker",
    "title": "3  En veldig kjapp intro til R",
    "section": "3.3 R-pakker",
    "text": "3.3 R-pakker\nNår man installerer R har man svært mye funksjonalitet tilgjengelig uten videre. Dette kalles “base R”, altså basic installasjon og funksjonalitet. Men R er i praksis basert på å bruke såkalte “pakker”. Dette er funksjoner som utvider R sin funksjonalitet. Så mens “base R” tilbyr infrastrukturen, så er de ulike pakkene laget for spesifikke oppgaver.\nR-pakker er et helt økosystem av funksjonalitet som dekker det aller meste du kan finne på å gjøre, fra bittesmå oppgaver, til avansert statistikk og maskinlæring, til hele systemer for dataanalyse. Det finnes mange hundre R-pakker tilgjengelig, og disse ligger på en server som heter CRAN. Hvis du vil se på hva som finnes kan du se på oversikten over tilgjengelige pakker. For nye brukere av R vil dette fremstå som ganske kaotisk. Det finnes også oversikter der viktigste pakker innenfor ulike typer analyse er gruppert slik at man lettere skal kunne finne frem. Dette kalles Task Views. Men du trenger ikke forholde deg til slike oversikter på en god stund ennå. Du får beskjed om hvilke pakker du trenger fortløpende, og det er et begrenset antall.\nFor å installere en pakke må du vite hva pakken heter og datamaskinen din må være koblet til internett. Funksjonen install.packages:\n\ninstall.packages(\"pakkenavn\")\n\nDet hender at man får en feilmelding når man prøver installere en pakke. Det er noen veldig vanlige grunner til feilmeldinger som skal være rimelig enkle å finne ut av selv:\n\nDu har stavet navnet på pakken feil. Passe på særlig små og store bokstaver.\nPakken krever at du har noen andre pakker installert fra før. I så fall vil disse pakkenes navn står i feilmeldingen. Installer disse på samme måte først og prøv igjen.\nNoen andre pakker trengs å oppdateres for at den nye pakken skal virke. Oppdater alle pakker og prøv på nytt.\nDin R installasjon må oppdateres. Hvis det er lenge siden du installerte R, så installer på nytt og prøv igjen. Da må alle andre pakker også installeres på nytt.\n\nNår du installerer pakker får du noen ganger spørsmål om du vil installere “from source”. Som hovedregel kan du velge nei. “From source” betyr at det finnes en ny versjon som ikke er ferdig kvalitetssjekket på CRAN, men som er tilgjengelig. Du trenger neppe det aller, aller siste av funksjonalitet, så “nei” holder.\nNår en pakke er installert på datamaskinen din er disse funksjonalitetene tilgjengelig i R, men ikke helt automatisk. Pakkene ligger i en egen mappe i filstrukturen på datamaskinen og R vet selvsagt hvor dette er. For at pakkene skal være tilgjengelig for deg må du fortelle R at du skal bruke en slik pakke. Vi sier at vi “laster en pakke” (engelsk: “load”) og da er disse funksjonene tilgjengelig for deg i hele R-sesjonen. Hvis du restarter R, så må du laste pakkene på nytt før du kan fortsette der du slapp.\nDu laster en pakke med funksjonen library.\n\nlibrary(pakkenavn)\n\nHvis en kode ikke fungerer og du får feilmelding kan dette være grunnen: du har glemt å laste pakken eller pakken er ikke installert på maskinen din.\nEn annen grunn til at koden ikke fungerer kan være at det er “konflikt” mellom pakker du har lastet. Hvis du bare laster alle pakker du vet du bruker (og noen ekstra som noen på internett har foreslått), så kan det hende at disse pakkene skaper trøbbel for hverandre. Det er typisk at noen funksjoner har samme navn i ulike pakker, og R bruker da en annen funksjon enn du tror. Så da er rådet: ikke last masse pakker du ikke vet hva er. I det etterfølgende introduseres ulike pakker fortløpende og du får da vite hva de brukes til. Utvalget av pakker er dessuten slik at det ikke skal være noen slike konflikter. De pakkene vi skal bruke jobber veldig fint sammen. (Se avsnitt nedenfor om dialekter).\nMen det er altså et poeng at du må vite hva slags funksjonalitet de ulike pakkene har, og hvilke du faktisk trenger."
  },
  {
    "objectID": "kort_intro_R.html#r-dialekter",
    "href": "kort_intro_R.html#r-dialekter",
    "title": "3  En veldig kjapp intro til R",
    "section": "3.4 R-dialekter",
    "text": "3.4 R-dialekter\nDe funksjonene som følger med grunnleggende installasjon av R kalles altså “base R” eller bare “base”. Dette er grunnstrukturen for programmeringsspråket. Man kan gjøre svært mye analyser med bare bruk av base R, og en god del lærebøker i statistikk og dataanalyse er lagt opp til hovedsakelig bruk av base.\nNoen R-pakker inneholder ikke bare enkeltfunksjoner, men nesten et helt programmeringsspråk i seg selv. Noen slike pakker er egentlig en hel samling av veldig mange andre pakker som er integrert i hverandre og fungerer sømløst sammen. Det er lurt å holde seg innenfor samme “dialekt” da man ellers kan bli veldig forvirret. I det følgende skal vi holde oss til dialekten “Tidyverse”, som er en dominerende variant i R.\nMerk at det finnes altså flere dialekter som er spesialiserte for spesifikke formål. Et eksempel er {data.table} som er lynrask for store datasett, {caret} som gir et rammeverk for maskinlæring, og {lattice} som er et eget grafikk-system. Det finnes enda flere. Dette gjør at det kan være vanskelig å søke på nettet etter løsninger fordi du kan få svar (som funker!) i en annen dialekt enn den du kan."
  },
  {
    "objectID": "kort_intro_R.html#tidyverse",
    "href": "kort_intro_R.html#tidyverse",
    "title": "3  En veldig kjapp intro til R",
    "section": "3.5 Tidyverse",
    "text": "3.5 Tidyverse\nNår man laster pakken {tidyverse} laster man egentlig flere pakker som også kan lastes individuelt. Merk at “tidy” betyr jo “ryddig” og hensikten her er et språk som er så ryddig og logisk som mulig. Dette innebærer også at det er innarbeidet en del prinsipper for datastruktur og datahåndtering som er redegjort for i Wickham (2014). Full oversikt over pakkene som inngår i Tidyverse finner du på deres hjemmeside. Men du trenger ikke sette deg inn i alt det for å bruke softwaren.\n\n3.5.1 Datahåndtering: {dplyr}\nGrunnleggende datahåndtering inkluderer først og fremst å endre variable ved omkoding, utregninger eller transformasjoner. Pakken {dplyr} inneholder de nødvendige verktøy for dette.\nDe grunnleggende funksjonene vi bruker kan ordnes sekvensielt og bindes sammen med en “pipe”. Norsk oversettelse vil være “rørlegging”. Dette er litt rart og uvant, men i første omgang kan du se for deg at det er en flyt av data fra venstre side mot høyre side. Du kan altså gjøre noe med data og “deretter gjøre” noe mer med de dataene du har endret. Vi kommer tilbake til dette nedenfor.\nVi skal bruke et bittelite datasett for å demonstrere. Det er seks observasjoner og to variable. Observasjonene tilhører gruppe a, b, eller c, og variabelen “varA” har en tallverdi. Dataene ser ut som følger:\n\ndinedata\n\n  gruppe varA\n1      a    3\n2      b    5\n3      b    2\n4      a    4\n5      c    3\n6      c    7\n\n\n\n3.5.1.1 Grunnleggende verb\nFor å endre variable brukes funksjonen mutate, som har to argumenter: hvilket datasett som skal endres på, og spesifikasjon av gitte variable.\nSyntaksen er slik at man starter med å angi objektnavnet med dataene, men her skal det ikke skrives data = av grunner vi kommer tilbake til straks. Deretter skriver man navnet på ny variabel “erlik” utregning av ny verdi. I det følgende lages en ny variabel “varB” som er 2 ganger varA:\n\nmutate(dinedata, varB = 2*varA)\n\n  gruppe varA varB\n1      a    3    6\n2      b    5   10\n3      b    2    4\n4      a    4    8\n5      c    3    6\n6      c    7   14\n\n\nMan kan også overskrive en eksisterende variabel på samme måte.\nVi kan også velge bort variable med select. Merk at det som ble gjort med mutate ovenfor ikke er lagt i et nytt objekt, så det er bare printet til konsollen. Objektet “dinedata” er altså ikke endret. I følgende kode bruker vi select til velge å bare beholde “varA”.\n\nselect(dinedata, varA)\n\n  varA\n1    3\n2    5\n3    2\n4    4\n5    3\n6    7\n\n\nVi kan slette variable ved å sette minustegn foran variabelnavnet som følger:\n\nselect(dinedata, -varA)\n\n  gruppe\n1      a\n2      b\n3      b\n4      a\n5      c\n6      c\n\n\n\n\n3.5.1.2 Pipe %&gt;% med {magrittr}\nVi bruker en “pipe” for å få lettere lesbare koder og slippe å lage mange nye objekter hele tiden. Vi kan binde sammen flere verb i en arbeidsflyt der man kun angir objektnavnet én gang.\n\ndinedata %&gt;% \n  mutate(varB = 2*varA) %&gt;% \n  select(-varA)\n\n  gruppe varB\n1      a    6\n2      b   10\n3      b    4\n4      a    8\n5      c    6\n6      c   14\n\n\nOperatoren %&gt;% betyr “gjør deretter”. Kode ovenfor kan dermed skrives i klartekst som følger:\n\nstart med datasettet dinedata og “gjør deretter:”\nlag en ny variabel med navn varB som er 2 ganger verdien av variabelen varA, og “gjør deretter:\nslett variabel varA\n\nHvis vi vil legge resultatet i et nytt objekt for å bruke det videre (og det vil vi nesten alltid!) så spesifiseres det med å sette nyttobjekt &lt;- helt først som følger:\n\ndinedata2 &lt;- dinedata %&gt;% \n  mutate(varB = 2*varA) %&gt;% \n  select(-varA)\n\n\n\n3.5.1.3 Logiske operatorer\nI mange sammenhenger setter man hvis-krav. F.eks. at man skal gi en ny variabel en verdi hvis en annen variabel har en bestemt verdig - og en annen verdi hvis ikke. Det kan også gjelde kombinasjoner av variable og verdier. Slike krav er da enten TRUE eller FALSE.\nHer er grunnleggende logiske operatorer.\n\n\n\nUttrykk\nKode\n\n\n\n\ner lik\n==\n\n\ner ikke lik\n!=\n\n\nog\n&\n\n\neller\n|\n\n\nstørre/mindre enn\n&gt; eller &lt;\n\n\nstørre/mindre enn eller er lik\n&lt;= eller &gt;=\n\n\n\nFor å kode om kategoriske variable trenger vi disse. La oss bruke mutate til å gruppere sammen gruppene “a” og “b” ved å gjøre om alle “a” til “b”. Da bruker vi funksjonen ifelse som har syntaksen: ifelse(krav, verdi hvis TRUE, verdi hvis FALSE). Altså: først kravet, og alle observasjoner som fyller dette kravet får en verdi, mens alle andre får en annen verdi. Her er en kode som sjekker hvem som er i gruppe “a”, og gjør alle disse om til “b”, og resten beholder verdiene fra variabelen “gruppe”.\n\ndinedata %&gt;% \n  mutate(gruppe2 = ifelse(gruppe == \"a\", \"b\", gruppe))\n\n  gruppe varA gruppe2\n1      a    3       b\n2      b    5       b\n3      b    2       b\n4      a    4       b\n5      c    3       c\n6      c    7       c\n\n\nLogiske krav kan også kombineres med & og | og også med parenteser for mer kompliserte krav. Her er et eksempel som omkoder basert på verdier på to variable for å lage en tredje variabel:\n\ndinedata %&gt;% \n  mutate(gruppe2 = ifelse(gruppe == \"a\" & varA &lt; 5, \"a5\", \"andre\"))\n\n  gruppe varA gruppe2\n1      a    3      a5\n2      b    5   andre\n3      b    2   andre\n4      a    4      a5\n5      c    3   andre\n6      c    7   andre\n\n\n\n\n3.5.1.4 Flere verb\nLogiske operatorer brukes også til å filtrere dataene, altså å beholde eller slette rader som oppfyller visse krav. Her er en kode som beholder alle observasjoner om ikke tilhører gruppe “a”:\n\ndinedata %&gt;% \n  filter(gruppe != \"a\")\n\n  gruppe varA\n1      b    5\n2      b    2\n3      c    3\n4      c    7\n\n\nsummarise aggregerer resultater i et datasett. Man må da manuelt oppgi hvordan man ønsker summere opp med funksjoner som n(), sum() osv. Her er et eksempel som summerer opp med antall observasjoner, og for en variabel regner ut totalsummen for hele datasettet, gjennomsnittet og standardavviket.\n\ndinedata %&gt;% \n  summarise(antall = n(), totalt = sum(varA), gjennomsnitt = mean(varA), standardavvik = sd(varA))\n\n  antall totalt gjennomsnitt standardavvik\n1      6     24            4      1.788854\n\n\nDu synes kanskje det virker litt tungvint å lage oppsummeringer på denne måten? Det burde da finnes en egen funksjon som bare spytter ut en standard oppsummering uten å skrive så mye kode! Det gjør det selvsagt, så dette kommer vi tilbake til i del 2 for deskriptive teknikker.\nMan kan også lage oppsummeringer for ulike grupper i datasettet. Funksjonen group_by grupperer dataene slik at når man bruker summarise etterpå, så blir resultatene per gruppe. Her er samme oppsummering som ovenfor, men gruppert:\n\ndinedata %&gt;% \n  group_by(gruppe) %&gt;% \n  summarise(antall = n(), totalt = sum(varA), gjennomsnitt = mean(varA), standardavvik = sd(varA)) \n\n# A tibble: 3 × 5\n  gruppe antall totalt gjennomsnitt standardavvik\n  &lt;chr&gt;   &lt;int&gt;  &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n1 a           2      7          3.5         0.707\n2 b           2      7          3.5         2.12 \n3 c           2     10          5           2.83 \n\n\nMerk at når et datasett først er gruppert, så vil alle utregninger fortsette å være gruppert helt til du legger til ... %&gt;% ungroup().\nMerk at summarise gjør at man bare får ut de aggregerte tallene. Noen ganger trenger man å inkludere en aggregert sum i de opprinnelige dataene. Et eksempel er hvis man vil regne ut for hver observasjon om den er over eller under gjennomsnittet i gruppen (eller totalt). Det følgende eksempelet lager nye variable med antall i gruppen og gjennomsnittet, regner avvik fra gjennomsnittet for hver observasjon og så “dummy” for om observasjonen er over gjennomsnittet eller ikke.\n\ndinedata %&gt;% \n  group_by(gruppe) %&gt;% \n  mutate(antall = n(), gjennomsnitt = mean(varA), \n         avvik = varA - gjennomsnitt, \n         over_snittet = ifelse(avvik &gt; 0, 1, 0)) \n\n# A tibble: 6 × 6\n# Groups:   gruppe [3]\n  gruppe  varA antall gjennomsnitt avvik over_snittet\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;int&gt;        &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n1 a          3      2          3.5  -0.5            0\n2 b          5      2          3.5   1.5            1\n3 b          2      2          3.5  -1.5            0\n4 a          4      2          3.5   0.5            1\n5 c          3      2          5    -2              0\n6 c          7      2          5     2              1\n\n\nResultatene kommer ut i samme rekkefølge som de var fra før selv om dataene er gruppert. Noen ganger trenger vi også å sortere dataene med funksjonen arrange. Akkurat her kan sortering være greit bare for å få et ryddigere output.\n\ndinedata %&gt;% \n  group_by(gruppe) %&gt;% \n  mutate(antall = n(), gjennomsnitt = mean(varA), \n         avvik = varA - gjennomsnitt, \n         over_snittet = ifelse(avvik &gt; 0, 1, 0)) %&gt;% \n  arrange(gruppe)\n\n# A tibble: 6 × 6\n# Groups:   gruppe [3]\n  gruppe  varA antall gjennomsnitt avvik over_snittet\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;int&gt;        &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n1 a          3      2          3.5  -0.5            0\n2 a          4      2          3.5   0.5            1\n3 b          5      2          3.5   1.5            1\n4 b          2      2          3.5  -1.5            0\n5 c          3      2          5    -2              0\n6 c          7      2          5     2              1\n\n\nOvenfor ser du eksempler på at flere funksjoner settes sammen med “pipe”, %&gt;%. Man kan sette sammen så mange slike man vil, men det er en fordel å ikke ha så mange at man mister oversikten: da bør du heller dele opp og lage noen nye objekter som mellomtrinn. Merk at i en slik rekke av funksjoner så utføres operasjonene i rekkefølge. Hvis du f.eks. lager en ny variabel kan du bruke den til å filtere etterpå, men ikke før du har laget den.\nHer er et eksempel der vi ønsker å få ut den observasjonen i hver gruppe som har høyeste positive avvik fra gjennomsnittet. Da sorteres det først på både gruppe og avvik, men merk at for avviket vil vi ha det sortert fra høyeste verdi til laveste verdi som angis med desc(avvik). (Funksjonen desc er forkortelse for “descending”, altså synkende). Deretter filtreres det ved å plukke ut den første observasjonen i hver gruppe, og til dette brukes en funksjon som nummererer radene i hver gruppe row_number().\n\ndinedata %&gt;% \n  group_by(gruppe) %&gt;% \n  mutate(antall = n(), gjennomsnitt = mean(varA), \n         avvik = varA - gjennomsnitt) %&gt;% \n  arrange(gruppe, desc(avvik)) %&gt;% \n  filter(row_number() == 1)\n\n# A tibble: 3 × 5\n# Groups:   gruppe [3]\n  gruppe  varA antall gjennomsnitt avvik\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;int&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 a          4      2          3.5   0.5\n2 b          5      2          3.5   1.5\n3 c          7      2          5     2  \n\n\nDet er mulig det ovenstående ikke fremstår veldig nyttig. Men poenget er å introdusere noe grunnleggende om hvordan R og tidyverse fungerer. Det gjør det lettere å forstå det etterfølgende kapitlene - som er konkret nyttige.\n\n\n\n3.5.2 Grafikk: {ggplot2}\n“Base R” har en del innebygde funksjoner for å lage grafikk som vi ikke dekker her. Grunnen til dette er at vi vektlegger funksjonen fra tidyverse ggplot. Det er noen viktige grunner til dette:\n\nggplot fungerer det sømløst med arbeidsflyten vi har vist over\nggplot er en fullstendig gramatikk for all slags grafiske fremstillinger av data. Vi ser på det grunnleggende her, men dette kan også brukes til å lage 3D-fremstillinger, kart og animasjoner og mye mer.1\nggplot gir ikke bare funksjonelle plot, men også i professjonelt publiserbar kvalitet. Selv hvis forlag har sære krav til fonter, fargebruk, dimensjoner og formater, så kan det fikses i ggplot. Dessuten blir det pent.\n\nFørste kapittel om deskriptiv statistikk handler om grafikk og vi går inn i detaljene der etterhvert som det trengs der.\nEt viktig moment i ggplot er at det er lagdelt og hvert lag skilles med + på en måte som ligner på “pipe”. Man kan så legge på flere lag oppgå det første laget. En vanlig feilmelding i starten er at man bruker %&gt;% når det skulle vært +.\n\n\n3.5.3 Import av data: {haven}\nR kan importere det aller meste av dataformater, men spesielt for samfunnsvitenskapen er noen formater som primært er brukt i samfunnsvitenskap. Det gjelder Stata, SPSS og SAS. Pakken {haven} er en del av tidyverse og tar seg av dette. Dette er forklart nærmere i kapittelet om import av data."
  },
  {
    "objectID": "kort_intro_R.html#andre-nyttige-ting",
    "href": "kort_intro_R.html#andre-nyttige-ting",
    "title": "3  En veldig kjapp intro til R",
    "section": "3.6 Andre nyttige ting",
    "text": "3.6 Andre nyttige ting\n\n3.6.1 Hjelpfiler / dokumentasjon\nDokumentasjonen i R er ofte ganske vanskelig å lese når man ikke er så god (ennå) i å bruke R. Det tar rett og slett litt tid å bli vant til hvordan ting fungerer. Hjelpfilene er skrevet slik at de er lette å finne frem i for erfarne brukere, men du er kanskje ikke der riktig ennå? Her gis en liten introduksjon for å hjelpe deg til å komme igang. Men ellers vil det meste du trenger å kunne forklares fortløpende etterhvert som funksjonene introduseres. Så foreløpig er rådet å ikke stresse med å finne ut av dette ennå. Men det er greit å vite at de finnes!\nAlle R-pakker kommer med egne dokumentasjonsfiler, og det er en slik fil til hver funksjon. Denne åpnes med kommandoen ? foran navnet på funksjonen. For å se nærmere på funksjonen for å lese inn csv-filer, read.csv blir det altså ?read.csv. Hjelpfilen åpens i en egen fane i Rstudio.\nNoen ganger er det flere funksjoner som er varianter av hverandre som står i samme dokumentasjon. F.eks. vil dokumentasjonen for read.csv også inneholde read.table, read.delim og et par andre. De har samme argumenter og struktur, og altså samme dokumentasjon.\nHjelpfiler har en fast struktur. Under overskriften Usage står koden med angitte forvalg for funksjonen(e). Hvis man ikke angir annet, så er det disse argumentene som brukes. Det gjør at man ofte ikke behøver å spesifisere så mye kode hver gang. Hvis man ønsker å gjøre noe annet må man imidlertid angi de relevante argumentene.\nUnder overskriften Arguments vil det stå spesifisert hva hvert argument gjør, og ofte angitt hvilke verdier som er gyldige å angi.\nUnder overskriften Details vil det gjerne være noe nærmere forklart, gjøre oppmerksom på spesielle utfordringer etc.\nUnder overskriften Value kan det stå noe mer om hva som kommer ut av funksjonen. Dette kan være hva slags objekt det blir eller andre ting.\nUnder overskriften See Also vil det være referanser til andre funksjoner som er relevante, enten alternativer eller tilleggsfunksjoner etc.\nOverskriften Examples er gjerne den mest nyttige. Det er rett og slett noen korte kodesnutter som illustrerer bruken.\n\n3.6.1.1 Vignetter\nAlle R-pakker publiseres på en server, CRAN, og hver pakke har sin egen side. Du kan gå inn på denne direkte. Her er lenken til tidyverse på CRAN. Under overskriften Dokumentation vil det være en lenke til en referansemanual, som er den samme som når du bruker ? i R, men her får du alt tilhørende pakken i en samlet pdf-fil.\nFor mange pakker vil deg også være lenker til “Vignettes”. Disse er gjerne mer utførlige tekster som forklarer pakkens struktur og viser bruk. Disse er gjerne de mest nyttige for vanlige brukere. Noen ganger er det egne nettsider for disse pakkene og vignettene. Det er lenket til flere slike i det etterfølgende.\n\n\n\n3.6.2 Bruke pakker uten å laste dem\nDet hender at man trenger å bruke en funksjon fra en spesifikk pakke én gang og derfor ikke har behov for å laste pakken. Som nevnt ovenfor hender det at funksjoner har samme navn i ulike pakker slik at det finnes en konflikt der R kan komme til å bruke en annen funksjon enn du hadde tenkt. Det burde ikke være et problem i noe av det som dekkes i dette heftet, men kan være greit å vite likevel.\nEn funksjon fra en spesifikk pakke kan angis med pakkenavn::funksjon(). Her er et eksempel der man eksplisitt angir å bruke funksjonen summarise fra pakken {dplyr}.\n\ndplyr::summarise(dinedata, antall = n(), snitt = mean(varA))\n\n  antall snitt\n1      6     4\n\n\n\n\n3.6.3 Få hjelp av chatGPT\nDet er mye snakk om kunstig intelligens for tiden, og AI er overalt. En av de tingene som AI-verktøy som chatGPT faktisk er god på er å skrive kode i mange språk, deriblant R. Det er imidlertid ingenting ved chatGPT som gjør at du ikke trenger å kunne skrive kode selv.2 Du må nemlig vite om løsningen gjør det du faktisk ønsker.\nEffektiv bruk av chatGPT innebærer at du kan formulere promptet godt. For å få til det bør du derfor vite hva du driver med. Du trenger også kunnskap og erfaring for å se om kodeforslaget ser rimelig ut, og vurdere om løsningen bruker riktige pakker. Det er ofte lurt å spesifisere at du vil ha en løsning med tidyverse eller andre spesifikke pakker. Oppfølgingsspørsmål kan også være nødvendig.\nDu må aldri bruk kode fra chatGPT (eller andre verktøy) uten at du forstår hva koden faktisk gjør. Det kan innebære at du må teste koden på dine data grundig. Det krever også ferdigheter. Du må rett og slett ha et godt grunnlag for å forstå koden. I mellomtiden kan du godt bruke chatGPT til å lære deg R.\nHvis du skal bruke chatGPT så bør du starte med å bruke det til å forstå instruksjoner du har problemer med. Prøv ut med følgende prompt:\n\nKan du forklare følgende kode? \n  dinedata %&gt;% \n  group_by(gruppe) %&gt;% \n  mutate(antall = n(), gjennomsnitt = mean(varA), \n         avvik = varA - gjennomsnitt) %&gt;% \n  arrange(gruppe, desc(avvik)) %&gt;% \n  filter(row_number() == 1)\n\n\nDu kan også bruke chatGPT til å finne feil i koden du ikke klarer å finne ut av selv. Du kan legge til en “kontekst” og be chatGPT om å finne feilen som gjør at du ikke får det resultatet du forventer. Prøv ut med følgende prompt:\n\nJeg ønsker å få aggregerte statistikker for et datasett, men det blir ikke riktig. Jeg ønsker å få en linje per gruppe, men resultatet gir aggregering per observasjon i stedet for en linje per gruppe. Kan du finne feilen i følgende kode?  \n  dinedata %&gt;% \n  group_by(gruppe) %&gt;% \n  mutate(antall = n(), gjennomsnitt = mean(varA), \n         avvik = varA - gjennomsnitt) %&gt;% \n  arrange(gruppe, desc(avvik)) %&gt;% \n  filter(row_number() == 1)\n\n\nMerk at chatGPT da vil foreslå en løsning, men det kan godt hende du får et litt annet svar enn det som er gjengitt ovenfor. Det er ikke gitt at den forstår problemet ditt korrekt og løsningen er heller ikke nødvendigvis riktig!\nFor å få et godt svar er det viktig at du i promptet gir en god beskrivelse av konteksten, som innebærer hva du ønsker å gjøre, hva resultatet blir og hva du tror er feil. For at dette skal fungere godt trenger du altså å forstå problemet ditt og beskrive det så tydelig som mulig. Så må du teste løsningen på din egen datamaskin og sjekke at det faktisk fungerer.\n\n\n3.6.4 OBS! chatGPT code interpreter\nI betalingsversjonen av chatGPT får man tilgang til appen code interpreter der man kan laste opp data og få dem analysert “ferdig”. Eller: tilsynelatende ferdig. Det finnes helt sikkert også andre tilsvarende AI-verktøy.\nMerk at alt du laster opp eller skriver inn i chatGPT innebærer å dele data både med tjenesten og potensielt senere brukere. Å laste opp persondata er slik sett i utgangspunktet et brudd med GDPR og de tillaltelsene du har til bruk av data. For å bruke slike tjenester bør du være veldig sikker på de dataene du bruker kan deles helt fritt.\nI tillegg er det selvsagt også slik at\nDu skal altså ikke bruke chatGPT code interpreter! Ikke under noen omstendighet, egentlig.\n\n\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of Statistical Software 59. https://doi.org/10.18637/jss.v059.i10.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science. Beijing, China: https://r4ds.had.co.nz/index.html; O’Reilley."
  },
  {
    "objectID": "kort_intro_R.html#footnotes",
    "href": "kort_intro_R.html#footnotes",
    "title": "3  En veldig kjapp intro til R",
    "section": "",
    "text": "Dette er i kontrast til annen statistikksoftware som i større grad er basert på enkeltfunksjoner for mer avgrensede typer grafikk.↩︎\nNei, heller ikke med code interpreter.↩︎"
  },
  {
    "objectID": "norlag.html#tilgang-og-lagring",
    "href": "norlag.html#tilgang-og-lagring",
    "title": "4  Datasettet NorLAG",
    "section": "4.1 Tilgang og lagring",
    "text": "4.1 Tilgang og lagring\nNorLAG er gule data og har restriksjoner på bruk og lagring. Du er pliktet til å sette deg inn i retningslinjene som du finner på denne siden.\nI denne sammenhengen betyr det i praksis at du bør jobbe på UiO-OneDrive. Altså: ikke lagre data på din personlige datamaskin og ikke skytjeneste med en personlig konto. Merk at det er forskjell på f.eks. OneDrive gjennom UiO og privat, og privat konto er ikke tillatt for slike data.\nFor å få tilgang på datasettet må du gjøre følgende:\n\nOppgi din uio-epostadresse i dette nettskjemaet. Emneansvarlig legge deg inn i systemet.\nDu får tilsendt en lenke fra Sikt med videre instruksjoner om hvordan du signerer en avtale. Les avtalen og signer digitalt.\nLast ned pdf-versjon av den signerte avtalen og behold den for senere referanse. Du kan også gjøre det senere ved å logge inn på Sikt sine sider for data access.\nLaster opp den signerte avtalen i dette skjemaet.\nEmneansvarlig vil dele en mappe med deg i Sharepoint der du kun har lesetilgang. Her ligger tilrettelagte versjoner av datasettet.1 Kopier alle filene over til en lokal mappe i din UiO-OneDrive (se ovenfor).\n\nOBS!! Dere signerer en avtale om bruk av data som er begrenset til å brukes til metodeundervisningen på master i sosiologi ved UiO. Den avtalen har også en begrensning i tid. Les avtalen nøye. Dere har et selvstendig ansvar for å overholde betingelsene, herunder at dataene skal slettes innen angitt dato. Det er fult mulig å bruke disse dataene til senere prosjekter, f.eks. til masteroppgave, men da må det søkes på nytt.2\n\n4.1.1 Innlesning av data\nDatasettet norlag.rds er altså konvertert til R-formatet rds. Når dette er gjort er du klar for både forkurset og SOS4020.\nNest økt vil omhandle innlesning av data: både rds og andre vanlige formater. For eksemplene her vil det brukes noen forenklede datasett med færre variable."
  },
  {
    "objectID": "norlag.html#footnotes",
    "href": "norlag.html#footnotes",
    "title": "4  Datasettet NorLAG",
    "section": "",
    "text": "Du kan også laste ned et datasett fra plattformen til Sikt, men vi skal kun bruke de tilrettelagte dataene i forkurset. Som du vil lære om i dette kurset er det ikke alltid import av data helt lett.↩︎\nHvis dere skriver ryddige script nå, så kan alt dere gjør lett reproduseres senere slik at ny søknad og ny utlevering av data ikke skal medføre merarbeid med data.↩︎"
  },
  {
    "objectID": "innlesning_data.html#generelt-om-ulike-dataformat",
    "href": "innlesning_data.html#generelt-om-ulike-dataformat",
    "title": "5  Innlesning av data",
    "section": "5.1 Generelt om ulike dataformat",
    "text": "5.1 Generelt om ulike dataformat\n\n5.1.1 rds\nRds-formatet er et format særlig egnet for R.\n\n\n5.1.2 Laste workspace med load()\nFiler av typen .Rdat eller .Rdata er egentlig ikke et dataformat, men brukes tidvis for å lagre datafiler. Man kan lagre en eller flere datafiler i samme .Rdat fil på disk.\nDu kan også lagre et “speilbilde” av hele ditt workspace på denne måten slik at du kan lukke R og så åpne R senere akkurat på det stedet du var i arbeidet. Det kan være kjekt, men forutsetter at du husker hva du drev med forrige gang. Den klare anbefalingen er derfor å ikke bruke dette rutinemessig.\n\n\n5.1.3 csv-filer\nSåkalte csv-format er ren tekstformat der verdiene i kollonnene har skilletegn. Skilletegnet er nesten alltid komma eller semikolon, men kan i prinsippet være hva som helst. Noen ganger vil slike\n\n\n5.1.4 Excel\nForbløffende mye data foreligger i Excel-format. Det finnes egne funksjoner for å jobbe direkte med excel-filer. Blant annet pakken readxl gir funksjoner til å lese inn denne typen filer. Her er et eksempel.\n\nlibrary(readxl)\nnorlag_xlsx &lt;- read_excel(\"data/norlag_panel.xlsx\")\nglimpse(norlag_xlsx)\n\nRows: 20,892\nColumns: 12\n$ ref_nr  &lt;dbl&gt; 5, 5, 10, 10, 10, 12, 12, 15, 15, 18, 18, 22, 23, 23, 25, 27, …\n$ round   &lt;dbl&gt; 1, 2, 3, 2, 1, 3, 1, 1, 2, 3, 2, 1, 3, 1, 1, 3, 2, 1, 2, 1, 3,…\n$ ioalder &lt;chr&gt; \"68\", \"72\", \"59\", \"49\", \"44\", \"61\", \"47\", \"58\", \"63\", \"67\", \"5…\n$ iolandb &lt;chr&gt; NA, \"Norskfødt\", NA, \"Norskfødt\", NA, NA, NA, NA, \"Norskfødt\",…\n$ iokjonn &lt;chr&gt; \"Mann\", \"Mann\", \"Kvinne\", \"Kvinne\", \"Kvinne\", \"Kvinne\", \"Kvinn…\n$ pa001c  &lt;chr&gt; \"Ja\", \"Ja\", \"Ja\", \"Ja\", \"Nei\", \"Ja\", \"Ja\", \"Nei\", \"Nei\", \"Ja\",…\n$ pa300   &lt;chr&gt; \"Partner gjør mest\", NA, NA, NA, NA, NA, \"IO gjør mest\", NA, N…\n$ hc230   &lt;chr&gt; \"En gang i uken\", \"En gang i uken\", \"2-3 ganger i måneden\", \"E…\n$ hc231   &lt;chr&gt; \"2-3 ganger i måneden\", \"2-3 ganger i måneden\", NA, \"2-3 gange…\n$ va207   &lt;chr&gt; \"Ganske viktig\", \"Litt viktig\", \"Litt viktig\", \"Ikke viktig\", …\n$ hcMCS12 &lt;chr&gt; \"59.7766\", \"60.68044\", \"58.74768\", \"60.69717\", \"55.86777\", \"53…\n$ hcPCS12 &lt;chr&gt; \"54.83583\", \"51.03453\", \"55.92348\", \"55.25834\", \"55.91285\", \"5…\n\n\nMen Excel-filer kan ha en litt mer komplisert struktur enn dette eksempelet. Data kan ligge i ulike faner i Excel-filen, men det kan da håndteres med å legge til argumentet sheet = .... Hvis excel-arket inneholder mye tekst eller andre ting som gjør at de faktiske dataene kommer litt lengre ned, så kan det spesifiseres hvilket celleområde som det skal leses inn fra ved range = ... eller bare hoppe over noen rader med skip = ....\nPå dette kurset skal vi ikke bruke Excel-filer, men det er stor sannsynlighet for at du vil få bruk for dette senere en gang.\n\n\n5.1.5 Proprietære format: Stata, SPSS og SAS\n\n5.1.5.1 Stata\n\nnorlag_dta &lt;- read_stata(\"data/norlag_panel.dta\")\nglimpse(norlag_dta)\n\nRows: 20,892\nColumns: 12\n$ ref_nr  &lt;dbl&gt; 5, 5, 10, 10, 10, 12, 12, 15, 15, 18, 18, 22, 23, 23, 25, 27, …\n$ round   &lt;dbl&gt; 1, 2, 3, 2, 1, 3, 1, 1, 2, 3, 2, 1, 3, 1, 1, 3, 2, 1, 2, 1, 3,…\n$ ioalder &lt;dbl+lbl&gt; 29, 33, 20, 10,  5, 22,  8, 19, 24, 28, 18, 24, 30, 16, 32…\n$ iolandb &lt;dbl+lbl&gt; NA,  1, NA,  1, NA, NA, NA, NA,  1, NA,  1, NA, NA, NA, NA…\n$ iokjonn &lt;dbl+lbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2…\n$ pa001c  &lt;dbl+lbl&gt; 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1…\n$ pa300   &lt;dbl+lbl&gt;  1, NA, NA, NA, NA, NA,  2, NA, NA, NA, NA,  3, NA, NA, NA…\n$ hc230   &lt;dbl+lbl&gt; 3, 3, 4, 3, 3, 9, 9, 1, 1, 9, 9, 1, 9, 3, 4, 3, 3, 4, 4, 3…\n$ hc231   &lt;dbl+lbl&gt;  4,  4, NA,  4,  3, NA,  9,  2,  1, NA,  9,  2, NA,  4,  5…\n$ va207   &lt;dbl+lbl&gt; 2, 3, 3, 4, 3, 5, 5, 3, 4, 5, 5, 1, 5, 3, 3, 2, 3, 3, 4, 4…\n$ hcMCS12 &lt;dbl+lbl&gt; 6350, 6647, 5994, 6650, 4891, 4121, 6672, 4736, 3529, 4632…\n$ hcPCS12 &lt;dbl+lbl&gt; 7085, 6420, 7258, 7149, 7255, 7544, 7355, 6956, 7368, 7342…\n\n\nLegg merke til at den andre kolonnen her viser hva slags variabeltype det er. &lt;dbl&gt; betyr at det er numerisk variabel^(Det finnes flere typer numeriske variable som vi for praktiske analyser sjelden behøver å forholde oss til. &lt;dbl&gt; står for Double som er et lagringsformat som kan ta svært mange desimaler. Det kan også stå &lt;num&gt; som håndterer færre desimaler. Det er også vanlig med &lt;int&gt; som står for Integer, altså heltall uten desimaler.) På noen variable står det også &lt;dbl+lbl&gt; der lbl står for labelled som betyr at det finnes såkalte labler tilhørende variabelen. Labler er vanlig å bruke i programmene Stata og SPSS, men er ikke noe som vanligvis brukes i R. Men R leser det inn og kan håndtere dette helt fint. Men som hovedregel er det bedre å rydde opp slik at dataene blir slik vi vanligvis bruker det i R. Dette er grunnen til at dere får en bearbeidet versjon av NorLAG datasettet!\nNeste kapittel er spesielt om NorLAG i formatet .rds. Hvordan effektivt lese inn fra Stata til R og gjøre om labler er dekket i et appendiks. De av dere som senere skal jobbe med data levert ut fra Sikt kan ha behov for dette, og da kan dere ta en nærmere titt på appedikset. For dette forkurset og SOS4020 vil dere ikke trenge kunne akkurat det.\n\n\n5.1.5.2 SPSS og SAS\nAndre vanlige dataformater er formater fra statistikkpakkene SPSS og SAS, med filhalene henholdsvis .sav og .sas7bdat. De leses inn på tilsvarende funksjoner tilpasset disse dataformatene. Her er eksempel for innlesning av SPSS-fil:\n\nnorlag_sav &lt;- read_spss(\"data/norlag_panel.sav\")\n\nHer er eksempel for innlesning av SAS-fil:\n\nnorlag_sas &lt;- read_sas(\"data/norlag_panel.sas7bdat\")\n\n\n\n\n5.1.6 Dataformater for store data\nDet finnes en hel rekke andre formater for spesielle formål, derav formater for store data. Med store data mener vi her enten at de er så store at det upraktisk lang tid å lese det inn - eller så store at det ikke er plass i minnet på datamaskinen. Formatene feather og parquet er varianter av det samme og håndteres med pakken Arrow. Det finnes også andre pakker for store data, men Arrow er nå den anbefalte. En annen grunn til det er at disse datasettene tillater sømløs bytte mellom programmeringsspråkene R og Python. Men det går laaaagt utenfor formålet med dette forkurset.\nFor mer spesielle behov går det også an å koble mot databaser som MySQL, Spark, Oracle eller noe helt annet, og en oversikt finnes her.\nEneste du trenger være klar over akkurat nå er at R kan håndtere svært mange forskjellige dataformater og koble mot andre løsninger. Kanskje vil du trenge det en gang - kanskje ikke."
  },
  {
    "objectID": "innlesning_data.html#oppgaver",
    "href": "innlesning_data.html#oppgaver",
    "title": "5  Innlesning av data",
    "section": "5.2 Oppgaver",
    "text": "5.2 Oppgaver\n\nExercise 5.1 Les inn datasettet… i rds-format\n\n\nExercise 5.2 Les inn datasettet… i xlsx-format\n\n\nExercise 5.3 Noen ganger vil datamaskiner være konfigurert slik at filhalene ikke synes. Det betyr jo ikke at de ikke er der, men du ser ikke umiddelbart hva slags fil det er. Finn ut hvordan du endrer dette på din datamaskin. Prøv å skru det av og på. For å finne det ut, søk på internett med søkestrengen “how to display file extension” eller tilsvarende."
  },
  {
    "objectID": "oversikt_datasettet.html#sjekk-om-innlesning-ble-riktig",
    "href": "oversikt_datasettet.html#sjekk-om-innlesning-ble-riktig",
    "title": "6  Få oversikt over datasettet",
    "section": "6.1 Sjekk om innlesning ble riktig",
    "text": "6.1 Sjekk om innlesning ble riktig\nDet første man bør sjekke er jo om innlesning av datasettet ble riktig. Skjer det noe feil her, så blir selvsagt alt annet feil. Men det er lite som kan gå galt når man leser inn fra datasett. Et unntak er csv-filer som ikke har metadata inkludert.\nFunksjonen class() gir informasjon om hva slags objekt man har. Altså: etter at man har lest inn dataene og lagt det i et objekt. Her sjekkes objektet norlag:\n\nclass(norlag)\n\n[1] \"data.frame\"\n\n\nI dette tilfellet får vi tre beskjeder. Det er en kombinert objekttype av tibble og data.frame. Mens data.frame er standard datasett tilsvarende som et regneark, så er tibble en utvidelse med noen ekstra funksjoner som er nyttige for avanserte brukere, men er å regne som en utvidelse av data.frame. For vårt formål vil det i praksis være det samme. Et datasett som leses inn i R bør altså være av typen tbl eller data.frame. Data kan også ha andre typer strukturer og da vil class() rapportere noe annet.\nNår man bruker funksjoner i R, så vil noen ganger resultatet avhenge av hva slags type objekt det er.\nFor å vite hvor mange rader og kolonner det er i datasettet kan man bruke funksjonen dim() slik:\n\ndim(norlag)\n\n[1] 20892  2605\n\n\nHer får vi vite at det er 20892 rader (dvs. observasjoner) og 2605 kollonner (dvs. variable).\n\n6.1.1 Bruke View()\nSærlig når man er uvant med å jobbe i R vil man kunne ha behov for å se på dataene slik man er vant til fra regneark eller software som SPSS eller Stata. En mulighet er å bruke funksjonen View() så vil hele datafilen åpnes i eget vindu. Dette er kun egnet for å se på dataene og du kan lukke vinduet uten at det påvirker dataene. Dataene ligger fremdeles i det samme objektet på samme måte som før.\n\nView(norlag)\n\nHvis variablene ser ut til å ha forventede variabelnavn og verdier, så er det antakeligvis ok.\nEt slikt datasett tar imidlertid stor plass og det er vanligvis mer hensiktsmessige måter å se på dataene på som også gir mer informasjon. I R er det ikke meningen at du skal “sitte og se på dataene” på den måten mens man jobber. Men ta gjerne en titt for å få et bedre inntrykk av hvordan dataene ser ut.\nDu kan lukke det vinduet med dataene uten at det har noe å si for dataene, som fremdeles er tilgjengelig i minnet på datamaskinen på samme måte som før.\n\n\n6.1.2 Bruke head()\nFunksjonen head() skriver de første 6 observasjonenen til konsollen i Rstudio. Det gir et første inntrykk av datasettet med variabelnavn og de første verdiene uten å åpne hele datasettet. Hva som faktisk vises vil avhenge av hvor stor skjerm du har, men R vil bare vise de første variablene etter hva som er plass til på skjermen din. For datasett med mer enn noen få variable er ikke dette veldig nyttig, men noen ganger har man små datasett. Med en liten skjerm kan dette da se omtrent slik ut:\n\nhead(norlag)\n\n\nLegg merke til at under hvert variabelnavn er det en indikasjon på hva slags variabeltype det er. For eksempel betyr &lt;dbl&gt; at det er en numerisk variabel mens &lt;dbl+lbl&gt; indikerer at variabelen inneholder labels.\nDet er lite hensiktsmessig å vise alt i konsollen fordi det rett og slett ikke er plass. Nerst står det derfor angitt at det er flere variable som ikke vises og navnet på de første av disse.\n\n\n6.1.3 Subset med klammeparenteser\nEn enkel løsning er å bare se på noen få variable om gangen. Med klammeparentes kan vi angi hvilke radnummer og kolonnenummer vi ønsker se på med følgende syntax: datasett[rader, kolonner] der altså komma skiller mellom rader og kolonner. Følgende eksempel viser hvordan man kan bruke head() for å vise de første observasjonene i datasettet med bare de første 5 variablene (altså: kollonne nr 1-5).\n\nhead(norlag[, 1:5])\n\n  ref_nr         iodeltakelse iododaar iofodselsaar iokjonn\n1      5     Deltatt T1 og T2     &lt;NA&gt;         1934    Mann\n2      5     Deltatt T1 og T2     &lt;NA&gt;         1934    Mann\n3     10 Deltatt T1, T2 og T3     &lt;NA&gt;         1957  Kvinne\n4     10 Deltatt T1, T2 og T3     &lt;NA&gt;         1957  Kvinne\n5     10 Deltatt T1, T2 og T3     &lt;NA&gt;         1957  Kvinne\n6     12     Deltatt T1 og T3     &lt;NA&gt;         1955  Kvinne\n\n\nVi kan altså også angi både rader og kollonner på denne måten. Her er eksempel som viser første 3 rader og variabelnummer 40 til 44.\n\nhead(norlag[1:3, 40:44])\n\n  hc201 hc202 hc203 hc204 hc205\n1   176    85    Ja   Nei    Ja\n2   176    95    Ja   Nei    Ja\n3   168    64    Ja   Nei    Ja\n\n\nLegg merke til at under hvert variabelnavn står det en liten tekst, f.eks.  eller &lt;S3: haven_labelled&gt;. Det kan også stå andre ting. dbl betyr at det er en kontinuerlig variabel, mens haven_labelled betyr at det er labler til alle eller noe verdier i variabelen.\nVi skal primært jobbe med data som ikke er “labelled”, men du vil noen ganger komme borti dette, spesielt hvis du importerer data fra andre statistikksoftware.\n\n\n6.1.4 Bruke ‘glimpse()’\nI tidligere kurs skal dere ha lært å bruke funksjonen glimpse(), men også her blir det mest rotete fordi det er så mange variable. Det tar rett og slett veldig stor plass på skjermen.\nEn variant er å bruke glimpse() bare på et utvalg variable på tilsvarende måte. Her er et eksempel, men der vi ser på de 20 første variablene ved bruk av klammeparentes tilsvarende som vist over.\n\nglimpse(norlag[, 1:20])\n\nRows: 20,892\nColumns: 20\n$ ref_nr          &lt;dbl&gt; 5, 5, 10, 10, 10, 12, 12, 15, 15, 18, 18, 22, 23, 23, …\n$ iodeltakelse    &lt;fct&gt; \"Deltatt T1 og T2\", \"Deltatt T1 og T2\", \"Deltatt T1, T…\n$ iododaar        &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2006, NA, …\n$ iofodselsaar    &lt;dbl&gt; 1934, 1934, 1957, 1957, 1957, 1955, 1955, 1944, 1944, …\n$ iokjonn         &lt;fct&gt; Mann, Mann, Kvinne, Kvinne, Kvinne, Kvinne, Kvinne, Kv…\n$ ionorlag1kohort &lt;fct&gt; Del av NorLAG1 kohort, Del av NorLAG1 kohort, Del av N…\n$ iopafyll        &lt;fct&gt; Ingen påfyll, Ingen påfyll, Ingen påfyll, Ingen påfyll…\n$ iovektnorlag2   &lt;fct&gt; 143, 143, 51, 51, 51, NA, NA, 195, 195, 215, 215, NA, …\n$ iovektnorlag3   &lt;fct&gt; NA, NA, 73, 73, 73, 135, 135, NA, NA, 227, 227, NA, 39…\n$ pr002c          &lt;fct&gt; 1905, 1905, 1933, 1933, 1933, 1918, 1918, 1918, 1918, …\n$ pr003c          &lt;fct&gt; 1991, 1991, NA, NA, NA, 2004, 2004, 1989, 1989, NA, NA…\n$ pr005c          &lt;fct&gt; 1905, 1905, 1933, 1933, 1933, 1915, 1915, 1909, 1909, …\n$ pr006c          &lt;fct&gt; 1996, 1996, NA, NA, NA, 1996, 1996, 1975, 1975, 1976, …\n$ pr007c          &lt;fct&gt; Grunnskole, Grunnskole, Videregående, Videregående, Vi…\n$ pr011c          &lt;fct&gt; Videregående, Videregående, Grunnskole, Grunnskole, Gr…\n$ round           &lt;dbl&gt; 1, 2, 3, 2, 1, 3, 1, 1, 2, 3, 2, 1, 3, 1, 1, 3, 2, 1, …\n$ ioalder         &lt;fct&gt; 68, 72, 59, 49, 44, 61, 47, 58, 63, 67, 57, 63, 69, 55…\n$ iointervjumnd   &lt;fct&gt; 5, 11, 5, 5, 5, 8, 5, 8, 3, 3, 5, 8, 5, 8, 2, 5, 9, 4,…\n$ iointervjuaar   &lt;fct&gt; 2002, 2007, 2017, 2007, 2002, 2017, 2002, 2002, 2007, …\n$ iolandb         &lt;fct&gt; NA, Norskfødt, NA, Norskfødt, NA, NA, NA, NA, Norskfød…\n\n\nI denne output’en er den første kollonnen altså variabelnavnene, deretter er det en kollonne som viser hva slags type variabel det er, og deretter de første observasjonene på hver variabel slik at man får et inntrykk av hvordan det ser ut. glimpse() gir altså omtrent samme informasjon som head(), men er nok mer hensiktsmessig hvis mange variable.\n\n\n6.1.5 Undersøke enkeltvariable med codebook() fra pakken {memisc}\nNoen ganger vil man ha litt mer informasjon om enkeltvariablene. Noen datasett vil komme med labler (omtalt annet sted) eller faktorvariable, som gjør at variablene inneholder både tallverdier og tekst.\nÅ få ut noe deskriptiv statistikk og se på fordelinger er da gjerne neste steg som vil bli behandlet i de etterfølgende kapitlene.\nMan vil klare seg greit med det vi har vist ovenfor. Men det finnes flere måter å gjøre det på. Pakken {memisc} inneholder en rekke funksjoner for å håndtere surveydata, som vi ikke skal gå nærmere inn på her. Men akkurat funksjonen codebook() gir litt mer informativt output enn look_for().\nFor å bruke denne må du installere pakken først. I eksempelet nedenfor er pakken ikke lastet med library(), men angitt pakken direkte med memisc:: først. Dette kan være nyttig hvis man ikke skal bruke noen andre funksjoner fra denne pakken.\n\nmemisc::codebook(norlag$iokjonn)\n\n================================================================================\n\n   norlag$iokjonn 'IOs kjønn'\n\n--------------------------------------------------------------------------------\n\n   Storage mode: integer\n   Factor with 2 levels\n\n   Levels and labels     N Valid\n                                \n   1 'Mann'          10244  49.0\n   2 'Kvinne'        10648  51.0\n\n\nPoenget her er altså bare å få en penere output og litt deskriptiv statistikk samtidig."
  },
  {
    "objectID": "oversikt_datasettet.html#søke-i-datasettet-etter-variable",
    "href": "oversikt_datasettet.html#søke-i-datasettet-etter-variable",
    "title": "6  Få oversikt over datasettet",
    "section": "6.2 Søke i datasettet etter variable",
    "text": "6.2 Søke i datasettet etter variable\nFor å se nærmere på en variabel går an å bruke funksjonen look_for(), som primært er en søke-funksjon, men det gir også informasjon om variabelen.\n\nlook_for(norlag, \"iokjonn\")\n\n pos variable label     col_type missing values\n 5   iokjonn  IOs kjønn fct      0       Mann  \n                                         Kvinne\n\n\nI output fremgår det at dette er den 10’ende variabelen, inneholder informasjonen “IOs kjønn”, er av typen numerisk med tilhørende labler, og verdiene er 1 = Mann og 2 = Kvinne.\nDet går også an å bare få ut variabel-label med funksjonen var_label() slik:\n\nvar_label(norlag$iokjonn)\n\n[1] \"IOs kjønn\"\n\n\nFor å se labels på verdiene bruk val_labels().\n\nval_labels(norlag$iokjonn)\n\nNULL\n\n\nAlle datasett skal komme med en dokumentasjon som sier hva hver variabel inneholder og hvilke verdier som finnes i hver variable, og hva de betyr. Dette leveres gjerne som en separat fil, ganske ofte i pdf eller html format. NSD/Sikt leverer dokumentasjonen for Norlag i html-format. (Ideelt burde det vært i et enkelt maskinlesbart format egnet til å bruke til omkoding og labler for de som ønsker det, men de har valgt en annen løsning).\nDu kan søke i dokumentasjonen på samme måte som i andre filer, men det kan være litt knotete. Et godt alternativ er å søke direkte i datasettet. Funksjonen look_for() søker både i variabelnavn, verdier og labler. Her er et eksempel for hvordan finne variabler som inneholder ordet “yrkesinntekt”. Du kan også søke på kortere eller lengre tekststrenger. (Søker du f.eks. bare på “innt” eller “yrke” så får du opp langt flere variable, så du må kanskje prøve deg litt frem).\n\nlook_for(norlag, \"Yrkesinntekt\")\n\nDet er to variable som inneholder teksten “yrkesinntekt”. Den første variabelen har posisjon 353 i datasettet og har variabelnavnet inwyrkinnt. Den andre variabelen har posisjon 371 og har navnet inpartwyrkinnt. Vi fokuserer på den første.\nMerk at når labelen avsluttes med ~ (uttales “tilde”) indikerer det at teksten er avkortet i outputvinduet. Du får opp hele teksten ved å bruke val_label() slik:\n\nvar_label(norlag$inwyrkinnt)\n\nNULL"
  },
  {
    "objectID": "grafikk.html#lagvis-grafikk",
    "href": "grafikk.html#lagvis-grafikk",
    "title": "7  Grafikk med ggplot",
    "section": "7.1 Lagvis grafikk",
    "text": "7.1 Lagvis grafikk\nI R er det mange funksjoner for å lage grafikk. Noen er spesialiserte og knyttet til spesielle analysemetoder og gir deg akkurat det du trenger. Vi skal her bruke et generelt system for grafikk som heter ggplot som kan brukes til all slags grafikk. Funksjonen ggplot er bygget opp som en gramatikk for grafisk fremstilling. Det ligger en teori til grunn som er utledet i boken ved omtrent samme navn: The grammar of graphics. Det er mye som kan sies om dette, men det viktige er at grafikken er bygget opp rundt noen bestanddeler. Når du behersker disse kan du fremstille nær sagt hva som helst av kvantitativ informasjon grafisk. Dette er altså et system for grafikk, ikke bare kommandoer for spesifikke typer plot. Vi skal likevel bare se på grunnleggende typer plot her.\nSystemet er bygd opp lagvis. Det gjelder selve koden, men også hvordan det ser ut visuelt. Man kan utvide plottet med flere lag i samme plot og det legges da oppå hverandre i den rekkefølgen som angis i koden.\nFor enkle plot som vi skal bruke her angir man i denne rekkefølgen og med en + mellom hver del (vanligvis per linje, men linjeskift spiller ingen rolle). Hver del av koden spesifiserer enten hva som skal plottes eller hvordan det plottes, mens andre deler kan kontrollere utseende på akser, fargeskalaer, støttelinjer eller andre ting som har med layout å gjøre.\n\nAngi data og hva som skal plottes med ggplot()\nAngi hvordan det skal plottes med geom_*()\nAngi andre spesifikasjoner (farger, titler, koordinatsystemer osv)\n\nDette blir tydeligere i eksemplene og forklares underveis.\n\nDet første argumentet i ggplot er data. Altså: hvilket datasett informasjonen hentes fra.\nInni ggplot() må det spesifiseres aes(), “aestethics”, som er hvilke variable som skal plottes. Først og fremst hva som skal på x-akse og y-akse (og evt. z-akse), men også spesifikasjon av om linjer (farge, linjetype) og fyllfarger, skal angis etter en annen variabel.\ngeom_* står for geometric og sier noe om hvordan data skal se ut. Det kan være punkter, histogram, stolper, linjer osv.\ncoord_* definerer koordinatsystemet. Stort sett blir dette bestemt av variablene. Men du kan også snu grafen eller definere sirkulært koordinatsystem, eller andre enklere ting.\nfacet_* definerer hvordan du vil dele opp grafikken i undergrupper"
  },
  {
    "objectID": "grafikk.html#kategoriske-variabel",
    "href": "grafikk.html#kategoriske-variabel",
    "title": "7  Grafikk med ggplot",
    "section": "7.2 Kategoriske variabel",
    "text": "7.2 Kategoriske variabel\n\n7.2.1 Stolpediagram\n\nlibrary(ggforce)\nggplot(abu89, aes(x = klasse89)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\nNoen ganger ønsker man å vise fordelingen for to ulike grupper, la oss si for kjønn. En mulighet er da å rett og slett lage to stolpediagram ved siden av hverandre. Til dette kan man spesifisere at dataene er gruppert etter variabelen female og at fyllfargen skal settes etter denne variablen med fill = factor(female). Merk bruken av factor(female) fordi variabelen er numerisk og det vil da ellers brukes en kontinuerlig fargeskale, mens å gjøre om variabelen til kategorisk brukes en annen fargeskala.\nI tillegg gjør vi her to ting til: setter et annet grafisk tema med theme_minimal() og snur plotvinduet slik at kategoriene er litt lettere å lese. Dette er smak og behag.\n\nggplot(abu89, aes(x = klasse89, group = female, fill = factor(female))) +\n  geom_bar(position=\"dodge\") +\n  theme_minimal()+\n  theme(axis.text.x = element_text(angle = 90))+\n  coord_flip()\n\n\n\n\nEt alternativ er å plassere grafikken for menn og kvinner ved siden av hverandre. Å legge til facet_wrap() gjør dette.\n\nggplot(abu89, aes(x = klasse89)) +\n  geom_bar() +\n  facet_wrap(~factor(female)) +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\nEt automatisk forvalg for geom_bar() er hvordan gruppene plasseres som er position=\"stack\". Det betyr at gruppene stables oppå hverandre. Dette er godt egnet hvis poenget er å vise hvor mange av hvert kjønn som er i hver gruppe. Det er mindre egnet hvis du ønsker å sammenligne menn og kvinner. Da er alternativet å velge position=\"dodge\" som følger:\n\n\n7.2.2 Kakediagram\nGenerelt er ikke kakediagram å anbefale da korrekt tolkning involverer å tolke et areal som inneholder vinkel. Med få kategorier som er rimelig forskjellig kan det gi et ok inntrykk, men ofte ender man opp med å måtte skrive på tallene likevel. Vi tar det med her egentlig bare fordi mange insisterer på å bruke det. Så vet du at det er mulig.\nDet enkleste er å bruke funksjonen pie() som gir følgende resultat.\n\ntab &lt;- table(abu89$klasse89) \ntab\n\n\n    I Øvre serviceklasse   II Nedre serviceklasse   III Rutinefunksjonærer \n                     328                     1181                     1248 \n V-VI Faglærte arbeidere VIIa Ufaglærte arbeidere \n                     648                      637 \n\npie(tab)\n\n\n\n\nMen hvis man skal bruke ggplot er det litt mer jobb. Fordelen med ggplot er at du har bedre kontroll for å lage publiserbar kvalitet. (Akkurat for kakediagram er det kanskje ikke så farlige, for du bør ikke bruke det i publikasjoner hvis du kan la være).\n\npc &lt;- abu89 %&gt;% \n  group_by(klasse89) %&gt;% \n  summarise(n = n()) %&gt;% \n  mutate(pct = n/sum(n)*100) %&gt;% \n  ungroup()\n\nggplot(pc, aes(x = \"\", y = pct, fill = (klasse89))) +\n  geom_bar(stat=\"identity\", width=1) +\n  coord_polar(\"y\", start=0) +\n  theme_void()+\n  geom_text( aes(label = paste0( round(pct,1), \"%\"), x = 1.4), \n            position = position_stack(vjust=.5), check_overlap = F) +\n  labs(x = NULL, y = NULL, fill = NULL)+\n  theme(axis.line = element_blank(),\n          axis.text = element_blank(),\n          axis.ticks = element_blank()) +\n  scale_fill_brewer(palette=\"Blues\", direction = -1)"
  },
  {
    "objectID": "grafikk.html#kontinuerlige-variable",
    "href": "grafikk.html#kontinuerlige-variable",
    "title": "7  Grafikk med ggplot",
    "section": "7.3 Kontinuerlige variable",
    "text": "7.3 Kontinuerlige variable\n\n7.3.1 Histogram\n\nggplot(abu89, aes(x = time89)) +\n  geom_histogram()\n\n\n\n\nDet er også vanlig å fremstille det samme på en “tetthetsskala”, der arealet summeres til 1. Det betyr at arealet for hvert intervall tilsvarer en andel. Visuelt sett er det vel så mye arealet vi oppfatter som høyden på stolpene. Men det er bare skalaen på y-aksen som har endret seg. Visuelt sett, ser histogrammene helt like ut.\n\nggplot(abu89, aes(x = time89, y = ..density..)) +\n  geom_histogram()\n\n\n\n\n\n\n7.3.2 Density plot\nDensity plot er en måte å fremstille det samme på, men i stedet for å dele inn i intervaller som i histogram lager vi en glattet kurve. Det blir på skalaen “tetthet” som i histogrammet ovenfor.\n\nggplot(abu89, aes(x = time89)) +\n  geom_density()\n\n\n\n\n\nggplot(abu89, aes(x = time89)) +\n  geom_histogram(aes(y = ..density..), fill = \"lightgrey\", col = \"grey\") +\n  geom_density(col = \"red\", linewidth = 1) +\n  theme_minimal()\n\n\n\n\nEn fordel med denne fremstillingen er at det er lettere å sammenligne grupper. Her er et eksempel med density plot etter hvor mye man drikker.\n\nggplot(abu89, aes(x = time89, group = klasse89, linetype = klasse89)) +\n  geom_density(linewidth = 1)+\n  guides(fill = guide_legend(override.aes = list(shape = 1 ) ) ) +\n  theme_minimal()\n\n\n\n\n\nggplot(abu89, aes(x = time89)) +\n  geom_density(linewidth = 1)+\n  theme_minimal()+\n  facet_wrap(~klasse89, scales=\"free\")\n\n\n\n\n\nggplot(abu89, aes(x = time89, group = female,  fill = factor(female))) +\n  geom_density(alpha = .3)+\n  guides(fill=guide_legend(title=\"Kjønn\"))+\n  theme_minimal()\n\n\n\n\n\n\n7.3.3 Flere variable samtidig\n\n7.3.3.1 Boksplot\n\nggplot(abu89, aes(y = time89, group = klasse89)) +\n  geom_boxplot()+\n  theme_minimal()\n\n\n\n\n\n\n7.3.3.2 Scatterplot\n\nggplot(abu89, aes(x = age, y = time89)) +\n  geom_point(alpha=.3)+\n  theme_minimal()\n\n\n\n\n\nggplot(abu89, aes(x = age, y = time89)) +\n  geom_jitter(alpha=.1, width = .3)+\n  theme_minimal()\n\n\n\n\n\n\n7.3.3.3 Ridgeplot\nRidgeplot er en annen måte å sammenligne en kontinuerlig fordeling betinget på en gruppering.\n\nlibrary(ggridges)\nggplot( abu89,  aes(y = klasse89, x = time89)) +\n  geom_density_ridges()"
  },
  {
    "objectID": "grafikk.html#oppgaver",
    "href": "grafikk.html#oppgaver",
    "title": "7  Grafikk med ggplot",
    "section": "7.4 Oppgaver",
    "text": "7.4 Oppgaver\nSlå opp i boken R for data science hvis du står fast eller ikke skjønner hva koden betyr.\n\nExercise 7.1 Last ned datasettet abu89 fra angitt hjemmeside og les inn dataene til R som vist ovenfor. Lag den samme grafikken som vist her, gjør noen endringer på kodene for å endre utseendet på plottene. Det er et mål at du skal forstå hva hver enkelt kommando gjør.\n\n\nExercise 7.2 Last inn datasettet NorLAG i R. Velg noen variable som du selv tenker kan være informative å se nærmere på. Bruk de samme teknikkene på disse variablene."
  },
  {
    "objectID": "deskriptive_tabeller.html#quick-and-dirty-oppsummeringer",
    "href": "deskriptive_tabeller.html#quick-and-dirty-oppsummeringer",
    "title": "8  Deskriptive tabeller",
    "section": "8.1 Quick-and-dirty oppsummeringer",
    "text": "8.1 Quick-and-dirty oppsummeringer\nFørst og fremst har vi funksjonen summary(). Når denne brukes på et objekt vil hva slags output du får avhenge av objekttypen. Derfor vil summary() gi forskjellig output om det er en vektor, et datasett eller et regresjonsobjekt etc. Vi avgrenser oss til datasett her.\nHer er output for hele datasettet.\n\nsummary(abu89)\n\n     io_nr          time89             ed             age       \n Min.   :   3   Min.   : 25.00   Min.   : 0.00   Min.   :16.00  \n 1st Qu.:1542   1st Qu.: 71.00   1st Qu.: 1.00   1st Qu.:30.00  \n Median :3093   Median : 83.33   Median : 3.00   Median :39.00  \n Mean   :3105   Mean   : 90.15   Mean   : 2.69   Mean   :39.65  \n 3rd Qu.:4644   3rd Qu.:102.56   3rd Qu.: 3.00   3rd Qu.:48.00  \n Max.   :6258   Max.   :343.75   Max.   :11.00   Max.   :74.00  \n                NA's   :368                                     \n     female                           klasse89    promot          fexp       \n Min.   :0.0000   I Øvre serviceklasse    : 328   NEI:2568   Min.   :0.0000  \n 1st Qu.:0.0000   II Nedre serviceklasse  :1181   JA :1559   1st Qu.:0.2000  \n Median :0.0000   III Rutinefunksjonærer  :1248              Median :0.7000  \n Mean   :0.4686   V-VI Faglærte arbeidere : 648              Mean   :0.9451  \n 3rd Qu.:1.0000   VIIa Ufaglærte arbeidere: 637              3rd Qu.:1.4000  \n Max.   :1.0000   NA's                    :  85              Max.   :4.9000  \n                                                                             \n    private    \n Public :1602  \n Private:2525  \n               \n               \n               \n               \n               \n\n\nMerk at summary() rapporterer forskjellig basert på om variabelen er kontinuerlig eller kategorisk. For kontinuerlige variable gis min/max, kvartiler, median og gjennomsnitt. For kategoriske variable gis det antall i hver kategori. Hvis det er manglende verdier på en variabel står det oppført nederst som antall NA's.\nMerk her at variabelen female er definert som kontinuerlig selv om det bare er to verdier. Det ville være mer hensiktsmessig å gjøre om denne variabelen til kategorisk.\nMan kan også bruke summary() på enkeltvariable med bruk av $ som følger:\n\nsummary(abu89$time89)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  25.00   71.00   83.33   90.15  102.56  343.75     368 \n\n\nDa får man altså bare tallene for den variabelen man har angitt etter dollartegnet.\n\n8.1.1 Enkeltfunksjoner\nMan kan hente ut hvert av disse tallene spesifikt fremfor å bruke summary(). Det er egne funksjoner for dette, og de kan også brukes når man gjør databearbeiding for litt andre formål. Vi ser her på de viktigste.\nHva om man vil ha en kvartil som ikke er oppgitt i forvalget? Da kan man bruke funksjonen quantile(). Argumentene i denne funksjonen er hvilken variabel og hvilket prosentil. Som vi ovenfor inneholder time89 noen NA. Vi må i tillegg bestemme hva vi ønsker å gjøre med NA i beregningen, og vi vil her se bort fra disse ved å angi na.rm = TRUE. Ellers får man feilmelding.\nHer er eksempel med første kvartil som skal gi samme svar som ovenfor:\n\nquantile(abu89$time89, .25, na.rm = TRUE)\n\n25% \n 71 \n\n\nHer er en variant der man ber om 95-prosentilen:\n\nquantile(abu89$time89, .95, na.rm = TRUE)\n\n     95% \n148.0362 \n\n\nMan kan også be om flere prosentiler. Da listes disse opp innenfor en c() som følger. Her gis prosentilene for 5, 10, 90 og 95 prosent.\n\nquantile(abu89$time89, c(.05, .10, .90, .95), na.rm = TRUE)\n\n       5%       10%       90%       95% \n 54.91651  61.00000 127.77778 148.03618 \n\n\nGjennomsnittet av en variabel gis ved funksjonen mean():\n\nmean(abu89$time89, na.rm = TRUE)\n\n[1] 90.14948\n\n\nStandardavviket gis ved sd():\n\nsd(abu89$time89, na.rm = TRUE)\n\n[1] 30.31473\n\n\nMedianen kan angis med quantile(), men enklere med median():\n\nmedian(abu89$time89, na.rm = TRUE)\n\n[1] 83.33333\n\n\nVi trenger også ofte antall. nrow() gir antall rader, dvs. antall observasjoner i datasettet\n\nnrow(abu89)\n\n[1] 4127\n\n\nTilsvarende gir ncol() antall kolonner, mens dim() gir begge deler:\n\nncol(abu89)\n\n[1] 9\n\ndim(abu89)\n\n[1] 4127    9"
  },
  {
    "objectID": "deskriptive_tabeller.html#professjonelle-tabeller-med-gtsummary",
    "href": "deskriptive_tabeller.html#professjonelle-tabeller-med-gtsummary",
    "title": "8  Deskriptive tabeller",
    "section": "8.2 Professjonelle tabeller med gtsummary",
    "text": "8.2 Professjonelle tabeller med gtsummary\nFor å lage ordentlig professjonelle tabeller kreves det mer. For det første skal de se ordentlige ut, men de skal også kunne eksporteres til andre formater på en hensiktsmessig måte.\nI R finnes det en hel rekke slike funksjoner. Her har vi vektlagt pakken gtsummary fordi den gir gode tabeller fra helt enkle til ganske avanserte relativt lett. Det er også mange muligheter for å justere tabellene slik du vil. Dessuten kan resultatene eksporteres lett til de fleste aktuelle formater (Word, html, pdf, Excel, latex).\nAvanserte brukere vil muligens se begrensningene i denne pakken og foretrekke noe annet. De fleste vil kunne lage det aller meste med denne pakken.\nVi starter med en enkel oversiktstabell med alle variablene i datasettet. Men vi fjerner løpenummeret for person, nemlig variabelen io_nr fordi den ikke inneholder noe analyserbar informasjon.\n\nabu89 %&gt;% \n  select(-io_nr) %&gt;% \n  tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 4,1271\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n83 (71, 103)\n        Unknown\n368\n    År utdanning\n\n        0\n839 (20%)\n        1\n1,156 (28%)\n        3\n1,121 (27%)\n        5\n483 (12%)\n        7\n308 (7.5%)\n        9\n205 (5.0%)\n        11\n15 (0.4%)\n    Alder\n39 (30, 48)\n    Respondentens kjønn\n1,934 (47%)\n    Goldthorpe klasse 1989\n\n        I Øvre serviceklasse\n328 (8.1%)\n        II Nedre serviceklasse\n1,181 (29%)\n        III Rutinefunksjonærer\n1,248 (31%)\n        V-VI Faglærte arbeidere\n648 (16%)\n        VIIa Ufaglærte arbeidere\n637 (16%)\n        Unknown\n85\n    Noen gang forfremmet\n\n        NEI\n2,568 (62%)\n        JA\n1,559 (38%)\n    Bedriftserfaring\n0.70 (0.20, 1.40)\n    Privat sektor\n\n        Public\n1,602 (39%)\n        Private\n2,525 (61%)\n  \n  \n  \n    \n      1 Median (IQR); n (%)\n    \n  \n\n\n\n\nLegg merke til at tbl_summary gjør en del ting automatisk. Først og fremst er bruker den variabel label og factor levels i sidespalten. Ofte vil ikke variable ha slike labler, og da vil det vises variabelnavnene. Variabelen kjønn har ikke angitt factor levels, og variabelen har bare verdiene 0 og 1, og da rapporteres kun den ene kategorien (dvs. verdien 1). Vi kan legge til annen tekst hvis vi ønsker.\nDernest er det en forhåndsinnstilling som angir at det for kontinuerlige variable skal rapporteres median og interquartile range (IQR), dvs. nedre og øvre kvartil i parentes. Det gir en god beskrivelse av variablene, men vi skal endre dette nedenfor. For kategoriske variable rapporteres det antall observasjoner og andelen i prosent i parentes.\nMen merk at for antall år utdanning og kjønn, så er det rapportert som kategoriske variable selv om variabeltypen er kontinuerlig. tbl_summary gjør dette fordi det er relativt få kategorier slik at median og IQR ikke er så interessant uansett.\nLa oss først endre slik at det rapporteres gjennomsnitt og standardavvik i stedet. Det er mer vanlig å gjøre selv om det ikke er noen regel for dette. Funksjonen theme_gtsummary_mean_sd() endrer standardvalget for tbl_summary i alle etterfølgende tabeller. Dermed slipper du endre neste gang. Flere themes finner du på pakkens hjemmeside. For å gå tilbake til opprinnelig theme brukes funksjonen reset_gtsummary_theme().\nVi kan endre andre ting ved tabellen med noen enkle grep. Alle variable kan endre navn i forspalten med å legge til argumentet label =. Nedenfor er to variable endret for å vise hvordan man endrer flere variable. Når det er flere variable må de spesifiseres innenfor argumentet list() som nedenfor. Her endrer vi også label for variabelen female og klasse89.\nNoen ganger kan man også ønske å endre hvordan en variabel presenteres. Et vanlig behov er å presisere hvilken type en variabel er. I dette tilfellet er utdanning antall år etter obligatorisk skolenivå, så det er egentlig en kontinuerlig variabel selv om antall verdier er få. Vi kan velge å presisere at denne er av typen continuous. Nedenfor presiserer vi også at female er kategorisk, dichotomous, selv om denne ble presentert riktig uansett. Vi bruker argumentet type = og flere variable må oppgis innenfor list().\nEn siste ting vi kan endre er å ikke rapportere NA. Det er ikke oppgitt timelønn for alle, så antall NA er rapportert for seg. Det kan være fint, men kan også hende vi ikke ønsker det. Nedenfor er det derfor også lagt til missing = \"no\".\n\ntheme_gtsummary_mean_sd()\nabu89 %&gt;% \n  select(-io_nr) %&gt;% \n  tbl_summary(label = list(female ~ \"Kjønn\", klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\", female ~ \"dichotomous\"), \n              missing = \"no\")\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 4,1271\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n90 (30)\n    År utdanning\n2.69 (2.56)\n    Alder\n40 (12)\n    Kjønn\n1,934 (47%)\n    Klasse\n\n        I Øvre serviceklasse\n328 (8.1%)\n        II Nedre serviceklasse\n1,181 (29%)\n        III Rutinefunksjonærer\n1,248 (31%)\n        V-VI Faglærte arbeidere\n648 (16%)\n        VIIa Ufaglærte arbeidere\n637 (16%)\n    Noen gang forfremmet\n\n        NEI\n2,568 (62%)\n        JA\n1,559 (38%)\n    Bedriftserfaring\n0.95 (0.91)\n    Privat sektor\n\n        Public\n1,602 (39%)\n        Private\n2,525 (61%)\n  \n  \n  \n    \n      1 Mean (SD); n (%)\n    \n  \n\n\n\n\nOfte vil vi ha en tabell som ikke bare viser univariat fordeling, men bi-variate, altså fordelt på to eller flere grupper. Det er f.eks. ganske vanlig å vise tabeller fordelt på kjønn. Det kan vi også gjøre her ved å legge til argumentet by = female. Nedenfor er det også forenklet argumentene for label = og type =. I slike tilfeller vil vi ofte ha totalen i tillegg til per gruppe, og det gjør vi ved å legge til funksjonen add_overall().\nFor de kontinuerlige variablene får vi ikke antallet som inngår i beregningene. Vi vil gjerne vise antall ikke-missing verdier - særlig fordi vi tok vekk NA som egen rad ovenfor. Dette gjør vi ved å legge til funksjonen add_n().\n\nabu89 %&gt;% \n  select(-io_nr) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n    tbl_summary(by = female, \n                label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;% \n  add_overall() %&gt;% \n  add_n()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N\n      Overall, N = 4,1271\n      Kvinner, N = 1,9341\n      Menn, N = 2,1931\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n3,759\n90 (30)\n79 (24)\n100 (32)\n    År utdanning\n4,127\n2.69 (2.56)\n2.38 (2.40)\n2.96 (2.66)\n    Alder\n4,127\n40 (12)\n40 (13)\n40 (12)\n    Klasse\n4,042\n\n\n\n        I Øvre serviceklasse\n\n328 (8.1%)\n74 (3.9%)\n254 (12%)\n        II Nedre serviceklasse\n\n1,181 (29%)\n555 (29%)\n626 (29%)\n        III Rutinefunksjonærer\n\n1,248 (31%)\n986 (52%)\n262 (12%)\n        V-VI Faglærte arbeidere\n\n648 (16%)\n46 (2.4%)\n602 (28%)\n        VIIa Ufaglærte arbeidere\n\n637 (16%)\n244 (13%)\n393 (18%)\n    Noen gang forfremmet\n4,127\n\n\n\n        NEI\n\n2,568 (62%)\n1,308 (68%)\n1,260 (57%)\n        JA\n\n1,559 (38%)\n626 (32%)\n933 (43%)\n    Bedriftserfaring\n4,127\n0.95 (0.91)\n0.83 (0.81)\n1.05 (0.97)\n    Privat sektor\n4,127\n\n\n\n        Public\n\n1,602 (39%)\n1,016 (53%)\n586 (27%)\n        Private\n\n2,525 (61%)\n918 (47%)\n1,607 (73%)\n  \n  \n  \n    \n      1 Mean (SD); n (%)\n    \n  \n\n\n\n\nMen vi kan lage mer kompliserte tabeller også. La oss si at vi ønsker å lage den samme tabellen som over, men fordelt på to grupper. Det kan være relevant å sammenligne offentlig og privat sektor. En mulighet er å lage en ny grupperingsvariabel ved å slå sammen kjønn og sektor slik at vi får fire kategorier. Men vi får et bedre resultat ved å lage en stratifisert tabell med funksjonen tbl_strata(). Det er litt kryptisk syntaks, men det viktige er å angi hvilken variabel det skal stratifiseres etter med argumentet strata = etterfulgt av .tbl_fun = ~ .x %&gt;%, så kommer tble_summary etter dette. Her er det også lagt til en ekstra header med antall observasjoner.\n\nabu89 %&gt;% \n  select(-io_nr) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n  tbl_strata(strata = private, \n             .tbl_fun = \n               ~ .x %&gt;%\n               tbl_summary(by = female, \n              label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;%\n               add_n(),\n    .header = \"**{strata}**, N = {n}\"\n    )\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      \n        Public, N = 1602\n      \n      \n        Private, N = 2525\n      \n    \n    \n      N\n      Kvinner, N = 1,0161\n      Menn, N = 5861\n      N\n      Kvinner, N = 9181\n      Menn, N = 1,6071\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n1,403\n82 (23)\n100 (28)\n2,356\n76 (24)\n100 (33)\n    År utdanning\n1,602\n2.88 (2.67)\n4.22 (3.12)\n2,525\n1.82 (1.92)\n2.50 (2.31)\n    Alder\n1,602\n42 (12)\n43 (11)\n2,525\n37 (13)\n39 (12)\n    Klasse\n1,592\n\n\n2,450\n\n\n        I Øvre serviceklasse\n\n55 (5.4%)\n150 (26%)\n\n19 (2.1%)\n104 (6.7%)\n        II Nedre serviceklasse\n\n340 (34%)\n196 (34%)\n\n215 (24%)\n430 (28%)\n        III Rutinefunksjonærer\n\n507 (50%)\n64 (11%)\n\n479 (54%)\n198 (13%)\n        V-VI Faglærte arbeidere\n\n5 (0.5%)\n114 (20%)\n\n41 (4.6%)\n488 (31%)\n        VIIa Ufaglærte arbeidere\n\n104 (10%)\n57 (9.8%)\n\n140 (16%)\n336 (22%)\n    Noen gang forfremmet\n1,602\n\n\n2,525\n\n\n        NEI\n\n696 (69%)\n318 (54%)\n\n612 (67%)\n942 (59%)\n        JA\n\n320 (31%)\n268 (46%)\n\n306 (33%)\n665 (41%)\n    Bedriftserfaring\n1,602\n0.93 (0.85)\n1.15 (0.94)\n2,525\n0.72 (0.74)\n1.01 (0.98)\n  \n  \n  \n    \n      1 Mean (SD); n (%)\n    \n  \n\n\n\n\nDet går også an å lage langt mer avanserte tabeller enn dette, og alle deler kan modifiseres. Men vi går ikke inn på dette her. Ved behov finner du instruksjoner på pakkens hjemmeside.\n\n8.2.1 Eksport av tabeller\nDu skal aldri bruke “klipp og lim” for å få en tabell over i et tekstbehandlingsprogram. Trikset er å konvertere tabellen til gt-format som har en eksportfunksjon til MS Word.\nFørst lagres tabellen i et eget objekt.\n\nfintabell &lt;- abu89 %&gt;% \n  select(-io_nr) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n  tbl_strata(strata = private, \n             .tbl_fun = \n               ~ .x %&gt;%\n               tbl_summary(by = female, \n              label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;%\n               add_n(),\n    .header = \"**{strata}**, N = {n}\"\n    )\n\nSå kan tabellen eksporteres til Word, og evt. redigeres videre der hvis det trengs. På dette nivået kan det være mer tidsbesparende å gjøre siste justeringer i Word fremfor å lære alle triks for å lage tabellen fiks ferdig i R. (Skal du lage mange tabeller kan det likevel lønne seg å gjøre mest mulig i R).\n\nfintabell %&gt;% \n  as_gt() %&gt;% \n  gt::gtsave(filename = \"output/fintabell.docx\")\n\nMerk at eksport til docx-formatet krever at du har en relativt ny installasjon av pakkene {gt} og {gtsummary}. Filhalen “.docx” innebærer at filen lagres i dette formatet. Tilsvarende kan du lagre i .html, .pdf, .rtf, .png, .tex eller .ltex bare ved å endre filhalen.\nEn tilsvarende variant som noen av dere har lært på sosgeo1120 er å bruke as_flextable og en tilsvarende eksportfunksjon. Det er selvsagt også helt ok. En tidligere versjon av {gt} kunne som sagt ikke eksportere til Word, så da var {flextable} beste løsning. Men pakken {flextable} har vist seg å være litt trøblete å installere på noen pc’er, så da er det bedre å bruke {gt}."
  },
  {
    "objectID": "deskriptive_tabeller.html#manuelle-tabeller",
    "href": "deskriptive_tabeller.html#manuelle-tabeller",
    "title": "8  Deskriptive tabeller",
    "section": "8.3 Manuelle tabeller",
    "text": "8.3 Manuelle tabeller\nNoen ganger trenger man å lage ganske spesifikke ting.\n\n8.3.1 For datasettet totalt\n\n\n8.3.2 Grupperte statistikker"
  },
  {
    "objectID": "deskriptive_tabeller.html#oppgaver",
    "href": "deskriptive_tabeller.html#oppgaver",
    "title": "8  Deskriptive tabeller",
    "section": "8.4 Oppgaver",
    "text": "8.4 Oppgaver\nSlå opp i boken R for data science hvis du står fast eller ikke skjønner hva koden betyr.\n\nExercise 8.1 Bruk datasettet abu89 og lag de samme tabellene som vist her, gjør noen endringer på kodene for å endre utseendet på tabellene. Det er et mål at du skal forstå hva hver enkelt kommando gjør.\n\n\nExercise 8.2 Last inn datasettet NorLAG i R. Velg noen variable som du selv tenker kan være informative å se nærmere på. Bruk de samme teknikkene på disse variablene."
  },
  {
    "objectID": "linearRegresjon.html#scatterplot",
    "href": "linearRegresjon.html#scatterplot",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "9.1 Scatterplot",
    "text": "9.1 Scatterplot\nBivariat regresjon beskriver sammenhengen mellom to variable. En naturlig start er å se på et scatterplot. Her er en figur som viser hvordan timelønn varierer med alder. I det nedenforstående er det brukt jitter og gjennomsiktig farge for å håndtere overplotting.\nI tillegg er det tegnet inn en linje som illustrerer trenden i gjennomsnittlig lønn med alder. Denne linjen skrår svakt oppover, som altså betyr at gjennomsnittlig lønn øker noe med alder. Vi ser med det blotte øyet at en rett linje ikke beskriver denne sammenhengen perfekt. Først og fremst er det en stor variasjon rundt denne linjen, så det er mye annet som påvirker lønna enn alder. Det er også verd å legge merke til at i de yngste aldersgruppene er lønna en god del lavere - og kanskje litt lavere i eldste aldersgrupper også. Så en rett linje er kanskje ikke optimalt i utgangspunktet. Fordelen med en rett linje er at vi kan si noe slikt som at “gjennosmsnittslønna øker med x antall kroner for hvert år eldre man blir”. Hvis linja er kurvlineær blir det litt mer komplisert. Så et første poeng er at en slik linje er en forenkling, og det er en tilsiktet forenkling.\n\nggplot(abu89, aes(x =age, y = time89))+\n  geom_jitter(alpha = .2)+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nDet er en viss tendens til at lønnen øker med alder, men det er ikke helt lett å si hvor mye. Poenget med lineær regresjon er å beskrive en gjennomsnittlig trend.\n\nggplot(abu89, aes(x =age, y = time89))+\n  geom_jitter(alpha = .2)+\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nDenne trendlinja er hva vi vanligvis kaller regresjonslinje."
  },
  {
    "objectID": "linearRegresjon.html#regresjonslinja",
    "href": "linearRegresjon.html#regresjonslinja",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "9.2 Regresjonslinja",
    "text": "9.2 Regresjonslinja\nRegresjonslinja kan beskrives med et stigningstall, som sier hvor bratt linjen er. Substansielt sett betyr det hvor mye utfallsvariabelen (y-aksen) endres med økning i forklaringsvariabelen (x-aksen). I tillegg trenger vi også vite hvor høyt/lavt linjen ligger.1 Til det bruker vi startpunktet for linjen, der hvor \\(x\\) har verdien 0. Dette må regnes ut, og det er akkurat dette estimering av lineær regresjon gir oss.\nUtregningen av regresjonslinja går vi ikke inn på her, men intuitivt sett ønsker vi jo den beste linja og ikke en hvilken som helst omtrentlig linje. Datapunktene (de svarte punktene i grafen) er spredt rundt linja, og avstanden mellom linje og punkt kalles residualer. Summen av disse residualene er grunnlaget for mål på hvor godt regresjonslinja beskriver de faktiske dataene. Den beste linja er definert som den som minimerer residualene. Det er dette som kalles “minste kvadraters metode”.\nI R estimeres regresjonsmodeller med funksjonen lm. Første argument er en formel på formen utfallsvariabel ~ forklaringsvariabel. Rekkefølgen variablene oppgis i er altså viktig. Dernest må det spesifiseres hvilket datasett som skal brukes med data = .2\nLegg alltid resultatene i et eget objekt med et navnt som er rimelig enkelt å forstå hva er. I følgende kode legges resultatet i en nytt objekt lm_est1. Deretter bruker kan man hente ut de delene av resultatet vi er interessert i. I aller første omgang er bare interessert i regresjonslinjas konstantledd (startpunktet) og stigningstall. Disse kaller vi vanligvis regresjonskoeffisienter. Det kan vi få ut ved å bruke funksjonen coef. (Vi kommer tilbake til å se på de fulle resultatene senere, som vi oftest er interessert i).\n\nlm_est1 &lt;- lm(time89 ~ age, data = abu89)\ncoef(lm_est1)\n\n(Intercept)         age \n 71.1101883   0.4828415 \n\n\nRegresjonslingningen kan skrives på formel der \\(\\alpha\\) er konstantleddet og \\(\\beta\\) er stigningstallet slik:\n\\[\n\\operatorname{time89} = \\alpha + \\beta_{1}(\\operatorname{age}) + \\epsilon\n\\]\nNår vi setter inn de estimerte koeffisientene inn i ligningen får vi følgende:\n\\[\n\\operatorname{\\widehat{time89}} = 71.11 + 0.48(\\operatorname{age})\n\\]\nTolkningen her er at gjennomsnittlig forskjell i timelønn mellom grupper der aldersforskjellen er ett år er 0.48 kroner i favør av den eldre gruppen.3 Merk enheten her: stigningstallet tolkes på den skalaen utfallsvariabelen er på, i dette tilfellet kroner. Det er også uttrykt endring ved at forklaringsvariabelen endres med nøyaktig 1.\nVi sier gjerne at regresjonslinjen er estimert, og det innebærer at det er usikkerhet i estimatene. Vi kommer tilbake til dette, men en vanligere output fra regresjonsmodeller er å bruke funksjonen summary. Da får man med mye mer detaljer og output vil se ut som følger:\n\nsummary(lm_est1)\n\n\nCall:\nlm(formula = time89 ~ age, data = abu89)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-69.287 -19.131  -6.304  12.864 255.258 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 71.11019    1.62232   43.83   &lt;2e-16 ***\nage          0.48284    0.03926   12.30   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 29.73 on 3757 degrees of freedom\n  (368 observations deleted due to missingness)\nMultiple R-squared:  0.0387,    Adjusted R-squared:  0.03844 \nF-statistic: 151.2 on 1 and 3757 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "linearRegresjon.html#dummy-variable",
    "href": "linearRegresjon.html#dummy-variable",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "9.3 Dummy-variable",
    "text": "9.3 Dummy-variable\nHvis en forklaringsvariabel har kun to verdier vil vi typisk gi den ene kategorien verdien 0 og den andre kategorien 1. Dette kalles en «dummy variabel» eller en «indikator variabel». For eksempel vil et datasett ofte ha en variabel for kjønn med verdiene «Mann» og «Kvinne». Da kan vi la mann få verdien 0 og kvinne verdien 1. Ofte vil man da gi variabelen et navn som indikerer hvilken verdi som er 1. Så i dette eksempelet er det hensiktsmessig å gi den nye variabelen navnet «Kvinne». I dette eksempelet vil man også kunne si at variabelen er en «dummy for kvinne» (altså: den kategorien som får verdien 1).\nDet spiller ingen rolle hvilken kategori som får verdien 0 og 1. I dette eksempelet kunne man like gjerne gjort det motsatt, og latt det være en «dummy for mann». Da ville det være naturlig å kalle variabelen «mann» i stedet for «kvinne». Som vi skal se nedenfor vil det bare påvirke fortegnet når vi bruker variabelen i en regresjonsanalyse.\nI datasettet abu89 er variabelen “female” en slik variabel som har verdiene 0 eller 1, og der 0 betyr “mann” og 1 betyr “kvinne”.\n\n\n\nKjønn\nFemale\n\n\n\n\nMann\n0\n\n\nKvinne\n1\n\n\nKvinne\n1\n\n\nMann\n0\n\n\nKvinne\n1\n\n\nKvinne\n1\n\n\nKvinne\n1\n\n\nMann\n0\n\n\n\nI R vil vi ofte ha slike variable som factor-variable. Da er variabelen definert som kategorisk og selv om det er tekst-verdier i variabelen, så vil R automatisk behandle den som om verdiene var 0 og 1 i estimeringen av regresjonsmodellen.\n\ntheme_gtsummary_mean_sd()\nabu89 %&gt;% \n  select(female, time89) %&gt;% \n  tbl_summary(by = female) \n\n\n\n\n\n  \n    \n    \n      Characteristic\n      0, N = 2,1931\n      1, N = 1,9341\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n100 (32)\n79 (24)\n        Unknown\n190\n178\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\nVi ser altså at menn hadde i gjennomsnitt høyere timelønn enn kvinner, nærmere bestemt 21 kroner mer. Dette kan vi også undersøke med lineær regresjon som følger:\n\nlm_est_i &lt;- lm(time89 ~ female , data = abu89)\n\ncoef(lm_est_i)\n\n(Intercept)      female \n   99.84382   -20.75229 \n\n\nRegresjonskoeffisenten for variabelen female uttrykker nettopp differansen mellom menn og kvinner, som er 21 kroner. Husk at \\(\\beta\\) er hvor mye \\(y\\)-variabelen endres når man sammenligner \\(x\\)-variabelen med akkurat 1 enhets forskjell. Her er mann 0 og kvinner 1, så da er dette faktisk 1 enhets forskjell. Altså: når \\(x\\) går fra 0 til 1, så reduseres \\(y\\) med 21. Derfor negativt fortegn.\nI R vil vi ofte gjøre om kategoriske variable til såkalte factor-variable. En factor-variabel vil håndtere kategoriske variable som tekst, men med en underliggende numerisk verdi. Da kan man bruke factor-variable i alle standard analysemetoder. I regresjon vil R automatisk bruke den første kategorien som referansekategori.\nVi kan gjøre den samme analysen med kjønn som en factor variabel og få de samme resultatene som ovenefor.\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(sex = factor(ifelse(female == 1, \"Female\", \"Male\"), levels = c(\"Male\", \"Female\"))) %&gt;% \n  filter(!is.na(time89))\n\nlm_est2 &lt;- lm(time89 ~ female , data = abu89)\n\ncoef(lm_est2)\n\n(Intercept)      female \n   99.84382   -20.75229 \n\n\n\n9.3.1 Dummy-variable med mer enn en kategori\nNoen ganger har vi forklaringsvariable med flere enn to kategorier. Det kan vi løse på en tilsvarende måte ved å lage flere dummy-variable. Et eksempel kan være sosial klasse. I datasettet abu89 er det fem kategorier.\nEn dummy-variabel har bare to kategorier: 0 og 1, men vi kan lage flere dummy-variable. Vi kan lager en ny variabel «klasse II» som har verdien 1 hvis personen tilhører denne klassen og 0 ellers. Altså en dummy. Så kan vi lage en ny variabel «Klasse III» som har verdien 1 hvis personen tilhører denne klassen og 0 ellers. Slik kan man lage en dummy-variabel for hver av kategoriene. Da har vi altså flere dummy-variable som til sammen fanger opp informasjonen i den opprinnelige variabelen.\n\n\n\nUtdanning\nKlasse II\nKlasse III\nKlasse V-VI\nKlasse VII\n\n\n\n\nKlasse I\n0\n0\n0\n0\n\n\nKlasse II\n1\n0\n0\n0\n\n\nKlasse III\n0\n1\n0\n0\n\n\nKlasse V-VI\n0\n0\n1\n0\n\n\nKlasse VII\n0\n0\n0\n1\n\n\n\nMerk at her er det ingen dummy for “Klasse I”. Denne gruppen brukes som referansekategori slik at estimatene for de andre dummyene blir tolkbare som forskjellen til denne referansekategorien. Mer om det siden, men man kan velge å bruke en annen referansekategori hvis man vil.\nLa oss først se på et plot. Her er det brukt en jitter-plot. Den røde linjen viser endring i gjennomsnitt mellom de kategoriene. En regresjonsanalyse vil gi slike estimater på differanser, men det er enklest hvis alle endringene er i forhold til samme referansekategori.\n\nggplot( abu89x, aes(x =klasse89, y = time89))+\n  geom_jitter(alpha = .3, width = .2)+\n  geom_point(aes(y=gr_snitt), col = \"red\", size = 3)+\n  #geom_hline(yintercept = mean(abu89x$time89, na.rm = TRUE))+\n  geom_line(aes(x = as.numeric(klasse89), y = smooth), col = \"red\", linewidth = 1) \n\n\n\n\nDen generelle regresjonsligningen skrives som \\(y=a+bx\\), der \\(x\\) er forklaringsvariabelen. Regresjonskoeffisienten, \\(b\\), tolkes som hvor forskjellen i gjennomsnittet på utfallsvariabelen, \\(y\\), mellom de som er en enhets forskjell på \\(x\\)-variabelen.\nSå kan vi kjøre en regresjon og få ut regresjonskoeffisientene på samme måte som før. Akkurat her er coef lagt inn i en parentes for data.frame, men det er bare for at det skal bli en pen kolonne. Vi kommer altså tilbake til teknikker for penere output nedenfor.\n\nest2 &lt;- lm(time89 ~ klasse89, data = abu89)  \ndata.frame(coef(est2)) \n\n                                 coef.est2.\n(Intercept)                       118.39851\nklasse89II Nedre serviceklasse    -14.49078\nklasse89III Rutinefunksjonærer    -42.89842\nklasse89V-VI Faglærte arbeidere   -29.68788\nklasse89VIIa Ufaglærte arbeidere  -36.95234\n\n\nHvert estimat for kategori for klasse sammenlignes med den første kategorien (altså den som mangler): klasse I. Det betyr at klasse VII (ufaglærte arbeidere) har en timelønn på -37 kroner mindre enn klasse I (øvre serviceklasse). Mens klasse II (nedre serviceklasse) tjener -14.5 kroner mindre enn klasse I.\nForskjellen mellom andre grupper er således differansen mellom disse estimatene. Altså: klasse VII tjener mindre enn klasse V-VI: \\(36.9 - 29.7 = 7.2\\) kroner. Se på plottet over, så ser du at disse tallene ser riktige ut."
  },
  {
    "objectID": "linearRegresjon.html#flere-variable",
    "href": "linearRegresjon.html#flere-variable",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "9.4 Flere variable",
    "text": "9.4 Flere variable\nDet er ikke så ofte vi bruker regresjon med bare en forklaringsvariabel, såklat “enkel lineær regresjon”.4 Langt mer vanlig er å bruke flere variable samtidig i det vi kaller “multippel regresjon”.5 I multippel regresjon kan man altså beskrive mer kompliserte mønstre i dataene.\nVi fortsetter med eksempelet om lønn og alder, men utvider med en dimensjon til, nemlig kjønn. La oss først se på kjønnsforskjellene i gjennomsnittlig timelønn.\n\nabu89 &lt;- abu89 %&gt;%\n  mutate(sex = factor(ifelse(female == 1, \"Female\", \"Male\"), levels = c(\"Male\", \"Female\"))) %&gt;% \n  filter(!is.na(time89))\n\nabu89 %&gt;% \n  select(sex, time89) %&gt;% \n  tbl_summary(by = sex) \n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Male, N = 2,0031\n      Female, N = 1,7561\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n100 (32)\n79 (24)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\nVi ser altså at menn hadde i gjennomsnitt høyere timelønn enn kvinner, nærmere bestemt 21 kroner mer. Dette kan vi også undersøke med lineær regresjon som følger:\n\nlm_est2 &lt;- lm(time89 ~ sex , data = abu89)\n\ncoef(lm_est2)\n\n(Intercept)   sexFemale \n   99.84382   -20.75229 \n\n\nDet er altså slik at koeffisienten, \\(\\beta\\), gir den samme differansen som en enkel sammenligning av to gjennomsnitt.\nVi har allerede sett på alder og lønn, så vi kan utvide dette til å inkludere kjønn samtidig i et scatterplot.\nGrafisk er det da greit å bruke farger og slik vise for menn og kvinner for seg. I ggplot spesifiseres da group = sex og at fargene skal settes etter sammen grupperingen col = sex slik:\n\nggplot(abu89, aes(x = age, y = time89, group = sex, col = sex)) +\n  geom_jitter(alpha = .4)\n\n\n\n\n\nlm_est3 &lt;- lm(time89 ~ sex + age, data = abu89)\n\nsummary(lm_est3)\n\n\nCall:\nlm(formula = time89 ~ sex + age, data = abu89)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-72.37 -17.12  -4.90  10.99 247.94 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  81.10147    1.58497   51.17   &lt;2e-16 ***\nsexFemale   -20.62511    0.91186  -22.62   &lt;2e-16 ***\nage           0.47380    0.03684   12.86   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 27.89 on 3756 degrees of freedom\nMultiple R-squared:  0.1539,    Adjusted R-squared:  0.1535 \nF-statistic: 341.7 on 2 and 3756 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "linearRegresjon.html#prediksjon",
    "href": "linearRegresjon.html#prediksjon",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "9.5 Prediksjon",
    "text": "9.5 Prediksjon\nLineær regresjon kan også brukes til prediksjon selv om dette i liten grad er hva samfunnsvitere bruker regresjonsmodeller til. Vanligvis vil vi primært være interessert i å tolke regresjonskoeffisientene som sammenligninger mellom grupper. Man kan si at man da er opptatt av forklaringsvariablene. Når man predikerer er man derimot opptatt av utfallsvariabelen. Hvis man skulle være interessert i temaer som maskinlæring, vil dette være en god inngang til det.6\n\n9.5.1 Regne ut forventet verdi\nMerk at konstantleddet er tolkbart som forventet verdi på utfallsvariabelen når alle andre prediktorer er null. I eksempelet ovenfor med timelønn og klassetilhøringhet, er det altså ikke noen koeffisient for klasse I. Gjennomsnittlig timelønn i klasse I er når de andre dummyene er 0, altså 118.4 kroner. Gjennomsnittlig timelønn for klasse II er tilsvarende 118.4 + (-14.49) = 103.9.\nHvis du skulle gjette timelønna til en person uten å vite noe annet enn klasseposisjon ville det være fornuftig å gjette på gjennomsnittet for denne klassen. Så vi kan bruke regresjonsmodeller til å regne ut gjennomsnittslønn for gitte verdier av forklaringsvariable. I dette eksempelet er det kanskje litt i overkant komplisert da vi jo også bare kunne regnet ut gjennomsnittet per gruppe i en enkel tabell. Det ville faktisk gitt akkurat samme resultat. Det er mer nyttig med kontinuerlige variable og mer kompliserte modeller.\nLa oss se på regresjonsmodellen for hvordan timelønn varierer med alder i stedet. Alder er kontinuerlig, så det er få personer på hvert alderstrinn.\n\ncoef(lm_est1)\n\n(Intercept)         age \n 71.1101883   0.4828415 \n\n\nGjennomsnittlig timelønn ved 30 år vil da være 71.1 + 30 \\(\\times\\) 0.5 = 86.1 kroner. Ved 35 år blir det tilsvarende 71.1 + 35 \\(\\times\\) 0.5 = 88.6 kroner.\nDette kan vi altså regne ut for hånd, men man kan også bruke en r-funksjon, nemlig predict. Denne funksjonen tar som argument et regresjonsobjekt og en data.frame (altså et datasett eller tilsvarende struktur) med samme variabelnavn som ble brukt i opprinnelig regresjonsmodell.7\n\n\n9.5.2 Predikere for kontinuerlig variabel\nKoden nedenfor lager først et datasett med én variabel: alder med noen verdier man er interessert i utregning for. Så bruker man mutate til å lage en kolonne til med predikerte verdier.\n\nnyedata &lt;- data.frame(age = c(17, 20, 30, 40, 50, 60))\n\nnyedata %&gt;% \n  mutate(pred = predict(lm_est1, newdata = nyedata))\n\n  age      pred\n1  17  79.31849\n2  20  80.76702\n3  30  85.59543\n4  40  90.42385\n5  50  95.25226\n6  60 100.08068\n\n\n\n\n9.5.3 Predikere kategorisk variabel\nTilsvarende kan vi predikere for kategoriske variable slik som ble benyttet i regresjonsmodellen for klasse. I det nye datasettet spesifiseres f.eks. alle nivåene av en factor-variabel med funksjonen levels og predikerer for disse.\n\nnyedata &lt;- data.frame(klasse89 = levels(abu89$klasse89))\n\nnyedata %&gt;% \n  mutate(pred = predict(est2, newdata = nyedata))\n\n                  klasse89      pred\n1     I Øvre serviceklasse 118.39851\n2   II Nedre serviceklasse 103.90773\n3   III Rutinefunksjonærer  75.50009\n4  V-VI Faglærte arbeidere  88.71063\n5 VIIa Ufaglærte arbeidere  81.44618\n\n\n\n\n9.5.4 Predikere for multippel regresjon\nNytten av predict-funksjonen kommer mer til sin rett ved mer kompliserte modeller. Her er et eksempel med flere variable:\nSå kan vi regne ut estimert gjennomsnittlig verdi for de ulike kombinasjonene av utvalgte verdier som følger:\n\nnyedata &lt;- expand.grid(age = 30:35, \n                      sex = c(\"Female\", \"Male\"))\nnyedata %&gt;% \n  mutate(pred = predict(lm_est3, newdata = nyedata))\n\n   age    sex     pred\n1   30 Female 74.69049\n2   31 Female 75.16429\n3   32 Female 75.63810\n4   33 Female 76.11190\n5   34 Female 76.58571\n6   35 Female 77.05951\n7   30   Male 95.31560\n8   31   Male 95.78940\n9   32   Male 96.26320\n10  33   Male 96.73701\n11  34   Male 97.21081\n12  35   Male 97.68462\n\n\nFunksjonen predict fungerer på tilsvarende måte uansett hvor komplisert modellen måtte være. Men det kreves at det nye datasettet har samme variabelnavn og variabeltype som i opprinnelige data."
  },
  {
    "objectID": "linearRegresjon.html#pene-tabeller-og-eksport-til-fil",
    "href": "linearRegresjon.html#pene-tabeller-og-eksport-til-fil",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "9.6 Pene tabeller og eksport til fil",
    "text": "9.6 Pene tabeller og eksport til fil\nSlik resultatene ser ut med bruk av summary er forsåvidt fint, og du får den informasjonen du trenger. Men det er ikke særlig presentabelt som ferdig produkt i en analyse. Du trenger typisk to ting: 1) Samle flere regresjonsmodeller i samme tabell, og 2) gjøre tabellene penere og lettere å lese, og 3) eksportere til det tekstbehandlingsprogrammet du bruker, typisk Microsoft Word.\nR har en hel rekke funksjoner for dette. Det spiller egentlig ingen rolle hvilke funksjoner du bruker da det er noe smak og behag her, så det viktigste er at det fungerer rimelig greit for deg. Nedenfor presenteres tre pakker for dette formålet. Velg én av dem. Hvis du ikke har egne preferanser, så velg det første alternativet: {modelsummary}. Alle disse funksjonene håndterer svært mange typer modeller, gir gode muligheter for å ferdigstille tabellene fullstendig før eksport, og eksporterer til de formatene som er mest aktuelle. De har også mer avansert funksjonalitet som f.eks. å rapportere robuste standardfeil (av forskjellig type) i stedet for vanlige standardfeil (dette er pensum på SOS4020).\nVi vil som regel ha behov for å flytte resultatene over til et tekstbehandlingsprogram. En strategi som går ut på “klipp og lim” eller skjermbilde etc er uaktuelt og må unngås for nærmest enhver pris.8 Resultatene skal skrives til en fil på en effektiv måte. Det er en fordel om tabellene da ser ganske ok ut i utgangspunktet og du kan bruke samme prosedyre for å eksportere til flere typer format hvis behovet skulle melde seg. Det er jo MS Word som er viktigst for de fleste, mens de øvrige formatene nedenfor er for spesielt interessert - men noen av dere vil kanskje bli det på et senere tidspunkt. De viktigste formatene som er:\n\nMS Word - det vanligste tekstbehandlingsprogrammet som de aller fleste av dere bruker.\nrtf - rikt tekstformat. Er et enklere format som fungerer på tvers av de fleste programmer. Kan brukes i Word også.\nhtml - for websider\nlatex - for mer tekniske dokumenter, særlig hvis du har mye formler og stæsj\nMarkdown/Quarto - for dynamiske dokumenter med integrert R-kode og tekst, og kan eksportere ferdig dokument til alle ovennevnte formater9 Det som fungerer med Markdown fungerer også med Quarto for samme formål.\n\n\n9.6.1 Alt 1: Bruke modelsummary()\nEksporterer til bl.a. følgende formater: Word, rtf, html, latex, markdown\nFordel: Gir pene og oversiktlige tabeller med enkel kode, og relativt enkelt å modifisere videre. Eksporterer direkte til alle viktigste formater. Kan også lett integreres med andre eksterne verktøy, først og fremst “grammar of tables” i pakket {gt} Ulempe:\nHer er kode for en enkel tabell med to regresjonsmodeller som vist ovenfor. Merk at objektene med regresjonsresultatene må legges inni funksjonen list().\n\nlibrary(modelsummary)\nmodelsummary(list(lm_est2, lm_est3))\n\n\n\n\n\n (1)\n  (2)\n\n\n\n\n(Intercept)\n99.844\n81.101\n\n\n\n(0.637)\n(1.585)\n\n\nsexFemale\n-20.752\n-20.625\n\n\n\n(0.932)\n(0.912)\n\n\nage\n\n0.474\n\n\n\n\n(0.037)\n\n\nNum.Obs.\n3759\n3759\n\n\nR2\n0.117\n0.154\n\n\nR2 Adj.\n0.116\n0.153\n\n\nAIC\n35854.9\n35694.9\n\n\nBIC\n35873.6\n35719.8\n\n\nLog.Lik.\n-17924.434\n-17843.437\n\n\nF\n496.278\n341.699\n\n\nRMSE\n28.49\n27.88\n\n\n\n\n\n\n\nDenne tabellen inneholder mer enn du er interessert i. Nedre del av tabellen inneholder “goodness of fit” statistikker, altså mål på hvordan modellen passer til dataene. Det finnes mange slike, men ingen grunn til å gå seg vill i disse her. De kan fjernes med argumentet gof_omit = og så angis statistikkene med de navnene du ser i tabellen. Det skrives på en spesiell måte: som en tekststreng angitt med anførselstegn rundt, og | mellom hver. I koden nedenfor beholdes kun antall observasjoner, \\(r^2\\) og \\(F\\).10\nVi gjør et par andre justeringer samtidig for å demonstrere noe funksjonalitet. I stedet for å oppgi estimatet og standardfeil på forskjellig linje kan vi spesifisere å ha det på samme linje med argumentet estimate =. Merk at den statistikken du vil rapportere settes i parentes {…} og mellomrom og parentes er ellers som det står. Man har også andre valg, derav det vanligste i bruk er å angi p-verdier eller stjerner for å vise disse på en forenklet måte. Det angis ved {p.value} eller {stars} på tilsvarende måte.\nI stedet for standardfeil på egen linje er det her angitt konfidensintervall på neste linje. For konfidensintervall vil det som forvalg være 95%, men vi kan angi f.eks. 99% konfidensintervall i stedet ved conf_level =. Hvis man ikke vil ha noe på neste linje kan man angi statistic = NULL i stedet. Man kan også velge å sette inn p.value eller stars på denne linjen.\nMerk at utfallsvariabelen i modellene er timelønn i kroner. I forrige tabell ble estimatene gitt med tre desimaler. Det er i overkant mange desimaler. En desimal er mer passende og nedenfor endres dette med fmt =.\n\nmodelsummary(list(lm_est2, lm_est3), \n             fmt = 1,\n             estimate = \"{estimate} ({std.error})\",\n             statistic = 'conf.int', \n             conf_level = .99, \n             gof_omit = 'DF|Deviance|R2 Adj.|AIC|BIC|Log.Lik.|RMSE')\n\n\n\n\n\n (1)\n  (2)\n\n\n\n\n(Intercept)\n99.8 (0.6)\n81.1 (1.6)\n\n\n\n[98.2, 101.5]\n[77.0, 85.2]\n\n\nsexFemale\n-20.8 (0.9)\n-20.6 (0.9)\n\n\n\n[-23.2, -18.4]\n[-23.0, -18.3]\n\n\nage\n\n0.5 (0.0)\n\n\n\n\n[0.4, 0.6]\n\n\nNum.Obs.\n3759\n3759\n\n\nR2\n0.117\n0.154\n\n\nF\n496.278\n341.699\n\n\n\n\n\n\n\nTo siste ting å ta med her er å endre navn på variablene til noe mer presentabelt og eksportere til Word. Med argumentet coef_rename = angis variabelen slik den ser ut i output og spesifiserer hva du vil skal stå. Koden nedenfor viser eksempel.\nFor å eksportere til Word settes output = med filbane og filnavn, og der filhalen .docx angir Word format. Du kan eksportere til annet format ved å angi annen filhale f.eks. .rtf eller .html.\n\n\n\n\n\n\n (1)\n  (2)\n\n\n\n\nKonstant\n99.8 (0.6)\n81.1 (1.6)\n\n\n\n[98.2, 101.5]\n[77.0, 85.2]\n\n\nKvinne\n-20.8 (0.9)\n-20.6 (0.9)\n\n\n\n[-23.2, -18.4]\n[-23.0, -18.3]\n\n\nAlder\n\n0.5 (0.0)\n\n\n\n\n[0.4, 0.6]\n\n\nNum.Obs.\n3759\n3759\n\n\nR2\n0.117\n0.154\n\n\nF\n496.278\n341.699\n\n\n\n\n\n\n\n\nmodelsummary(list(lm_est2, lm_est3), \n             fmt = 1,\n             estimate = \"{estimate} ({std.error})\",\n             statistic = 'conf.int', \n             conf_level = .99, \n             gof_omit = 'DF|Deviance|R2 Adj.|AIC|BIC|Log.Lik.|RMSE', \n             coef_rename = c(\"sexFemale\" = \"Kvinne\", \n                                   \"age\" = \"Alder\", \n                                  \"(Intercept)\" = \"Konstant\"), \n             output = \"output/reg_table.docx\")\n\nMerk at Word vil vise tabellen med de fonter etc som er forvalgt for Word. Dette kan du endre i Word etterpå. Det er en rekke funksjoner i Word for å formattere tabeller som du kan bruke.\nPakken {modelsummary} har også en rekke andre funksjoner for å redigere tabeller som du kan utforske ved behov. For avanserte brukere kan man også gjøre om tabellen til et gt-objekt og redigere videre med pakken {gt} eller tilsvarende med pakken {flextable}. Det er altså tilnærmet uendelige muligheter for avanserte tabeller. Dette går imidlertid langt utenfor hva de fleste av dere vil trenge. {modelsummary} har egen hjemmeside med mer detaljer og instruksjoner.\n\n\n9.6.2 Alt 2: Bruke {stargazer}\nMange R-brukere foretrekker pakken {stargazer}. Dette er en noe eldre funksjon og er derfor godt etablert.\nEksporterer til bl.a. følgende formater: rtf, html, latex, markdown\nFordel: Er en stand-alone pakke men gir enkelt veldig fine tabeller som antakeligvis er det du trenger Ulempe: Eksport til Word er ikke den beste, men god nok.\nStargazer lager tabeller i kun tre formater: latex, html, og ren tekst. Vi velger derfor type = \"text\" for at det skal se ok ut her.\n\nlibrary(stargazer)\nstargazer(lm_est2, lm_est3, type = \"text\")\n\n\n=======================================================================\n                                    Dependent variable:                \n                    ---------------------------------------------------\n                                          time89                       \n                               (1)                       (2)           \n-----------------------------------------------------------------------\nsexFemale                  -20.752***                -20.625***        \n                             (0.932)                   (0.912)         \n                                                                       \nage                                                   0.474***         \n                                                       (0.037)         \n                                                                       \nConstant                    99.844***                 81.101***        \n                             (0.637)                   (1.585)         \n                                                                       \n-----------------------------------------------------------------------\nObservations                  3,759                     3,759          \nR2                            0.117                     0.154          \nAdjusted R2                   0.116                     0.153          \nResidual Std. Error    28.495 (df = 3757)        27.891 (df = 3756)    \nF Statistic         496.278*** (df = 1; 3757) 341.699*** (df = 2; 3756)\n=======================================================================\nNote:                                       *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nVi kan modifisere tabellen tilsvarende som vi gjorde med {modelsummary}. Forklaringer av de enkelte argumenter finnes i manualen for stargazer.\ncovariate.labels = Angir teksten for variabelnavn. Merk at det oppgis i den rekkefølgen det skal stå, så være veldig nøye hvis du har mange variable! report = angir hva som skal inngå i tabellen, der hver bokstav viser til spesifikke deler: v = variabelnavn, c = koeffisient/estimat, s = standardfeil. single.row = setter statistikkene på samme linje fremfor under hverandre. keep.stat = angir hvilke “model fit statistics” som skal rapporteres. Hvis du skriver “all” her får du en lang remse tilsvarende vi fikk med {modelsummary}. digits = angir antall desimaler\n\nstargazer(lm_est2, lm_est3, \n          type = \"text\", \n          covariate.labels = c(\"Kvinne\", \"Alder\", \"Konstant\"),\n          report = \"vcs\",\n          single.row = TRUE, \n          keep.stat = c(\"n\",\"rsq\", \"ser\"),\n          digits = 1)\n\n\n=====================================================\n                           Dependent variable:       \n                    ---------------------------------\n                                 time89              \n                          (1)              (2)       \n-----------------------------------------------------\nKvinne                -20.8 (0.9)      -20.6 (0.9)   \nAlder                                   0.5 (0.04)   \nKonstant               99.8 (0.6)       81.1 (1.6)   \n-----------------------------------------------------\nObservations             3,759            3,759      \nR2                        0.1              0.2       \nResidual Std. Error 28.5 (df = 3757) 27.9 (df = 3756)\n=====================================================\nNote:                     *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nFor å eksportere til Word kan man bruke rikt tekstformat (.rtf) eller html. rtf-formatet er som navnet tilsier ren tekst og selv om det ser greit ut, så er videre redigering i et tekstbehandlingsprogram krøkete. (Prøv og se selv). Bruk heller html fordi da beholdes tabell-strukturen. Du kan åpne html-tabeller fra Word og redigere videre der ved behov.\n\nstargazer(lm_est2, lm_est3, \n          type = \"text\",\n          covariate.labels = c(\"Kvinne\", \"Alder\", \"Konstant\"),\n          report = \"vcs\",\n          single.row = TRUE, \n          keep.stat = c(\"n\",\"rsq\", \"ser\"),\n          digits = 1, \n          out = \"output/reg_starg.html\")\n\nMer detaljer finner du i {stargazer} sin vignette.\n\n\n9.6.3 Alt 3: Bruke {gtsummary}\nVi har tidligere brukt {gtsummary} for å lage deskriptive tabeller, som er det pakken er best til. Men den kan også lage gode regresjonstabeller. Det er imidlertid en stor ulempe for nybegynnere i R: det er ganske krøkete å sette sammen flere regresjonsmodeller i en samlet tabell. Derfor er rådet å ikke bruke denne pakken med mindre du har veldig lyst til å prøve.\nFordel med å bruke denne pakken er at man slipper å lære enda en ny pakke og slik sett ha ett sett med konsistent syntaks. En mulighet er selvsagt å ikke lage tabellene så ferdig i R, men eksportere til Word og redigere ferdig der mer manuelt.\n{gtsummary} kan eksportere til følgende formater: Word, rtf, html, latex og markdown. Resultatene kan også lett integreres med andre funksjoner, først og fremst “grammar of tables” i pakket {gt} og {flextable} - altså for mer avanserte ting som vi ikke dekker her.\nPrinsippet er å lage hver tabell for seg og så slå dem sammen med tbl_merge etterpå. Det innebærer en del mer kode, rett og slett. I utgangspunktet virker det ganske greit, men det er alltid en del småting som krever litt mer.\nFølgende kode lager først en ryddig tabell for hver regresionsmodell og så kobler sammen disse to tabellene.\n\nlm_tab1 &lt;- tbl_regression(lm_est2, intercept = T, \n                          estimate_fun = function(x) style_number(x, digits = 1),\n                          show_single_row = \"sex\",\n                          label = list(sex ~ \"Kvinne\")) %&gt;% \n    add_glance_table(include = c(nobs, r.squared, sigma))\n                     \nlm_tab2 &lt;- tbl_regression(lm_est3, intercept = T,\n                          estimate_fun = function(x) style_number(x, digits = 1), \n                          show_single_row = \"sex\",\n                          label = list(age ~ \"Alder\", sex ~ \"Kvinne\")) %&gt;% \n    add_glance_table(include = c(nobs, r.squared, sigma)\n  )\n\n\ntbl_merge(tbls = list(lm_tab1, lm_tab2)) %&gt;% \n  modify_table_body(\n    ~.x %&gt;% \n      dplyr::arrange(\n        row_type == \"glance_statistic\", # sort glance table to bottom\n        var_label                       # sort by the variable label (a hidden column) \n      )\n  )\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      \n        Table 1\n      \n      \n        Table 2\n      \n    \n    \n      Beta\n      95% CI1\n      p-value\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n99.8\n98.6, 101.1\n&lt;0.001\n81.1\n78.0, 84.2\n&lt;0.001\n    Alder\n\n\n\n0.5\n0.4, 0.5\n&lt;0.001\n    Kvinne\n-20.8\n-22.6, -18.9\n&lt;0.001\n-20.6\n-22.4, -18.8\n&lt;0.001\n    No. Obs.\n3,759\n\n\n3,759\n\n\n    R²\n0.117\n\n\n0.154\n\n\n    Sigma\n28.5\n\n\n27.9\n\n\n  \n  \n  \n    \n      1 CI = Confidence Interval"
  },
  {
    "objectID": "linearRegresjon.html#footnotes",
    "href": "linearRegresjon.html#footnotes",
    "title": "9  Regresjon: Sammenheng mellom variable",
    "section": "",
    "text": "Du kan jo tenke deg flere parallelle linjer i plottet ovenfor med samme stigningstall↩︎\nGrunnen til det siste er at R kan ha flere datasett oppe samtidig, så R vet ikke nødvendigvis hvilket datasett du tenker på↩︎\nNoen ganger sier man at gjennomsnittslønna øker med 0.48 kroner for hvert år eldre man blir. Men det er ikke helt riktig, for dataene beskriver jo ikke individuell endringer over tid! Men hvis du synes det er lettere å tenke på det på den måten er det ok - men prøv å husk at det også er litt feil.↩︎\nDet er selvsagt ingenting enkelt med slike modeller utover at det finnes mer kompliserte varianter.↩︎\nNoen kaller dette også for multivariat regresjon, men det er tvetydig da det også kan bety modeller med flere utfallsvariable, som er noe ganske annet.↩︎\nf.eks. Et introduksjonskurs i maskinlæring som SOS2901 starter gjerne med nettopp prediksjon med lineær regresjon.↩︎\nHvis man ikke spesifiserer data.frame brukes opprinnelige data og predikerer for hver person. Det kan man også gjøre for å f.eks. regne ut residualer, men vi gjør ikke det her nå.↩︎\nHvis du blir tatt i å gjøre slikt vil faglærer sette fyr på datamaskinen din som straff.↩︎\nF.eks. dette dokumentet er skrevet i Quarto↩︎\nØvrige statistikker har selvsagt sitt bruksområde. De nevnte holder for de fleste formål.↩︎"
  },
  {
    "objectID": "linearRegresjon_kat.html#dummy-som-utfallsvariabel",
    "href": "linearRegresjon_kat.html#dummy-som-utfallsvariabel",
    "title": "10  Lineær sannsynlighetsmodell",
    "section": "10.1 Dummy som utfallsvariabel",
    "text": "10.1 Dummy som utfallsvariabel\nI samfunnsvitenskapen er utfallsvariabelen ganske ofte kategorisk. I en regresjon vil vi behandle kategoriske variable dem som om de er tall på kontinuerlig akse, også der det typisk bare finnes to verdier: 0 og 1. Dette kalles en dummyvariabel eller en indikatorvariabel.\nNår man bruker kategoriske variable i en lineær regresjon er det derfor ikke egentlig noe nytt. Det som står i boken om kontinuerlige variable gjelder også for kategoriske variable (i hvert fall for alle praktiske formål som dekkes for dette kurset).\nHusk at tolkningen av regresjonskoeffisienten, \\(b\\), tolkes på den skalaen \\(y\\)-variabelen er på. Altså: hvis utfallsvariabelen er i kroner, så er tolkningen av \\(b\\) i måleenheten kroner. Hvis y-variabelen er i antall timer, så er tolkningen av \\(b\\) i antall timer, osv. Husk også at vi estimerer endring i gjennomsnitt.\nNår utfallsvariabelen er en dummy, så har den verdiene 0 eller 1. Da er gjennomsnittet det samme som en andel. For eksempel: hvis utfallet er om man er i jobb eller ikke, og koder å være i jobb som 1 og 0 ellers. Hvis man har 5 personer, derav 3 er i jobb får man så: \\(\\bar{y} = \\frac{(0+0+1+1+1)} {5} = \\frac{3}{5}=0.6\\) som er det samme som 60%.\nI regresjon med slike variable er dermed utfallet en andel og dette kalles derfor ofte en «lineær sannsynlighetsmodell». Men det er egentlig en helt vanlig regresjonsmodell. Vi tolker fremdeles på den skalaen y-variabelen er på, som altså er en andel. (Vi skal forresten senere omtale andeler som estimater på sannsynligheter). En økning i \\(x\\)-variabelen tilsvarer altså en endring, b, i andelen med den egenskapen som er kodet 1 på \\(y\\)-variabelen.\nLa oss si at vi er interessert i å beskrive kjønnsforskjell i hvorvidt menn og kvinner jobber i privat vs offentlig sektor. Variabelen “private” er en factor-variabel der første kategori er “public”, som da blir referansekategorien. R regner da privat sektor som 1 mens offentlig sektor er 0. Koeffisientene vil da uttrykke forskjell i sannsynlighet for å være i privat sektor.\n\nlm(private ~ female + ed + age, data = abu89)\n\n\nCall:\nlm(formula = private ~ female + ed + age, data = abu89)\n\nCoefficients:\n(Intercept)       female           ed          age  \n   2.167030    -0.287998    -0.049017    -0.007274  \n\n\nVi ser her at sannsynligheten for at kvinner jobber i privat sektor er 0.28 lavere enn for menn, dvs. 28 prosentpoeng lavere. Dette er da kontrollert for utdanning og alder, slik at vi kan se bort fra at utdanningsnivå og forskjell i aldersfordeling i dataene kan være grunnen til forskjellene."
  },
  {
    "objectID": "grunnleggendeDesign.html#tre-nivåer-av-regresjonanalyse",
    "href": "grunnleggendeDesign.html#tre-nivåer-av-regresjonanalyse",
    "title": "11  Design og tolkning",
    "section": "11.1 Tre nivåer av regresjonanalyse",
    "text": "11.1 Tre nivåer av regresjonanalyse\nRichard Berk (R. A. Berk 2010; R. Berk 2016) beskriver tre nivåer av regresjonsanalyse basert på hvordan dataene ble til. Dette er et godt utgangspunkt som burde klargjøre betydelig, i hvert fall som et først skritt.\n\n11.1.1 Nivå I: Ikke tilfeldig utvalg fra en veldefinert populasjon\nGrunnlaget for statistisk tolkning (sannsynligheter, p-verdier og sånn) er at dataene er en tilfeldig realisering av en underliggende sann verdi. Typisk betyr dette bare at man har trukket et tilfeldig utvalg fra en populasjon. Da vil man få et godt mål på f.eks. gjennomsnittsverdi i populasjonen, men på grunn av tilfeldighet vil det være en feilmargin på denne målingen.\nDet avgjørende er altså at det finnes en veldefinert populasjon som det kan generaliseres til. Grunnen til å bruke begrepet veldefinert er at det må være rimelig spesifisert.\nHvis dataene ikke er fra en veldefinert populasjon kalles dette noen ganger for convenience sample. Altså, at man gjorde et uttrekk av beleilighetsgrunner, men uten at det var en veldefinert populasjon.\nEt eksempel kan være en arbeidsmiljøundersøkelse i en bestemt bedrift. Det skal litt til at disse resultatene skal gjelde utover denne bedriften. Man kan selvsagt argumentere for at erfaringene gjelder med generelt, men en slik slutning vil da hvile først og fremst på disse argumentene - ikke på statistiske utregninger.\nDet kan være veldig nyttig å analysere slike data, og det kan bringe innsikt og kunnskaper. Men med slike data gir det ikke mye mening å regne på statistisk usikkerhet. Hvis man ikke skal si noe utover de dataene man har (ikke generalisere), så er det heller ikke denne typen usikkerhet i målingene.\nSlike ikke-tilfeldige utvalg kan betraktes nærmest som case-studier. En dataanalyse vil gi oss kunnskaper om de erfaringene som gjøre akkurat der. Størrelsen på datasettet kan gi oss mer pålitelig informasjon om dette caset, men hjelper ikke for å generalisere utover caset.\n\n\n11.1.2 Nivå II: Tilfeldig utvalg fra en veldefinert populasjon\nTilfeldig utvalg er akkurat det det høres ut som, og er den foretrukne metoden for alle surveyundersøkelser. Teorien bak er at utvalget vil gjenspeile populasjonen, og avvik fra “de sanne verdiene” skyldes tilfeldigheter. Disse tilfeldighetene er grunnlaget for statistisk tolkning ved at vi kan si noe om samplingfordelingen (se annet kapittel) og dermed har grunnlag for å regne på standardfeil og p-verdier osv. Med andre ord: generalisering til populasjonen.\nSå er det viktig å påpeke at forutsetningen her er at det må være et utvalg fra en veldefinert populasjon. Hvis vi ikke vet hvem resultatene generaliserer til, så blir det jo tullete, og vi er egentlig på nivå 1.\n\n\n11.1.3 Nivå III: Estimering av kausale effekter\nFra et teknisk perspektiv er det ingenting som skiller studier av eksperimenter fra observasjonsstudier. De samme regresjonsmodellene kan estimeres og de samme utregningene av usikkerhet. Hva som bestemmer tolknigen (og hvorvidt modellspesifikasjonen er rimelig etc) avhenger av forskningsdesignet. Kort sagt kreves det et eksperiment. Hvis man har en treatment-gruppe og en kontrollgruppe, så vil \\(\\beta\\) beskrive forskjellen mellom disse gruppene som i andre typer data. Det som gir \\(\\beta\\) en kausal tolkning er om dataene tilfredsstiller kravene til et eksperiment.\nVi kan også regne inn kvasi-eksperimentelle studier eller naturlige eksperimenter her. Enten er disse studiene gode nok til å kvalifisere til å tolke som kausaleffekter - eller så er de det ikke, men da hører de hjemme på nivå II.\n\n\n11.1.4 Mot et nivå IV?\nI Berk sin fremstilling av de tre nivåene får man en følelse av at den vitenskapelige verdien øker ved hvert nivå. Mange vil da også mene akkurat det. Men logisk sett er det litt mer tvetydig enn som så.\nVi har snakket om to dimensjoner: kausalitet (ja/nei) og generalisering (ja/nei). Dette gir fire logisk mulige kombinasjoner.\n\n\n\nTable 11.1: Nivåer av regresjonsanalyse og hvor vanlige de er\n\n\n\n\n\n\n\n\nIkke tilfeldig utvalg fra veldefinert populasjon\nTilfeldig utvalg fra veldefinert populasjon\n\n\n\n\nDeskriptiv\nOverraskende mange\nDet aller meste\n\n\nKausal\nMye, men burde nok vært mer\nGanske sjelden\n\n\n\n\nJeg har ingen empiri for å si hvor vanlig hver enkelt type analyse er. Men jeg tror det nokså omtrentlige angivelsen i tabellen er ganske riktig, basert på egen erfaring fra studier jeg har lest og presentasjoner jeg har sett.\nI Berk sin fremstilling er Nivå III hele nederste rad, men da er det altså ikke gjort skille mellom om resultatene kan generaliseres videre eller ikke. Et slik skille bør man nok gjøre.\nEksperimenter omtales noen ganger - og i noen fagmiljøer - som gullstandarden. Men altså: ethvert eksperiment kan ikke være en gullstandard, ikke engang når formålet er å estimere kausaleffekter. Nivå IV er i så fall det vi ser etter, da nivå III har begrenset gyldighet. I tilsvarende ånd omtaler Berk eksperimenter som bronsestandarden, med den begrunnelse at det i praksis ikke er noe på palleplassene sølv og gull."
  },
  {
    "objectID": "grunnleggendeDesign.html#hva-er-poenget-her-egentlig",
    "href": "grunnleggendeDesign.html#hva-er-poenget-her-egentlig",
    "title": "11  Design og tolkning",
    "section": "11.2 Hva er poenget her, egentlig?",
    "text": "11.2 Hva er poenget her, egentlig?\nPoenget er at tolkning av resultatene handler vel så mye om hvordan dataene har blitt til som hvordan de er analysert. Hvis du har data på nivå I, så finnes det ingen statistiske krumspring du kan gjøre som løfter det til et annet nivå. Det samme gjelder nivå II og nivå III. Du kan fremdeles gjøre svært så nyttige og informative analyser på det nivået du har data på. De statistiske analyseteknikkene er det ellers ikke så stor forskjell på."
  },
  {
    "objectID": "grunnleggendeDesign.html#hva-med-sosiologisk-teori",
    "href": "grunnleggendeDesign.html#hva-med-sosiologisk-teori",
    "title": "11  Design og tolkning",
    "section": "11.3 Hva med sosiologisk teori?",
    "text": "11.3 Hva med sosiologisk teori?\nVi bruker kvantitative metoder til å beskrive statistiske sammenhenger. Men vi er jo ikke interessert i variablene som sådan. Poenget er å beskrive sosiale fenomener. Å si hva det betyr krever imidlertid en teoretisk tolkning. Å teste om et estimat er statistisk signifikant er ikke det samme som å teste en teori, selv om begge deler kan omtales med ordet “test”.\n\nGitt et fenomen (beskrevet med statistikk), hvordan kan vi forklare det?\nHva skjer med fenomenet vi er interessert i hvis vi gjør en intervensjon?\nGitt en teori, er observasjonsdata (dvs. statistikk) konsistent med teorien?\nGitt en teori, kan vi sjekke om observasjonsdata (dvs. statistikk) ikke er konsistent med teorien?\n\nDen første varianten handler om å først beskrive - gjerne eksplorerende - og så bruke teori til å forklare hvorfor det er slik. Det følger gjerne flere analyser som gjør beskrivelsen mer nyanserte og utforsker ulike muligheter.\nDen andre varianten handler om å måle effekter, gjerne et naturlig eksperiment eller et felteksperiment. Hvis man ønsker å vite hva effekten av et tiltak er, så må man endre noe slik at man kan observere resultatet. Randomisering handler om å håndtere seleksjon.\nDen tredje varianten er en konfirmerende strategi: En teori bør jo være konsistent med hvordan verden ser ut. Det er viktig å sjekke at dette er tilfellet. Hvis det er konsistent vet man jo det, men det er ikke en test av noe som helst fordi det kan jo være alternative teorier som forklarer minst like godt.\nDen fjerde varianten krever at teorien gir en empirisk forventning - helst som er motstridende med en annen teori. Hvis det kan vises empiriske mønster som er inkonsistente med teori, så må teorien enten forkastes eller i det minste justeres. Hvor mye vil være helt avhengig av den teoretiske påstanden.\nStatistiske tester, med p-verdier og konfidensintervaller, brukes til å skille mellom tilfeldig variasjon og systematisk variasjon på en tilsvarende måte for alle strategier.\n\n\n\n\nBerk, Richard. 2016. Statistical Learning from a Regression Perspective. USA: Springer.\n\n\nBerk, Richard A. 2010. “What You Can and Can’t Properly Do with Regression.” Journal of Quantitative Criminology 26: 481–87. https://doi.org/https://doi.org/10.1007/s10940-010-9116-4."
  },
  {
    "objectID": "statistiskTolkning.html#estimater-og-feilmarginer",
    "href": "statistiskTolkning.html#estimater-og-feilmarginer",
    "title": "12  Statistisk tolkning",
    "section": "12.1 Estimater og feilmarginer",
    "text": "12.1 Estimater og feilmarginer\n\n12.1.1 Estimat\nLa oss si at du ønsker å si noe om gjennomsnittet i populasjonen, men har bare data om et tilfeldig utvalg fra denne populasjonen. Når du da regner ut gjennomsnittet i utvalget er det din beste gjetning på hva gjennomsnittet er i populasjonen. En slik gjetning kaller vi et estimat.\n\n\n12.1.2 Standardfeil\nStandardfeilen uttrykker usikkerheten ved estimatet. Standardfeilen til estimatet er et mål på usikkerheten ved målemetoden. Usikker målemetode gjør at feilen kan være større.\nOrdet standardfeil er lett å blande sammen med standardavvik, så la oss ta det med det samme. Standardavviket beskriver variasjon i data, f.eks. hvis man vil beskrive hvordan personers inntekt varierer rundt gjennomsnittet. Standardavviket beskriver altå variasjon i data.\nStandardfeilen beskriver derimot ikke data, men sannsynlighetsfordelingen for hvordan vi forventer at estimatet vil kunne avvike fra den sanne verdien på grunn av tilfeldigheter.\nSentralgrenseteoremet sier at estimatet på et gjennomsnitt vil ha tilfeldige feil som er normalfordelt, og dermed kan vi bruke normalfordelingen til å si noe om usikkerheten ved estimatet. Dette er forsøkt illustrert nedenfor der x-aksen viser hvor mye estimatet kan avvike fra den sanne verdien, mens kurven viser hvor sannsynligsfordelingen til avviket. Den stiplede linjen viser den sanne verdien. Når x-aksen er avvik fra sanne verdien, så vil altså \\(x = 0\\) bety null avvik fra sanne verdien: helt riktig estimat.\nAltså: det er aller mest sannsynlig å få et estimat som ligger nærme den sanne verdien, men litt avvik (større eller lavere estimat) er nesten like sannsynlig. Jo lengre til hver av sidene man går (større feil), jo mindre sannsynlig er det å få et slikt estimat.\n\n\n\n\n\nSkalaen på x-aksen er \\(z\\), som i denne sammenheng kan tolkes som antall standardfeil. Den følger en standard normalfordeling som har kjente og faste egenskaper. Vi vet f.eks. at andelen nedenfor -1.96 er 0.025, og det samme gjelder ovenfor 1.96. Dette er illustrert i figuren nedenfor. Det er altså 0.05 (dvs 5%) sannsynlighet for å få et estimat som ligger 1.96 standardfeil unna den sanne verdien. Motsatt er sannsynligheten for å få et estimatet innenfor intervallet mellom -1.96 og 1.96 tilsvarende 95%. Dette er grunnlaget for det vi kaller konfidensintervall.\n\n\n\n\n\n\n\n12.1.3 Konfidensintervall\nHvis man ønsker å være “95% sikker”, så bruker man altså et 95% konfidensintervall. Det er ikke noe magisk ved akkurat 95% og er primært blitt en norm. Grunnen er bare at det skal være en ganske lav sannsynlighet for at estimatet skyldes tilfeldig variasjon.\nTil ethvert estimat er knyttet en feilmargin som uttrykkes ved \\(z \\times se\\), der \\(se\\) er forkortelse for standardfeil (engelsk: “standard error”). \\(z\\) er et tall som er knyttet til grad av usikkerhet ved feilmarginen. En feilmargin basert på 95% konfidensgrad er dermed \\(1.96 \\times se\\). Hvis man så tar denne feilmarginen til hver side, så gir det samme som illustrert i figuren ovenfor.\nEt konfidensintervall er altså bare å ta hensyn til feilmarginen til hver side av estimatet. Når vi bruker dette i praksis baserer vi oss på denne normalfordelingen og trenger bare å få regnet ut standardfeilen i tillegg.\n\n\n[1] 91.0712\n\n\nHvis man f.eks. har estimert gjennomsnittlig timelønn til å være 90.2 og standardfeilen er 0.5. Da blir 95% konfidensintervallet som følger:\n\\[ 90.1 \\pm 1.96 \\times 0.47 = [89.2, 91.1]\\] Dette betyr at vi har brukt en målemetode som har en feilmargin som gjør at vi kan være 95% sikker på at den sanne verdien ligger innenfor dette intervallet.\n\n12.1.3.1 Er man egentlig “95% sikker”?\nDet sies ofte at feilmarginen uttrykker hvor sikker man er. Det er jo ikke helt riktig - eller det er riktig under noen spesielle forutsetninger om hva man mener med “sikker”. La oss derfor ta dette med en gang.\nEt 95% konfidensintervall er vårt anslag på hvor god vår målemetode er. Vi har jo regnet ut f.eks. et gjennomsnitt og det er jo greit nok. Usikkerheten kommer fra utvalgsprosedyren og variasjonen i data.\nVi vet ikke hvorvidt vårt estimat ligger nærme eller langt unna den sanne verdien. Det vi derimot vet noe om er påliteligheten i den metoden vi har brukt. Det viktigste her er altså tilfeldig utvalg, og hvis utvalget ikke er tilnærmet tilfeldig trukket, så bryter det hele sammen.\nNår man sier at konfidensintervallet uttrykker at man er “95% sikker” på at den sanne verdien ligger i det intervallet mener man da følgende: Man har brukt en metode (dvs utvalg og utregninger og det hele) som har en feilmargin. Denne feilmarginen er slik at hvis man gjorde estimeringen (altså nytt utvalg hver gang) på samme måte svært mange ganger (f.eks. uendelig mange ganger), så ville 95% av resultatene ligget innenfor et slikt intervall.\nMan gjør selvsagt ikke samme undersøkelse tusenvis av ganger, så dette er en hypotetisk tanke. Man man kan også tenke seg at mange ulike forskere gjør en tilsvarende studie og får litt forskjellige resultat. Disse resultatene vil (i teorien) fordele seg som en normalfordeling rundt den sanne verdien. Noen ganske få vil ligge langt unna sannheten.\n\n\n\n12.1.4 T-testen\nHvis man skal sammenligne to grupper, så vet vi i utgangspunktet at dataene fra et utvalg antakeligvis vil vise at de ikke er helt like på grunn av tilfeldig variasjon. Det kan altså være at gruppene er like i virkeligheten, bare at dataene våre tilfeldigvis ble litt forskjellige. Det må vi jo regne med, men det er begrenset hvor forskjellig vi kan forvente at gruppene er på grunn av rene tilfeldigheter.\nSe igjen på figuren over av normalfordelingen i omtalen av konfidensintervall. Gitt at det ikke er noen sann forskjell mellom gruppene, så vil vi forvente at estimatet ligger innenfor en viss feilmargin. Det betyr at en observert forskjell i dataene som ligger innenfor denne feilmarginen vil være konsistent med at forskjellene bare skyldes tilfeldig variasjon. Motsatt: hvis estimatet ligger utenfor denne feilmarginen, ja da kan vi si at det ikke er konsistent med dette utgangspunktet om at forskjellene bare skyldes tilfeldig variasjon.\nEn av de meste brukte statistiske testene i praksis er “t-testen”. Du kan tenke på det som en beslutningsregel: hva skal til for at du skal bestemme deg for å tro at forskjellen ikke skyldes tilfeldigheter? Standardfeil og feilmarginer er det samme som før, så du må bare bestemme deg for hvor stor feilmargin du er villig til å operere med. Hvis estimatet på en differanse er større enn feilmarginen, da forkastes hypotesen om at forskjeller skyles tilfeldigher. Altså: forskjellene i data må da skyldes noe mer systematisk.\nSå i utgangspunktet så må du altså ta stilling til om du mener det er en forskjell - eller ikke. Du kan ikke konkludere med at det “kanskje er en forskjell”, men må ta et valg. Derfor kaller vi gjerne dette for hypotesetesting i en litt snever forstand. Det er bare to mulige hypoteser:\n\\(H_0\\): Det er egentlig ingen forskjell mellom gruppene, og forskjell i dataene skyldes bare tilfeldig variasjon. (Nullhypotesen). \\(H_A\\): Det er faktisk en forskjell mellom gruppene, og forskjellen i dataene er for stor til av det er sannsynlig at det skyldes tilfeldig variasjon. (Alternativ hypotese).\n\n12.1.4.1 Formler og slikt\nT-testen i prinsippet en sammenligning mellom estimatets størrelse og standardfeilen til estimatet. Vi kan skrive det som følger:\n\\[\n\\frac{\\mu}{SE(\\mu)} = t\n\\]\nEller sagt på en annen måte: \\[\n\\frac{estimat}{standardfeil} = t\n\\]\nDet betyr at \\(t\\)-verdien egentlig bare er forholdstallet mellom estimatet og standardfeilen. Intuitivt kan man vel forstå at hvis usikkerheten bør være mindre enn estimatet. Altså: hvis du har estimert en forskjell i timelønn mellom to grupper, og feilmarginen til dette estimatet er større enn forskjellen, ja, da er det vanskelig å lære noe særlig fra det estimatet.\nVerdien \\(t\\) tilsvarer verdien \\(z\\) som vi nevnte i forbindelse med konfidensintervall. Så hvis \\(t\\) er større enn \\(z\\), så ligger estimatet utenfor konfidensintervallet.\nTolkningen av \\(t\\)-verdien brukes gjerne som en en beslutningsregel: Ja/Nei. Litt firkantet, med andre ord. Men \\(t\\)-verdien er også knyttet til normalfordelingen på samme måte som nevnt ovenfor i forbindelse med konfidensintervaller. Ethvert mulig resultat er knyttet til en viss sannsynlighet for at det skal skje ved en tilfeldighet.\n\n\n12.1.4.2 P-verdi\nTolkningen av p-verdien er i hvilken grad det er sannsynlig å få det observerte resultatet ved en tilfeldighet hvis NULL-hypotesen er riktig. Dette høres ganske pussig ut. Tanken er at man nesten alltid vil observere noe forskjell fra null, og det kan skje ved en tilfeldighet. Hvis null-hypotesen er riktig er det mindre sannsynlig at vi observerer en veldig stor forskjell. Men hvor stor forskjell er det, egentlig? Løsningen er å se avstanden fra null i lys av standardfeilen. Hvis man bruker en usikker målemetode, så er det mer sannsynlig å observere en stor forskjell ved tilfeldigheter enn om man bruker en veldig nøyaktig målemetode.\nI praksis: Tenk at du observerer en stor forskjell mellom to grupper. Med “stor” mener vi f.eks. at forskjellen er over dobbelt så stor som standardfeilen. Da får vi en p-verdi som er \\(p &lt; 0.05\\). Da kan vi si at hvis nullhypotesen er sann, så er det lite sannsynlig at vi ville fått et slikt resultat på grunn av tilfeldigheter.^(Hvis vi ønsker være pinlig korrekte kan vi også si noe slikt som at hvis man gjorde målingen tusenvis av ganger, så ville 5% av resultatene ligge så langt unna null (eller lengre).)\nSå er logikken videre at vi som hovedregel ikke tror på resultater som er usannsynlige. Så i stedet for å holde fast på nullhypotesen velger vi i stedet å tro på den alternative hypotesen."
  },
  {
    "objectID": "statistiskTolkning.html#kan-man-velge-fritt-konfidensgrad",
    "href": "statistiskTolkning.html#kan-man-velge-fritt-konfidensgrad",
    "title": "12  Statistisk tolkning",
    "section": "12.2 Kan man velge fritt konfidensgrad?",
    "text": "12.2 Kan man velge fritt konfidensgrad?\nDet er ingenting magisk med tallet 1.96 eller \\(p &lt; 0.05\\). Det er en konvensjon. Konfidensgrad er nemlig noe du velger. All tolkning av “statistisk signifikans” er basert på en gitt konfidensgrad.\nProblemet oppstår hvis du først ser på resultatene og så velger en konfidensgrad som passer til det du har mest lyst til å konkludere med. Det er rett og slett juks. For at du skal velge en annen konfidensgrad må du si det høyt og tydelig før du gjennomfører undersøkelsen - og da må du faktisk etterleve det når resultatene foreligger. Du bør også kunne argumentere selvstendig for en annen konfidensgrad, altså før resultatene foreligger. Dette innebærer at det ikke er godt nok å si det høyt ut i luften der du sitter alene for deg selv. Det må pre-registeres på et offentlig sted, f.eks. osf.io eller tilsvarende websider.\nDette er egentlig en mye større diskusjon, men verd å være obs på. Du kan velge konfidensgrad, men i så fall må du gjøre det på en ordenlig måte hvis du vil bli tatt seriøst av andre. Vi skal ikke drive med cherry-picking av resultater og konklusjoner!"
  },
  {
    "objectID": "statistiskTolkning.html#statistiske-tester-generelt",
    "href": "statistiskTolkning.html#statistiske-tester-generelt",
    "title": "12  Statistisk tolkning",
    "section": "12.3 Statistiske tester generelt",
    "text": "12.3 Statistiske tester generelt\nDet finnes en hel haug av statistiske tester. Prinsippet er gjerne variasjoner av t-testen og har disse komponentene:\n\nen nullhypotese og et alternativ\nen statistikk, altså et måltall som er et avstandsmål mellom observert resultat og hva man forventer under nullhypotesen\nen statistisk modell for samplingfordelingen som sier noe om fordelingen av tilfeldige feil\nen uttalt beslutningsregel for konklusjonen. Et vanlig mål er at hvis \\(p &lt; 0.05\\), så forkastes nullhypotesen.\n\nDu har sikker lært om \\(\\chi^2\\) testen for krysstabeller. Den er forskjellig på mange måter fra \\(t\\)-testen, men logikken er tilsvarende: \\(\\chi^2\\) er et avstandsmål for hva vi forventer gitt hypotesen om ingen forskjell. Hvis resultatet fra dataanalysen er for langt unna dette, så beslutter vi å tro at forskjellen skyldes systematikk.\n\n\n\n\nMoore, David S., Notz William I, and Michael Fligner. 2021. The Basic Practice of Statistics. W.H.Freeman & Co Ltd."
  },
  {
    "objectID": "statistiskTolkning.html#footnotes",
    "href": "statistiskTolkning.html#footnotes",
    "title": "12  Statistisk tolkning",
    "section": "",
    "text": "Hvis dette er ukjent stoff for deg kan du se f.eks. Moore, Notz, and Fligner (2021), kapittel 15, etterfulgt av forlengelsen til konfidensintervall og statistiske tester i kapittel 16 og 17.↩︎"
  },
  {
    "objectID": "praktiskStatistikk.html#deskriptiv-statistikk",
    "href": "praktiskStatistikk.html#deskriptiv-statistikk",
    "title": "13  Statistikk i praksis",
    "section": "13.1 Deskriptiv statistikk",
    "text": "13.1 Deskriptiv statistikk\nNår man har en tabell med deskriptiv statistikk fordelt på grupper, så gjør man jo en sammenligning av disse gruppene på de aktuelle variablene. Da kan man bare legge til en statistisk test for denne sammenligningen. I følgende eksempel brukes tbl_summary med tilhørende add_difference. I første omgang tar vi bare med kontinuerlige variable. Resultatet blir tilsvarende som i det tidligere kapittelet for deskriptiv statistikk, men her legges det til tre kolonner: forskjellen i gjennomsnitt, konfidensintervallet og p-verdi fra en \\(t\\)-test.^(Legg merke til fotnoten som spesifiserer “Welch two sample t-test”. Dette er den vanlig t-testen. Den opprinnelige “Student’s t-test” forutsetter lik varians i begge grupper, noe som Welch t-test ikke gjør. Vi kaller det bare for \\(t\\)-test. Dette bare til oppklaring.)\n\ntheme_gtsummary_mean_sd()\nabu89 %&gt;% \n  #select(-io_nr) %&gt;%\n  select(female, time89, ed,  fexp, age) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n    tbl_summary(by = female, \n                label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;% \n  add_difference() \n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Kvinner, N = 1,9341\n      Menn, N = 2,1931\n      Difference2\n      95% CI2,3\n      p-value2\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n79 (24)\n100 (32)\n-21\n-23, -19\n&lt;0.001\n    År utdanning\n2.38 (2.40)\n2.96 (2.66)\n-0.58\n-0.74, -0.43\n&lt;0.001\n    Bedriftserfaring\n0.83 (0.81)\n1.05 (0.97)\n-0.22\n-0.27, -0.16\n&lt;0.001\n    Alder\n40 (13)\n40 (12)\n-0.17\n-0.93, 0.58\n0.7\n  \n  \n  \n    \n      1 Mean (SD)\n    \n    \n      2 Welch Two Sample t-test\n    \n    \n      3 CI = Confidence Interval\n    \n  \n\n\n\n\nLegg merke til at kollonnen “Difference” er forskjellen i gjennomsnitt i de to gruppene, og konfidensintervallet gjelder for denne differansen. Den gjennomsnittlige forskjellen i timelønn for menn er altså 21 kroner høyere enn for kvinner, men når vi tar feilmarginen med i beregningen er det rimelig å si at den ligger mellom 19 og 23 kroner høyere for menn enn for kvinner, siden et 95% konfidensintervall tilsier det.\n\nabu89 %&gt;% \n  select(female, time89, ed,  fexp, age) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n    tbl_summary(by = female, \n                label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;% \n  add_p() \n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Kvinner, N = 1,9341\n      Menn, N = 2,1931\n      p-value2\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n79 (24)\n100 (32)\n&lt;0.001\n    År utdanning\n2.38 (2.40)\n2.96 (2.66)\n&lt;0.001\n    Bedriftserfaring\n0.83 (0.81)\n1.05 (0.97)\n&lt;0.001\n    Alder\n40 (13)\n40 (12)\n0.7\n  \n  \n  \n    \n      1 Mean (SD)\n    \n    \n      2 Welch Two Sample t-test\n    \n  \n\n\n\n\nFor kategoriske variable bruker man ikke en t-test, men en test som omtales som \\(\\chi^2\\) test (uttales som “kji-kvadrat test”).1\n\nabu89 %&gt;% \n  select(female, klasse89, promot, private) %&gt;% \n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n    tbl_summary(by = female, \n                label = list(klasse89 = \"Klasse\"), \n              missing = \"no\") %&gt;% \n  add_p() \n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Kvinner, N = 1,9341\n      Menn, N = 2,1931\n      p-value2\n    \n  \n  \n    Klasse\n\n\n&lt;0.001\n        I Øvre serviceklasse\n74 (3.9%)\n254 (12%)\n\n        II Nedre serviceklasse\n555 (29%)\n626 (29%)\n\n        III Rutinefunksjonærer\n986 (52%)\n262 (12%)\n\n        V-VI Faglærte arbeidere\n46 (2.4%)\n602 (28%)\n\n        VIIa Ufaglærte arbeidere\n244 (13%)\n393 (18%)\n\n    Noen gang forfremmet\n\n\n&lt;0.001\n        NEI\n1,308 (68%)\n1,260 (57%)\n\n        JA\n626 (32%)\n933 (43%)\n\n    Privat sektor\n\n\n&lt;0.001\n        Public\n1,016 (53%)\n586 (27%)\n\n        Private\n918 (47%)\n1,607 (73%)\n\n  \n  \n  \n    \n      1 n (%)\n    \n    \n      2 Pearson’s Chi-squared test\n    \n  \n\n\n\n\nDet kan også settes sammen i en felles tabell.\n\nabu89 %&gt;% \n  select(-io_nr) %&gt;%\n  mutate(female = ifelse(female == 0, \"Menn\", \"Kvinner\")) %&gt;% \n    tbl_summary(by = female, \n                label = list(klasse89 = \"Klasse\"), \n              type = list(ed ~ \"continuous\"), \n              missing = \"no\") %&gt;% \n  add_overall() %&gt;% \n  add_p() \n\n\n\n\n\n  \n    \n    \n      Characteristic\n      Overall, N = 4,1271\n      Kvinner, N = 1,9341\n      Menn, N = 2,1931\n      p-value2\n    \n  \n  \n    Gjennomsnittlig timelønn 1989\n90 (30)\n79 (24)\n100 (32)\n&lt;0.001\n    År utdanning\n2.69 (2.56)\n2.38 (2.40)\n2.96 (2.66)\n&lt;0.001\n    Alder\n40 (12)\n40 (13)\n40 (12)\n0.7\n    Klasse\n\n\n\n&lt;0.001\n        I Øvre serviceklasse\n328 (8.1%)\n74 (3.9%)\n254 (12%)\n\n        II Nedre serviceklasse\n1,181 (29%)\n555 (29%)\n626 (29%)\n\n        III Rutinefunksjonærer\n1,248 (31%)\n986 (52%)\n262 (12%)\n\n        V-VI Faglærte arbeidere\n648 (16%)\n46 (2.4%)\n602 (28%)\n\n        VIIa Ufaglærte arbeidere\n637 (16%)\n244 (13%)\n393 (18%)\n\n    Noen gang forfremmet\n\n\n\n&lt;0.001\n        NEI\n2,568 (62%)\n1,308 (68%)\n1,260 (57%)\n\n        JA\n1,559 (38%)\n626 (32%)\n933 (43%)\n\n    Bedriftserfaring\n0.95 (0.91)\n0.83 (0.81)\n1.05 (0.97)\n&lt;0.001\n    Privat sektor\n\n\n\n&lt;0.001\n        Public\n1,602 (39%)\n1,016 (53%)\n586 (27%)\n\n        Private\n2,525 (61%)\n918 (47%)\n1,607 (73%)\n\n  \n  \n  \n    \n      1 Mean (SD); n (%)\n    \n    \n      2 Welch Two Sample t-test; Pearson’s Chi-squared test"
  },
  {
    "objectID": "praktiskStatistikk.html#footnotes",
    "href": "praktiskStatistikk.html#footnotes",
    "title": "13  Statistikk i praksis",
    "section": "",
    "text": "Denne gir identisk resultat som z-test for andeler.↩︎"
  },
  {
    "objectID": "tidyverse.html#lage-ny-variabel-mutate",
    "href": "tidyverse.html#lage-ny-variabel-mutate",
    "title": "14  Datahåndtering med Tidyverse",
    "section": "14.1 Lage ny variabel: mutate",
    "text": "14.1 Lage ny variabel: mutate\nAlle verbene i tidyverse starter med å angi hvilket objekt man skal gjøre noe med, altså datasettet.\nHer er et eksempel der man lager en ny variable som summen av eksisterende variablene x og z.\n\nnyttobjekt &lt;- mutate(dinedata, nyvariabel = x + z)\n\nHer er et eksempel der man lager to variable samtidig der den andre er x delt på z.\n\nnyttobjekt &lt;- mutate(dinedata, nyvariabel = x / z,\n                     nyvariabel2 = x + z)"
  },
  {
    "objectID": "tidyverse.html#rørlegging-hva-i-alle-dager-betyr",
    "href": "tidyverse.html#rørlegging-hva-i-alle-dager-betyr",
    "title": "14  Datahåndtering med Tidyverse",
    "section": "14.2 Rørlegging: Hva i alle dager betyr %>% ??",
    "text": "14.2 Rørlegging: Hva i alle dager betyr %&gt;% ??\nSymbolet %&gt;% kalles in “pipe” eller på norsk: rørlegging. Det betyr at det som står til venstre flyttes over til høyre. Eller sagt på en annen måte betyr det: “Gjør deretter følgende”. Vi vil bruke denne syntaxen konsekvent fra nå når vi introduserer de ulike “verbene”.\n\nnyttobjekt &lt;- dinedata %&gt;% \n  mutate(nyvariabel = x / z,\n         nyvariabel2 = x + z)\n\nDenne koden sier følgende, linje for linje:\n\nlag en kopi av dinedata og lagre det i nyttobjekt ^deretter gjør du følgende:^\nlag de nye variablene nyvariabel som får verdier fra variablene x delt på y\nog nyvariabel2som summen av x og z"
  },
  {
    "objectID": "tidyverse.html#beholde-og-slette-variable-select",
    "href": "tidyverse.html#beholde-og-slette-variable-select",
    "title": "14  Datahåndtering med Tidyverse",
    "section": "14.3 Beholde og slette variable: select",
    "text": "14.3 Beholde og slette variable: select"
  },
  {
    "objectID": "tidyverse.html#aggregere-summarise",
    "href": "tidyverse.html#aggregere-summarise",
    "title": "14  Datahåndtering med Tidyverse",
    "section": "14.4 Aggregere: summarise",
    "text": "14.4 Aggregere: summarise"
  },
  {
    "objectID": "tidyverse.html#grupperte-utregninger-group_by",
    "href": "tidyverse.html#grupperte-utregninger-group_by",
    "title": "14  Datahåndtering med Tidyverse",
    "section": "14.5 Grupperte utregninger: group_by",
    "text": "14.5 Grupperte utregninger: group_by"
  },
  {
    "objectID": "tidyverse.html#sette-det-hele-sammen",
    "href": "tidyverse.html#sette-det-hele-sammen",
    "title": "14  Datahåndtering med Tidyverse",
    "section": "14.6 Sette det hele sammen",
    "text": "14.6 Sette det hele sammen"
  },
  {
    "objectID": "omkode_factor.html#endre-variabelnavn-med-rename-og-mutate",
    "href": "omkode_factor.html#endre-variabelnavn-med-rename-og-mutate",
    "title": "15  Omkoding av variable",
    "section": "15.1 Endre variabelnavn med rename og mutate",
    "text": "15.1 Endre variabelnavn med rename og mutate"
  },
  {
    "objectID": "omkode_factor.html#kontinuerlige-variable",
    "href": "omkode_factor.html#kontinuerlige-variable",
    "title": "15  Omkoding av variable",
    "section": "15.2 Kontinuerlige variable",
    "text": "15.2 Kontinuerlige variable\nÅ omkode kontinuerlige variable er i utgangspunktet det enkleste. Dette er tall og man kan gjøre normale regneoperasjoner på dem."
  },
  {
    "objectID": "omkode_factor.html#tekstvariable-strings",
    "href": "omkode_factor.html#tekstvariable-strings",
    "title": "15  Omkoding av variable",
    "section": "15.3 Tekstvariable (strings)",
    "text": "15.3 Tekstvariable (strings)"
  },
  {
    "objectID": "omkode_factor.html#factorvariable",
    "href": "omkode_factor.html#factorvariable",
    "title": "15  Omkoding av variable",
    "section": "15.4 Factorvariable",
    "text": "15.4 Factorvariable\nR har en egen variabeltype for kategoriske variable som kalles “factor”. I utgangspunktet er kategoriske variable mer å regne som tekstvariable enn som tall, men i en del beregninger vil softwaren bruke numeriske verdier uansett. Hvis man gjør om en tekst-variabel til en factor-variabel beholdes teksten, men kategoriene numeriske verdier 1, 2, 3, … osv. Disse tallene kan du tenke på som rekkefølgen på kategoriene. For kategoriske variable er det jo ikke noen egentlig rekkefølge, men det kan være grunner til å foretrekke rekkfølgen av andre grunner som vi kommer tilbake til.\nHvis variabelen er ordnet f.eks. på en skala fra 1 til 5 eller annen naturlig rekkefølge1, så kan man også angi dette.\n\n15.4.1 Få oversikt over factor-levels med levels()\n\nlevels(norlag_ex$wr117zz)\n\n[1] \"Nei\"                                                               \n[2] \"Ja\"                                                                \n[3] \"filter: jobber deltid\"                                             \n[4] \"filter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet)\"\n[5] \"filter: ikke i arbeid\"                                             \n[6] \"vil ikke svare\"                                                    \n[7] \"vet ikke\"                                                          \n[8] \"mangler data\"                                                      \n[9] \"Deltok ikke i runden\"                                              \n\n\n\n\n15.4.2 Enkel omkoding med fct_recode() og fct_collapse()\n\n\n15.4.3 Endre rekkefølgen på faktorene med fct_reorder()"
  },
  {
    "objectID": "omkode_factor.html#betinget-omkoding-med-ifelse-og-case_when",
    "href": "omkode_factor.html#betinget-omkoding-med-ifelse-og-case_when",
    "title": "15  Omkoding av variable",
    "section": "15.5 Betinget omkoding med ifelse() og case_when()",
    "text": "15.5 Betinget omkoding med ifelse() og case_when()\nDu kan lære mer om effektiv håndtering av kategoriske variable med forcats-pakken, som er en del av “tidyverse”."
  },
  {
    "objectID": "omkode_factor.html#factorvariable-med-skikkelig-lang-tekst",
    "href": "omkode_factor.html#factorvariable-med-skikkelig-lang-tekst",
    "title": "15  Omkoding av variable",
    "section": "15.6 Factorvariable med skikkelig lang tekst",
    "text": "15.6 Factorvariable med skikkelig lang tekst\nNår man omkoder en variabel må man skrive hele tekstverdien man ønsker endre, og det må være nøyaktig likt stavet. Særlig i survey-data vil disse tekststrengene kunne være lange og det gir jo større muligheter for å skrive feil og du kan få andre resultater enn forventet. Det kan også være vanskelig å finne feilen i lange tekststrenger! Så det er altså noe hærk. Kan man gjøre dette på en lurere måte? Minst mulig tårer? Ja, selvsagt.\nVi jobber normalt med factorvariable for kategoriske variable. I NorLAG er variabelen wr117zz svar på et spørsmål om “Mulighet for å redusert arbeidstid (deltid)”. Når denne variabelen er gjort om til factor kan man se hvilke verdier variabelen har med bruke av funksjonen levels() slik:\n\nlevels(norlag_ex$wr117zz)\n\n[1] \"Nei\"                                                               \n[2] \"Ja\"                                                                \n[3] \"filter: jobber deltid\"                                             \n[4] \"filter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet)\"\n[5] \"filter: ikke i arbeid\"                                             \n[6] \"vil ikke svare\"                                                    \n[7] \"vet ikke\"                                                          \n[8] \"mangler data\"                                                      \n[9] \"Deltok ikke i runden\"                                              \n\ntable(norlag_ex$wr117zz)\n\n\n                                                               Nei \n                                                              1360 \n                                                                Ja \n                                                              4146 \n                                             filter: jobber deltid \n                                                              1964 \nfilter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet) \n                                                              1171 \n                                             filter: ikke i arbeid \n                                                              6238 \n                                                    vil ikke svare \n                                                                 9 \n                                                          vet ikke \n                                                               382 \n                                                      mangler data \n                                                                67 \n                                              Deltok ikke i runden \n                                                                 0 \n\n\nLa oss si at vi vil kode om slik at vi får en variabel som bare er om vedkommende har mulighet til å jobbe deltid eller ikke. De som allerede jobber deltid har jo åpenbart mulighet til det, så de skal kodes om til “Ja”. De andre kategoriene er egentlig grunner til at det mangler data, så de skal settes til NA. En mulighet er da å omkode som følger:\n\nnorlag_omkodet &lt;- norlag_ex %&gt;%\n  mutate(redarbtid = replace(wr117zz, wr117zz == \"filter: jobber deltid\", \"Ja\"), \n         redarbtid = replace(redarbtid, redarbtid == \"filter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet)\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"filter: ikke i arbeid\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"vil ikke svare\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"vet ikke\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"mangler data\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"Deltok ikke i runden\", NA)) %&gt;% \n  droplevels()\n\nnorlag_omkodet %&gt;% \n  select(redarbtid) %&gt;% \n  gtsummary::tbl_summary()\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      N = 20,8921\n    \n  \n  \n    redarbtid\n\n        Nei\n1,360 (18%)\n        Ja\n6,110 (82%)\n        Unknown\n13,422\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nDette funker, men blir ganske mye tekst å skrive, og da kan man altså lett skrive feil. Husk at faktornivåene må angis helt nøyaktig slik de er skrevet! Merk at den siste funksjone, droplevels, bare fjerner faktor-levels som ikke er i bruk.\nI output for faktor-levels angir klammeparentesen gir rekkefølgen på disse verdiene. Vi kan bruke denne informasjonen direkte i omkodingen for å unngå å skrive så veldig mye. Når man bruker levels() får man en vektor med verdier, og disse kan man altså henvise til med rekkefølgen. Her er et eksempel for bare å bytte ut de som jobber deltid til “Ja”:\n\nnorlag_omkodet &lt;- norlag_ex %&gt;%\n  mutate(redarbtid = replace(wr117zz, wr117zz == levels(wr117zz)[3], \"Ja\")) %&gt;% \n  droplevels()\n\nTrikset her er altså å bruke levels og vise til hvilket nummer i rekkefølgen. Da unngår vi også faren for skrivefeil.\nVi vil også kode om alle de andre verdiene, nummer 4-9 til NA. Det kan vi gjøre på samme måte, men vi behøver ikke skrive en ny linje for hver verdi. Den logiske operatoren == kan man bruke når man skal sjekke om to verdier er like. Hvis vi skal se om en verdi er lik en av flere mulige kan vi bruke %in% og så en liste med verdier. levels gir en liste med verdier, så da kan vi angi den direkte og alle verdiene 4 til 9 ved å skrive 4:9. Samlet blir det da slik:\n\nnorlag_omkodet &lt;- norlag_ex %&gt;%\n  mutate(redarbtid = replace(wr117zz, wr117zz == levels(wr117zz)[3], \"Ja\"), \n         redarbtid = replace(redarbtid, redarbtid %in% levels(wr117zz)[4:9], NA)) %&gt;% \n  droplevels()\n\nmemisc::codebook(norlag_omkodet$redarbtid)\n\n================================================================================\n\n   norlag_omkodet$redarbtid\n\n--------------------------------------------------------------------------------\n\n   Storage mode: integer\n   Factor with 2 levels\n\n   Levels and labels     N Valid Total\n                                      \n    1 'Nei'           1360  18.2   6.5\n    2 'Ja'            6110  81.8  29.2\n   NA                13422        64.2"
  },
  {
    "objectID": "omkode_factor.html#spesielle-problemstillinger-ved-veldig-mange-kategorier",
    "href": "omkode_factor.html#spesielle-problemstillinger-ved-veldig-mange-kategorier",
    "title": "15  Omkoding av variable",
    "section": "15.7 Spesielle problemstillinger ved veldig mange kategorier",
    "text": "15.7 Spesielle problemstillinger ved veldig mange kategorier\nFor disse eksemplene skal vi bruke et litt annet datasett, nemlig et lite uttrekk fra European Social Survey. Her er det 3 variable: yrkeskode, kjønn og politisk interesse.\n\npolit &lt;- read.csv2(\"data/politics.csv\", colClasses = \"character\")\n\nglimpse(polit)\n\nRows: 49,519\nColumns: 3\n$ isco08  &lt;chr&gt; \"3333\", \"7122\", \"4221\", \"4311\", \"6130\", \"7212\", \"5131\", \"5223\"…\n$ gndr    &lt;chr&gt; \"1\", \"1\", \"2\", \"1\", \"2\", \"1\", \"1\", \"2\", \"1\", \"2\", \"1\", \"2\", \"1…\n$ polintr &lt;chr&gt; \"3\", \"2\", \"4\", \"3\", \"2\", \"2\", \"4\", \"3\", \"3\", \"4\", \"2\", \"2\", \"1…\n\n\nVi kan sjekke hvor mange kategorier det er ved å lage en tabell over kodene og se hvor mange det er. Det er imidlertid upraktisk da den tabellen tar veldig mye plass. Koden nedenfor gjør en enklere opptelling ved å trekke ut unike verdier og telle hvor mange det er:\n\nantall_koder &lt;- polit %&gt;%  \n  pull(isco08) %&gt;%   # trekker ut en vektor med kun en variabel \n  unique() %&gt;%       # beholder kun unike verdier \n  length()           # lengden på gjenværende vektor \n\nantall_koder\n\n[1] 561\n\n\nDet er altså 561 unike yrkeskoder i datasettet.\n\n15.7.1 Hierarkisk strukturerte tall som tekststrenger\nNoen ganger er det hundrevis av verdier. Et slik eksempel er yrkesklassifisering der hver type yrke har en spesifikk kode. Det finnes mange typer yrker, så det er omlag 800 koder. For de fleste typer analyser er dette altfor detaljert og du trenger å gruppere til færre kategorier. SSB har en kodeliste offentlig tilgjengelig. Kort fortalt er det en kode med 4 siffer, der det første sifferet er en grov gruppering, og de etterfølgende sifrene innebærer en økt detaljeringsgrad innenfor grupperingen angitt ved første siffer.\nHvis du skulle omkodet yrker slik som forklart i et tidligere avsnitt om omkoding ville det tatt veldig lang tid, men det ville også være veldig lett å gjøre feil. Det vil rett og slett være et mareritt å de-bugge koden for å finne feil eller kvalitetssjekke. Altså: en slik tilnærming er helt uaktuelt. En langt bedre tilnærming er å bare trekke ut det første sifferet fra koden. Funksjonen str_sub() gjør akkurat slike ting ved å angi hvilken del av tekststrengen du vil trekke ut, angitt ved posisjonen du starter ved og slutter ved. Her er det altså første posisjon.\n\npolit &lt;- polit %&gt;% \n  mutate(occupation = str_sub(isco08, start = 1, end = 1)) \n\npolit %&gt;% \n  select(gndr, occupation) %&gt;% \n  tbl_summary(by = gndr)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1, N = 23,0201\n      2, N = 26,4991\n    \n  \n  \n    occupation\n\n\n        \n1,847 (8.0%)\n2,947 (11%)\n        0\n5 (&lt;0.1%)\n1 (&lt;0.1%)\n        1\n2,185 (9.5%)\n1,350 (5.1%)\n        2\n3,665 (16%)\n5,018 (19%)\n        3\n2,736 (12%)\n3,250 (12%)\n        4\n1,071 (4.7%)\n2,862 (11%)\n        5\n2,418 (11%)\n5,569 (21%)\n        6\n704 (3.1%)\n445 (1.7%)\n        7\n4,162 (18%)\n1,158 (4.4%)\n        8\n2,495 (11%)\n966 (3.6%)\n        9\n1,732 (7.5%)\n2,933 (11%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n15.7.2 Bruke kataloger for kodeverk\nNoen ganger har slike lange lister med unike koder en standard gruppering som ikke er hierarkisk, eller man ønsker å lage en annen type gruppering av andre grunner. Et slikt eksempel er gruppering av yrker etter klasseskjemaer, slik som f.eks. ORDC class schema utviklet av HISTCLASS-prosjektet. Dette er et kodeskjemae for isco-koder til klasser og en katalog er tilgjengelig fra prosjektets hjemmeside. Det er omtrent 800 unike verdier og de er lagret i et Excel-format med gruppering for hver kode. De første linjene i arket ser ut som følgende:\n\nDette Excel-arket er også lagt til rette for omkoding med bruk av Stata, men du kan se bort fra de siste kolonnene.\nFilen kan leses inn med read_excel(), der første linje typisk leses inn som variabelnavn. Men i dette tilfellet skal ikke de første linjene brukes og flere kolonner skal heller ikke brukes. Derfor ber vi R droppe de første linjenene, endrer variabelnavn og beholder kun isco-kodene og tilhørende ORDC-grupperingen. Variabelnavn bør ikke inkludere mellomrom, så vi legger til et argument som endrer til gyldige variabelnavn ved å bytte ut mellomrom med punktum. Vi også spesifiserer col_types = \"text\" for å unngå at tallverdier tolkes som numeriske verdier.\n\nlist.files(\"data/\")\n\n [1] \"3_codes_isco88_ordc.xlsx\" \"abu89.dta\"               \n [3] \"CODES_isco88_ordc.xlsx\"   \"dat_dict.rds\"            \n [5] \"ESS2016.dta\"              \"ESS2016.rds\"             \n [7] \"ISCO_ORDC.do\"             \"norlag.rds\"              \n [9] \"norlag_labelled.rds\"      \"norlag_panel.csv\"        \n[11] \"norlag_panel.dta\"         \"norlag_panel.Rdata\"      \n[13] \"norlag_panel.rds\"         \"norlag_panel.sas7bdat\"   \n[15] \"norlag_panel.sav\"         \"norlag_panel.xlsx\"       \n[17] \"norlag_panel2022.dta\"     \"ordc.ado\"                \n[19] \"ordc.sthlp\"               \"politics.csv\"            \n\nisco &lt;- readxl::read_excel(path = \"data/CODES_isco88_ordc.xlsx\", skip = 4, .name_repair = \"universal\", col_types = \"text\") %&gt;% \n  select(2,9) \nhead(isco)\n\n# A tibble: 6 × 2\n  ISCO.88.code ORDC_YRK\n  &lt;chr&gt;        &lt;chr&gt;   \n1 1237         1       \n2 2141         1       \n3 2310         1       \n4 2351         1       \n5 2442         1       \n6 2443         1       \n\n\nNow, we can merge the data with this catalogue. So that every record in the catalogue is merged to each record with the same code. To do this, we use left_join(), and store in a new object.\n\nisco &lt;- isco %&gt;% \n  rename(isco08 = ISCO.88.code)\n\npolit2 &lt;- left_join(polit, isco, by = \"isco08\")\n\nhead(polit2)\n\n  isco08 gndr polintr occupation ORDC_YRK\n1   3333    1       3          3     &lt;NA&gt;\n2   7122    1       2          7       10\n3   7122    1       2          7       10\n4   4221    2       4          4        8\n5   4311    1       3          4     &lt;NA&gt;\n6   6130    2       2          6       12\n\n\nWhat happened here is that the recoding happened almost automatically by adding a new column with the new variable.\nNow, you can make e.g. a cross-tabulation of social class by gender.\n\npolit2 %&gt;% \n  select(ORDC_YRK, gndr) %&gt;% \n  tbl_summary(by = gndr)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1, N = 29,2851\n      2, N = 33,9501\n    \n  \n  \n    ORDC_YRK\n\n\n        1\n448 (2.4%)\n364 (2.0%)\n        10\n5,887 (32%)\n3,222 (17%)\n        11\n3,757 (20%)\n5,563 (30%)\n        12\n1,222 (6.6%)\n1,187 (6.4%)\n        2\n1,367 (7.4%)\n1,333 (7.1%)\n        3\n30 (0.2%)\n13 (&lt;0.1%)\n        4\n561 (3.0%)\n1,251 (6.7%)\n        5\n2,000 (11%)\n2,669 (14%)\n        6\n1,681 (9.1%)\n1,850 (9.9%)\n        7\n180 (1.0%)\n267 (1.4%)\n        8\n1,129 (6.1%)\n726 (3.9%)\n        9\n134 (0.7%)\n105 (0.6%)\n        996\n84 (0.5%)\n109 (0.6%)\n        997\n5 (&lt;0.1%)\n1 (&lt;0.1%)\n        Unknown\n10,800\n15,290\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n15.7.3 Noen ganger finnes det en pakke\nSiden R støtter pakker laget av brukere rundt omkring i verden, så er det alltids en sjanse for at noen har laget noe lurt som fikser akkurat ditt problem. Du kan altså ha flaks.\nNår det gjelder omkoding av ISCO-koder til klasseskjemaer, så har noen faktisk gjort dette. Pakken {DIGCLASS} koder om til flere forskjellige klasseskjemaer ganske greit. Se gjerne nærmere på vignetten til pakken.\nDenne pakken finnes imidlertid ikke på CRAN i skrivende stund. Derimot finnes den tilgjengelig på nettet. Følgende kode installerer pakken. Hvis du får feilmelding om at du trenger {devtools}, så installer denne pakken først på vanlig måte.\n\ndevtools::install_git(\"https://code.europa.eu/digclass/digclass.git\")\n\nDenne pakken inneholder også funksjonen for å rydde opp i isco-kodene. Det er noen vanlige problemer som omkodes enkelt med repair_isco. I følgende kode sjekkes isco-kodene før funksjonen isco88_to_ordc brukes til selve omkodingen. Den har en versjon som gir tallkode og en som gir tekstverdier, som er kjekt, så da kjøres begge to.\nDenne funksjonen spytter også ut mange beskjeder i output som vi strengt tatt ikke trenger. Den melder fra om alle verdier som ikke inngår i klasseskjemaet og som derfor settes til NA. Det er fint, men tar i dette tilfellet ganske mye plass. Vet å bruke funksjonen suppressMessages({...}) og parenteser rundt hele koden slipper vi dette. Normalt skal du ikke bruke denne funksjonen da du vanligvis vil ha slike beskjeder. Her tar det bare litt mye plass.\n\nlibrary(DIGCLASS)\n\nsuppressMessages({\npolit3 &lt;- polit %&gt;% \n  mutate(isco08 = repair_isco(.$isco08), \n         orcd = isco88_to_ordc(isco08, label = FALSE), \n         orcd_lab = isco88_to_ordc(isco08, label = TRUE))\n})\n\nhead(polit3)\n\n  isco08 gndr polintr occupation orcd                     orcd_lab\n1   3333    1       3          3 &lt;NA&gt;                         &lt;NA&gt;\n2   7122    1       2          7   10        Skilled working class\n3   4221    2       4          4    8 Lower-middle class: balanced\n4   4311    1       3          4 &lt;NA&gt;                         &lt;NA&gt;\n5   6130    2       2          6   12     Primary-sector employees\n6   7212    1       2          7   10        Skilled working class\n\n\nDa kan vi lage tabellen omigjen bare for å sjekke at vi får samme svar.\n\npolit3 %&gt;% \n  select(orcd, gndr) %&gt;% \n  tbl_summary(by = gndr)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1, N = 23,0201\n      2, N = 26,4991\n    \n  \n  \n    orcd\n\n\n        1\n190 (1.6%)\n182 (1.6%)\n        10\n4,188 (36%)\n1,890 (17%)\n        11\n2,075 (18%)\n2,564 (23%)\n        12\n723 (6.2%)\n669 (6.0%)\n        13\n80 (0.7%)\n101 (0.9%)\n        2\n1,014 (8.7%)\n838 (7.5%)\n        3\n10 (&lt;0.1%)\n2 (&lt;0.1%)\n        4\n316 (2.7%)\n604 (5.4%)\n        5\n947 (8.1%)\n1,062 (9.5%)\n        6\n572 (4.9%)\n639 (5.7%)\n        7\n226 (1.9%)\n422 (3.8%)\n        8\n1,137 (9.8%)\n1,882 (17%)\n        9\n167 (1.4%)\n333 (3.0%)\n        Unknown\n11,375\n15,311\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n```"
  },
  {
    "objectID": "omkode_factor.html#gjøre-samme-ting-med-mange-variable-med-across",
    "href": "omkode_factor.html#gjøre-samme-ting-med-mange-variable-med-across",
    "title": "15  Omkoding av variable",
    "section": "15.8 Gjøre samme ting med mange variable med across()",
    "text": "15.8 Gjøre samme ting med mange variable med across()"
  },
  {
    "objectID": "omkode_factor.html#footnotes",
    "href": "omkode_factor.html#footnotes",
    "title": "15  Omkoding av variable",
    "section": "",
    "text": "Noen ganger kalles slike variable å være på “ordinalnivå”↩︎"
  },
  {
    "objectID": "appendix_addins.html#styler---skriv-pent",
    "href": "appendix_addins.html#styler---skriv-pent",
    "title": "Appendix A — Rstudio addins",
    "section": "A.1 Styler - skriv pent",
    "text": "A.1 Styler - skriv pent\nI R spiller det ingen rolle hvordan du skriver kode: linjeskift, innrykk og mellomrom etter parentes osv gir det samme resultatet. (Komma og parenteser er derimot viktig!). Men det er ikke likegyldig for lesbarheten. {styler} kan brukes til å bedre lesbarheten av egen kode. Denne addin’en er laget av de samme som lager tidyverse, og er derfor utmerket verktøy for å skrive bedre kode. “Bedre” er da her i betydningen ryddig og ordentlig, noe som gjør den lettere å lese, de-bugge og at andre forstår koden din.\nDu kan se nærmere på vignetten til Styler"
  },
  {
    "objectID": "appendix_addins.html#esquisse---grafikk",
    "href": "appendix_addins.html#esquisse---grafikk",
    "title": "Appendix A — Rstudio addins",
    "section": "A.2 Esquisse - grafikk",
    "text": "A.2 Esquisse - grafikk\nEsquisse kan brukes til å lage grafikk med “drag-and-drop”. Noen synes det er lettere i begynnelsen. Men det viktigste med å bruke slike verktøy er at du etterpå kan vise koden slik den lages med ggplot.\nDu kan se nærmere på vignetten til Esquisse."
  },
  {
    "objectID": "appendix_addins.html#questionr---omkode-factor",
    "href": "appendix_addins.html#questionr---omkode-factor",
    "title": "Appendix A — Rstudio addins",
    "section": "A.3 Questionr - omkode factor",
    "text": "A.3 Questionr - omkode factor\nÅ omkode factor-variable kan være litt styr. Det er en egen addin for dette formålet.\nOBS! Questionr generer kode i base-R. Det er altså ikke helt den samme dialekten som ellers er dekket her. Men det er likheter, så det kan være til hjelp likevel. Dessuten funker det, jo.\nDu kan se nærmere på vignetten til questionr."
  },
  {
    "objectID": "import_metadata.html#håndtering-av-user-nas",
    "href": "import_metadata.html#håndtering-av-user-nas",
    "title": "Appendix B — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "B.1 Håndtering av user-NAs",
    "text": "B.1 Håndtering av user-NAs\nFor disse dataene vil det være ulike sett av missing-verdier for de ulike variablene. Dette kan helt fint håndteres manuelt variabel for variabel. Men for å ha ordentlig kontroll på at det blir riktig bør det automatiseres. Logikken i denne delen går et stykke utover hva vi forventer at den jevne sosiologistudent skal lære.\nEn første sted er å lese inn dokumentasjonsrapporten fra en html-fil slik den leveres fra Sikt og gjør det om til et håndterbart oppslags-datasett. Dette er beskrevet i eget appendix. Det følgende tar utgangspunkt i at en slik oppslagsfil finnes.\nDet er noen verdier som i dokumentasjonen er spesifisert som spesielle typer missing. Disse skal vi kode om til NA. Disse verdiene har labler som starter med “filter:” eller “vil ikke svare” etc. Disse danner basis for omkoding til NA. Dette er ikke en komplett liste over koder som innebærer at det egentlig mangler informasjon. (Dvs. fordi koden indikerer grunner til at det mangler informasjon). Etter denne oppryddingen kan det altså fremdeles hende at det dukker opp noe slikt, så vær påpasselig med å sjekke variabelens fordeling før du analyserer med regresjonsmodeller.\nFunksjonen nedenfor skal brukes innenfor et steg der man går gjennom alle variablene en om gangen. For hver variabel slås det opp de aktuelle missing-verdiene som gjelder for denne og bruker replace til å omkode til NA for disse verdiene. Når denne funksjonen kalles for hver variabel senere, så brukes det altså ulike definisjoner av missing-verdier for hver variabel.^(Basert på kode fra https://tim-tiefenbach.de/post/2023-recode-columns/ )\n\n# leser inn kodeliste/dokumentasjon\ndat_dict &lt;- readRDS(\"data/dat_dict.rds\")\n\n# velger kun missing-lablene\ndat_dict_na &lt;- dat_dict %&gt;% \n  filter(  str_sub(tolower(label), 1, 7) == \"filter:\" | \n           str_sub(tolower(label), 1, 10) == \"filterfeil\" |\n           str_sub(tolower(label), 1, 12) == \"ikke besvart\" |\n           str_sub(tolower(label), 1, 9) %in% c(\"filter t2\", \"filter t1\", \"filter t3\") |\n           tolower(label) %in% c(\"vil ikke svare\",\n                                 \"deltok ikke i runden\",\n                                 \"mangler data\", \"manglende data\", \n                                 \"mangler verdi\", \"ubesvart spørsmål\", \n                                 \"ugyldig verdi\", \"oppgitt verdi ikke et årstall\",\n                                 \"filter -\",\n                                 \"ikke svart post/web skjema\")) \n\n# Funksjon for å recode som har gitte user-NA.\n# (Må brukes innenfor `across()` nedenfor)\nrecode_col_na &lt;- function(x, dict) {\n  recode_vec &lt;- dict %&gt;%\n    filter(col_nm == cur_column()) %&gt;%\n    mutate(value = as.numeric(value)) %&gt;% \n    pull(value)\n  replace(x, x %in% recode_vec, NA)\n}"
  },
  {
    "objectID": "import_metadata.html#innlesning-av-data",
    "href": "import_metadata.html#innlesning-av-data",
    "title": "Appendix B — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "B.2 innlesning av data",
    "text": "B.2 innlesning av data\n\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(labelled)\n\n\n# data\nfaste &lt;- read_stata( paste0(infilbane, \"NorLAG-lengde-faste.dta\"), encoding = \"utf-8\")\n\nlang &lt;- read_stata( paste0(infilbane, \"NorLAG-lengde-intervju.dta\"), encoding = \"utf-8\")\n\n\n\nnorlag_lbl &lt;- merge(faste, lang, by = c(\"ref_nr\"), all.y = TRUE) %&gt;% \n  filter(iodeltakelse == 1 |  \n           iodeltakelse == 2 & round %in% c(1, 3) | \n           iodeltakelse == 3 & round %in% c(2, 3) |\n           iodeltakelse == 4 & round %in% c(1) |\n           iodeltakelse == 5 & round %in% c(1, 2) |\n           iodeltakelse == 6 & round %in% c(2)\n  ) \n\n\n\n# vektorer av variable som skal omkodes\ncols_vec_all &lt;- unique(dat_dict$col_nm)\nvars &lt;- unique(names(norlag_lbl))\ncols_vec &lt;- cols_vec_all[cols_vec_all %in% vars]\ncols_vec_na &lt;- cols_vec[(cols_vec %in% unique(dat_dict_na$col_nm))]\n\nnorlag &lt;- norlag_lbl %&gt;% \n  mutate(across(all_of(cols_vec_na), \n              \\(x,dic) recode_col_na(x, .env$dat_dict_na))) %&gt;% \n  mutate(across(where(is.labelled), ~as_factor(.))) %&gt;% \n  mutate(across(where(is.factor), ~fct_drop(.)))\n\nI tilegg skal vi lage en variabel for det vi kan kalle hovedaktivitet som sysselsettingsstatus. Det er om man er yrkesaktiv, arbeidsledig, student eller annet. I hver runde av NorLAG ble svarkategoriene utformet litt forskjellig, så derfor er svarene fordelt over tre variable. Nedenfor samles disse sammen og kodes om basert på tekststrenger.\n\n## Omkoder hovedaktivitet \nfs &lt;- lvls_union( list(norlag$wr001, norlag$wr002, norlag$wr003c)) %&gt;% tolower() %&gt;% unique()\n\nnorlag &lt;- norlag %&gt;% \n  mutate(across(wr001:wr003c, ~factor(tolower(.), levels=fs))) %&gt;% \n  mutate(hovedaktivitet = case_when(round == 1 ~ wr001, \n                                    round == 2 ~ wr002, \n                                    round == 3 ~ wr003c) ) %&gt;% \n  mutate(hovedaktivitet2 = case_when( str_sub(hovedaktivitet, 1, 5) == \"yrkes\" ~ \"Yrkesaktiv\", \n                                      str_detect(hovedaktivitet, \"arbeidsledig\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_detect(hovedaktivitet, \"student\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_detect(hovedaktivitet, \"trygd\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_detect(hovedaktivitet, \"annet\") ~ \"Trygdet/arbeidsledig/stud/annet\", \n                                      str_sub(hovedaktivitet,1,6)   == \"hjemme\" ~ \"hjemmeværende/husmor\", \n                                      str_detect(hovedaktivitet, \"pensjonist\") ~ \"pensjonist\", \n                                      is.na(hovedaktivitet) ~ \"Trygdet/arbeidsledig/stud/annet\") %&gt;% as_factor())\n\nOg dermed har vi et datasett i et svært så ryddig R-format."
  },
  {
    "objectID": "import_metadata.html#hvordan-fungerer-koden-ovenfor-en-intro-til-mer-avansert-databehandling",
    "href": "import_metadata.html#hvordan-fungerer-koden-ovenfor-en-intro-til-mer-avansert-databehandling",
    "title": "Appendix B — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "B.3 Hvordan fungerer koden ovenfor?? En intro til mer avansert databehandling",
    "text": "B.3 Hvordan fungerer koden ovenfor?? En intro til mer avansert databehandling\n\nB.3.1 Sjekk datastruktur og bruk av filter\n\n\nB.3.2 Omkode bruker-spesifiserte missing-verdier til NA\n\n\nB.3.3 Kode om på tvers av mange variable med across\n\n\nB.3.4 Fjerne nivåer som ikke brukes: drop_unused_value_labels\n\n\nB.3.5 Gjør om til factor med unlabelled"
  },
  {
    "objectID": "import_metadata.html#for-spesielt-interesserte-jobbe-med-labelled-data",
    "href": "import_metadata.html#for-spesielt-interesserte-jobbe-med-labelled-data",
    "title": "Appendix B — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "B.4 For spesielt interesserte: jobbe med labelled-data",
    "text": "B.4 For spesielt interesserte: jobbe med labelled-data"
  },
  {
    "objectID": "import_metadata.html#footnotes",
    "href": "import_metadata.html#footnotes",
    "title": "Appendix B — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "",
    "text": "Det kan sies mye om å levere ut data på denne måten, men det vil ikke ta seg ut å gjøre det i undervisningsmateriale.↩︎"
  },
  {
    "objectID": "createDictionary.html#lese-inn-html-dokumentasjonen",
    "href": "createDictionary.html#lese-inn-html-dokumentasjonen",
    "title": "Appendix C — Lage dictionary-fil",
    "section": "C.1 Lese inn html-dokumentasjonen",
    "text": "C.1 Lese inn html-dokumentasjonen\nFørste sted er å lese inn html-filen. Funksjonen read_html() gjør dette. For å skjønne litt mer av hvordan dette ser ut kan du åpne den opprinnelige html-filen i ren tekst, f.eks. med bruk av Notepad. Det er dette som leses inn. Jeg legger det i et nytt objekt som jeg har kalt cb (forkortelse for codebook).\n\n#library(XML)\n\n# read html file\nu &lt;- \"C:/Users/torbskar/OneDrive - Universitetet i Oslo/Dokumenter/Undervisning/SOS4020_forkurs/data2023/data_tilDeling/Kodebok.html\"\n\ncb &lt;- read_html(u)\n\nFor NorLAG er dokumentasjonsdokumentet inndelt i flere deler, og det er bare den siste delen som inneholder kodeskjemaene. Det er denne siste delen vi trenger, så første utfordring er å plukke ut denne delen.\nEn html-fil er strukturert innenfor “noder” som har en start og en slutt. Et avsnitt starter med en kode &lt;a&gt; og avsluttes med &lt;/a&gt;. Tilsvarende koder finnes for tabeller og andre elementer. Disse delene har er oftest gitt et navn som man kan identififiseres og brukes til lage lenker til spesifikke deler av siden (jf. innholdsfortegnelsen). Vi bruker denne til å filtrere filen.\nI akkurat denne filen trenger vi informasjonen som ligger etter overskriften “Variables Description”. For å finne navnet på dette avsnittet kan man undersøke lenken i innholdsfortegnelsen der det fremkommer som #variables. Eller man kan åpne html-filen i et tekstdokument og søke opp tittelen, så finner man koden name='variables innenfor det avsnittet.\nVi bruker html_nodes til å trekke ut bare dette avsnittet som følger.\n\n# Find the specific heading\nvariables &lt;- cb %&gt;% \n  html_nodes(\"a[name='variables']\")\n\nI denne dokumentasjonen er hver variabel lagret i en egen tabell. I html-kode angis begynnelsen av en tabell med &lt;table&gt; og denne brukes til å trekke ut bare tabellene.\n\ntables &lt;- variables %&gt;% \n    #html_node(xpath = \"//a[@name='variables']\") %&gt;% \n    html_nodes(xpath = \"./following::table\")\n\nSå kan vi bruke funksjonen html_table til å trekke ut hver enkelt tabell i en struktur som er lettere å jobbe med, nemlig en “data.frame”, altså en rektangulær struktur med rader og kolonner slik datasett vanligvis ser ut. Hver tabell blir et eget data.frame-objekt, og når man legger dette i et nytt objekt blir det av typen “list”. En “list” er en samling objekter som har hver sin plass i det samme objektet. (Du kan tenke på det som en eske med flere mindre ekster oppi). Vi kommer tilbake til hvordan de slås sammen.\n\ntable_data &lt;- html_table(tables)\n\n\nC.1.1 Legge det hele i en funksjon\n\n# Check if the heading exists\nif (length(variables) &gt; 0) {\n  # Find the tables after the heading\n  tables &lt;- variables %&gt;% \n    html_node(xpath = \"//a[@name='variables']\") %&gt;% \n    html_nodes(xpath = \"./following::table\")\n  \n  # Extract the table data\n  table_data &lt;- html_table(tables)\n  } else {\n  cat(\"The specified heading was not found.\")\n}\n\n\ntbslist &lt;- list()\nfor(i in 1:length(table_data)){ \n  if(\"X2\" %in% names(table_data[[i]]) & \n     \"X3\" %in% names(table_data[[i]]) & \n     !(\"X4\" %in% names(table_data[[i]])) ){\n    \n    tbslist[[i]] &lt;- table_data[[i]] %&gt;% \n      mutate(col_nm = strsplit(as.character(.[1,1]), split = \":\")[[1]][1],\n             spm = strsplit(as.character(.[1,1]), split = \":\")[[1]][2]) %&gt;% \n      rename( value = X2, \n              label = X3) %&gt;%\n      filter( str_detect(X1, \"Values and categories\")) %&gt;% \n      filter( !is.na(value)) %&gt;% \n      select(-X1)\n  }\n  else{\n    if(i==1){\n      teller &lt;- 0\n      }\n    teller &lt;- teller + 1 \n  }\n  if(i == length(table_data)){\n    print(paste(\"Antall variable som ikke har omkodinger: \", teller)) \n  }\n}\n\n[1] \"Antall variable som ikke har omkodinger:  1\"\n\ndat_dict &lt;- bind_rows(tbslist) %&gt;% \n  select(col_nm, value, label, spm)\n\n\nsaveRDS(dat_dict, \"data/dat_dict.rds\")"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Berk, Richard. 2016. Statistical Learning from a Regression\nPerspective. USA: Springer.\n\n\nBerk, Richard A. 2010. “What You Can and Can’t Properly Do with\nRegression.” Journal of Quantitative Criminology 26:\n481–87. https://doi.org/https://doi.org/10.1007/s10940-010-9116-4.\n\n\nMoore, David S., Notz William I, and Michael Fligner. 2021. The\nBasic Practice of Statistics. W.H.Freeman & Co Ltd."
  }
]