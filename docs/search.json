[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Forkurs for kvantitativ metode",
    "section": "",
    "text": "Forord\nDette materialet er beregnet på et forkurs for masterstudenter i sosiologi ved universitet i Oslo som skal ta emnet SOS4020 Kvantitative metoder. Forkurset dekker de mest sentrale elementene fra BA-nivået som trengs for å ta SOS4020.\nDet anbefales å repetere materiale fra kurs i kvantitative metoder på bachelornivå. Forkurset er en oppfrisker av det aller viktigste materialet fra SOSGEO1120.\nDe som lært annen statistikksoftware enn R på bachelornivå vil ha særlig nytte av dette kurset. I tillegg til programmeringsspråket skal du lære å lage en hensiktsmessig mappestruktur og lese inn datasett i R.\nVi skal jobbe med datasettet som skal brukes i SOS4020. Dette datasettet er tilgangsbegrenset så det er litt formaliteter som må på plass først.\nLæringsmålene for forkurset er som følger:\n\nBli kjent med R og Rstudio, mappestruktur og jobbe med Rstudio projects\nKunne lese inn data i vanlige formater\nHa lest inn og bli kjent med datasettet som skal brukes videre i SOS4020\nKunne lage grunnleggende grafikk med ggplot\nKunne lage deskriptive tabeller med gtsummary (og litt andre funksjoner)\nKunne lage 3-veis krysstabeller\nKunne lage grafisk fremstilling av sammenheng mellom inntil 4 variable\nKunne beskrive sammenhengen mellom variable med lineær regresjon\nKjenne grunnleggende sammenhengen mellom hvordan dataene ble til og hvordan analysene kan tolkes\nKjenne til hva en samplingfordeling er og kunne tolke standardfeil, konfidensintervall og p-verdier\nKunne gjennomføre en t-test for gjennomsnitt og for regresjonsparametre\nKunne grunnleggende datahåndtering med tidyverse for å kunne gjøre selvstendige analyser senere\nKunne eksportere alle resultater fra R til Word på en effektiv måte"
  },
  {
    "objectID": "Installering.html#installasjon",
    "href": "Installering.html#installasjon",
    "title": "1  Installere R og Rstudio",
    "section": "1.1 Installasjon",
    "text": "1.1 Installasjon\nInstaller nyeste versjon av R herfra: https://cran.uib.no/ Du trenger det som heter «base» når man installerer for første gang. Hvis du har R installert på maskinen din fra før, sørg for at du har siste versjon installert. Siste versjon er 4.1.2. Versjon etter 4.0 bør gå bra, men tidligere versjoner vil kunne gi problemer. Installer nyeste versjon av RStudio (gratisversjon) herfra: https://rstudio.com/products/rstudio/download/ Viktig: du må installere R før du installerer Rstudio for Rstudio finner R på din datamaskin og vil gi feilmelding hvis den ikke finner R. Hvis du har en eldre datamaskin og du får feilmelding ved installasjon av RStudio kan du vurdere å installere forrige versjon av Rstudio herfra: https://www.rstudio.com/products/rstudio/older-versions/\nR og Rstudio er to programmer er integrert i hverandre og du åpner heretter R ved å åpne RStudio. Merk: R er navnet på programmeringsspråket og programmet som gjør selve utregningene. Det kjører fra en kommandolinje og er ikke veldig brukervennlig alene. RStudio er et “integrated development environment” (IDE) til R. Det integrerer R med en konsoll, grafikk-vindu og en del andre nyttige ting. Det gjør det lettere å bruke R.\nDet finnes også andre IDE for R, men vi skal bruke RStudio gjennomgående på dette kurset. (RStudio inneholder også masse annen funksjonalitet vi ikke trenger til dette kurset).\n\n1.1.1 Spesielt om Windows-maskiner: installer Rtools\nHvis du jobber på en Windows-maskin må du også installere Rtools herfra: https://cran.r-project.org/bin/windows/Rtools/\n\n\n1.1.2 Spesielt om Mac-maskiner\nR skal normalt installere på Mac uten problemer. Noen har fått beskjed om at de også trenger å installere XQuartz eller Xcode. I så fall installerer du de også. Se mer informasjon her: https://cran.r-project.org/bin/macosx/tools/\n\n\n1.1.3 Spesielt om Linux-maskiner\nHar du Linux vet du antakelig hva du driver med. Siste versjon av R og Rstudio kan antakeligvis installeres fra distroens repository.\n\n\n1.1.4 Spesielt om Chromebook\nChromebook kjører et annet operativsystem og R vil ikke uten videre fungere. Derimot kan man på de fleste slike maskiner åpne opp for å kjøre Linux og da kan man installere linux-versjon av R og Rstudio. https://blog.sellorm.com/2018/12/20/installing-r-and-rstudio-on-a-chromebook/ Eller se nedenfor hvordan du kan kjøre R i skyen."
  },
  {
    "objectID": "Installering.html#oppsett-og-forberedelser",
    "href": "Installering.html#oppsett-og-forberedelser",
    "title": "1  Installere R og Rstudio",
    "section": "1.2 Oppsett og forberedelser",
    "text": "1.2 Oppsett og forberedelser\nDette oppsettet gjelder både hvis du har en lokal installasjon og for skyløsninger. Utseendet spiller ingen rolle, og R kan også fungere uten å opprette «projects» som beskrevet her. Men det er lettere å bruke og du har bedre orden hvis du gjør dette.\n\n1.2.1 Utseende i Rstudio\nEndre gjerne på oppsettet i RStudio ved å gå til Tools og deretter Global options, så Pane Layout.\n\nDet spiller ingen rolle for funksjonaliteten hvor du har hvilken fane, men her er et forslag.\n\nDette kan også endres senere og har altså bare med hvordan Rstudio ser ut."
  },
  {
    "objectID": "Installering.html#rstudio-projects",
    "href": "Installering.html#rstudio-projects",
    "title": "1  Installere R og Rstudio",
    "section": "1.3 Rstudio projects",
    "text": "1.3 Rstudio projects\nNår du åpner Rstudio skal du alltid åpne som «project» (se video med instruksjon og i R4DS). Arbeidsområdet er da definert og du kan åpne data ved å bruke relative filbaner, dvs. at du oppgir hvor dataene ligger med utgangspunkt i prosjektmappen. Se kursvideo og instruksjoner i R4DS og gjør følgende:\nOpprettet mappestruktur med SOSGEO1120 som øverste nivå og egne undermapper for data, script, og output."
  },
  {
    "objectID": "Installering.html#åpne-rstudio-og-opprett-et-.rproject",
    "href": "Installering.html#åpne-rstudio-og-opprett-et-.rproject",
    "title": "1  Installere R og Rstudio",
    "section": "1.4 Åpne RStudio og opprett et .Rproject",
    "text": "1.4 Åpne RStudio og opprett et .Rproject\n\nBruk kommandoen getwd() og se at du har riktig filbane til arbeidsområdet. Hvis du ikke er sikker på hva det betyr, må du spørre noen eller finne det ut på annen måte!\nDet første dere må gjøre er å sørge for å ha orden i datasett, script og annet på din egen datamaskin. Å f.eks. lagre alle filer på skrivebordet bør du aldri gjøre, og særlig ikke i dette kurset eller når man jobber med større prosjekter og datasett. For dette kurset skal du ha en mappestruktur med en hovedmappe for SOSGEO1120 og tilhørende undermapper. Det spiller ingen rolle hvor på datamaskinen du legger disse mappene, men du må vite hvor det er. Lag første en mappe som heter SOSGEO1120, og innunder denne mappen lager du tre andre mapper med navnene data, output og script. Du kan ha andre mapper i tillegg ved behov. Det kan se slik ut:\n\nDu skal opprette et Rstudio-prosjekt for hele kurset. Dette er beskrevet nærmere i R4DS i kapittel 6. Når du har åpnet RStudio skal du aller først klikke New Project.\n\nDeretter klikker du du «Existing Directory»\n\nKlikk «Browse» og bla deg så frem til mappen du har laget for SOSGEO1120.\nRStudio-prosjektet ligger så i den mappen du har valgt. I filutforsker på datamaskinen vil nå disse to filene dukke opp:\n\nFor å starte R videre i dette kurset skal du dobbeltklikke det første ikonet, så vil R åpne seg med riktig arbeidsområde. Mappen .Rproj.user skal du ikke røre. I RStudio vil du se at prosjektet er åpnet ved at det i øvre høyre hjørne er dette ikonet:\n\nEn stor fordel med å bruke projects er at du kan flytte hele mappen til et annet sted, eller til en annen datamaskin og alt vil fungere akkurat som før. Hvis du bruker en skytjeneste (OneDrive, Dropbox etc) vil du kunne åpne Rstudio projects på samme måte fra flere maskiner."
  },
  {
    "objectID": "innlesning_data.html#generelt-om-ulike-dataformat",
    "href": "innlesning_data.html#generelt-om-ulike-dataformat",
    "title": "2  Innlesning av data",
    "section": "2.1 Generelt om ulike dataformat",
    "text": "2.1 Generelt om ulike dataformat\n\n2.1.1 rds\nRds-formatet er et format særlig egnet for R.\n\n\n2.1.2 Laste workspace med load()\nFiler av typen .Rdat eller .Rdata er egentlig ikke et dataformat, men brukes tidvis for å lagre datafiler. Man kan lagre en eller flere datafiler i samme .Rdat fil på disk.\nDu kan også lagre et “speilbilde” av hele ditt workspace på denne måten slik at du kan lukke R og så åpne R senere akkurat på det stedet du var i arbeidet. Det kan være kjekt, men forutsetter at du husker hva du drev med forrige gang. Den klare anbefalingen er derfor å ikke bruke dette rutinemessig.\n\n\n2.1.3 csv-filer\nSåkalte csv-format er ren tekstformat der verdiene i kollonnene har skilletegn. Skilletegnet er nesten alltid komma eller semikolon, men kan i prinsippet være hva som helst. Noen ganger vil slike\n\n\n2.1.4 Excel\nForbløffende mye data foreligger i Excel-format. Det finnes egne funksjoner for å jobbe direkte med excel-filer. Blant annet pakken readxl gir funksjoner til å lese inn denne typen filer. Her er et eksempel.\n\nlibrary(readxl)\nnorlag_xlsx <- read_excel(\"data/norlag_panel.xlsx\")\nglimpse(norlag_xlsx)\n\nRows: 20,892\nColumns: 12\n$ ref_nr  <dbl> 5, 5, 10, 10, 10, 12, 12, 15, 15, 18, 18, 22, 23, 23, 25, 27, …\n$ round   <dbl> 1, 2, 3, 2, 1, 3, 1, 1, 2, 3, 2, 1, 3, 1, 1, 3, 2, 1, 2, 1, 3,…\n$ ioalder <chr> \"68\", \"72\", \"59\", \"49\", \"44\", \"61\", \"47\", \"58\", \"63\", \"67\", \"5…\n$ iolandb <chr> NA, \"Norskfødt\", NA, \"Norskfødt\", NA, NA, NA, NA, \"Norskfødt\",…\n$ iokjonn <chr> \"Mann\", \"Mann\", \"Kvinne\", \"Kvinne\", \"Kvinne\", \"Kvinne\", \"Kvinn…\n$ pa001c  <chr> \"Ja\", \"Ja\", \"Ja\", \"Ja\", \"Nei\", \"Ja\", \"Ja\", \"Nei\", \"Nei\", \"Ja\",…\n$ pa300   <chr> \"Partner gjør mest\", NA, NA, NA, NA, NA, \"IO gjør mest\", NA, N…\n$ hc230   <chr> \"En gang i uken\", \"En gang i uken\", \"2-3 ganger i måneden\", \"E…\n$ hc231   <chr> \"2-3 ganger i måneden\", \"2-3 ganger i måneden\", NA, \"2-3 gange…\n$ va207   <chr> \"Ganske viktig\", \"Litt viktig\", \"Litt viktig\", \"Ikke viktig\", …\n$ hcMCS12 <chr> \"59.7766\", \"60.68044\", \"58.74768\", \"60.69717\", \"55.86777\", \"53…\n$ hcPCS12 <chr> \"54.83583\", \"51.03453\", \"55.92348\", \"55.25834\", \"55.91285\", \"5…\n\n\nMen Excel-filer kan ha en litt mer komplisert struktur enn dette eksempelet. Data kan ligge i ulike faner i Excel-filen, men det kan da håndteres med å legge til argumentet sheet = .... Hvis excel-arket inneholder mye tekst eller andre ting som gjør at de faktiske dataene kommer litt lengre ned, så kan det spesifiseres hvilket celleområde som det skal leses inn fra ved range = ... eller bare hoppe over noen rader med skip = ....\nPå dette kurset skal vi ikke bruke Excel-filer, men det er stor sannsynlighet for at du vil få bruk for dette senere en gang.\n\n\n2.1.5 Proprietære format: Stata, SPSS og SAS\n\n2.1.5.1 Stata\n\nnorlag_dta <- read_stata(\"data/norlag_panel.dta\")\nglimpse(norlag_dta)\n\nRows: 20,892\nColumns: 12\n$ ref_nr  <dbl> 5, 5, 10, 10, 10, 12, 12, 15, 15, 18, 18, 22, 23, 23, 25, 27, …\n$ round   <dbl> 1, 2, 3, 2, 1, 3, 1, 1, 2, 3, 2, 1, 3, 1, 1, 3, 2, 1, 2, 1, 3,…\n$ ioalder <dbl+lbl> 29, 33, 20, 10,  5, 22,  8, 19, 24, 28, 18, 24, 30, 16, 32…\n$ iolandb <dbl+lbl> NA,  1, NA,  1, NA, NA, NA, NA,  1, NA,  1, NA, NA, NA, NA…\n$ iokjonn <dbl+lbl> 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2…\n$ pa001c  <dbl+lbl> 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1…\n$ pa300   <dbl+lbl>  1, NA, NA, NA, NA, NA,  2, NA, NA, NA, NA,  3, NA, NA, NA…\n$ hc230   <dbl+lbl>  3,  3,  4,  3,  3, NA, NA,  1,  1, NA, NA,  1, NA,  3,  4…\n$ hc231   <dbl+lbl>  4,  4, NA,  4,  3, NA, NA,  2,  1, NA, NA,  2, NA,  4,  5…\n$ va207   <dbl+lbl>  2,  3,  3,  4,  3, NA, NA,  3,  4, NA, NA,  1, NA,  3,  3…\n$ hcMCS12 <dbl+lbl> 6350, 6647, 5994, 6650, 4891, 4121, 6672, 4736, 3529, 4632…\n$ hcPCS12 <dbl+lbl> 7085, 6420, 7258, 7149, 7255, 7544, 7355, 6956, 7368, 7342…\n\n\nLegg merke til at den andre kolonnen her viser hva slags variabeltype det er. <dbl> betyr at det er numerisk variabel^(Det finnes flere typer numeriske variable som vi for praktiske analyser sjelden behøver å forholde oss til. <dbl> står for Double som er et lagringsformat som kan ta svært mange desimaler. Det kan også stå <num> som håndterer færre desimaler. Det er også vanlig med <int> som står for Integer, altså heltall uten desimaler.) På noen variable står det også <dbl+lbl> der lbl står for labelled som betyr at det finnes såkalte labler tilhørende variabelen. Labler er vanlig å bruke i programmene Stata og SPSS, men er ikke noe som vanligvis brukes i R. Men R leser det inn og kan håndtere dette helt fint. Men som hovedregel er det bedre å rydde opp slik at dataene blir slik vi vanligvis bruker det i R. Dette er grunnen til at dere får en bearbeidet versjon av NorLAG datasettet!\nNeste kapittel er spesielt om NorLAG i formatet .rds. Hvordan effektivt lese inn fra Stata til R og gjøre om labler er dekket i et appendiks. De av dere som senere skal jobbe med data levert ut fra Sikt kan ha behov for dette, og da kan dere ta en nærmere titt på appedikset. For dette forkurset og SOS4020 vil dere ikke trenge kunne akkurat det.\n\n\n2.1.5.2 SPSS og SAS\nAndre vanlige dataformater er formater fra statistikkpakkene SPSS og SAS, med filhalene henholdsvis .sav og .sas7bdat. De leses inn på tilsvarende funksjoner tilpasset disse dataformatene. Her er eksempel for innlesning av SPSS-fil:\n\nnorlag_sav <- read_spss(\"data/norlag_panel.sav\")\n\nHer er eksempel for innlesning av SAS-fil:\n\nnorlag_sas <- read_sas(\"data/norlag_panel.sas7bdat\")\n\n\n\n\n2.1.6 Dataformater for store data\nDet finnes en hel rekke andre formater for spesielle formål, derav formater for store data. Med store data mener vi her enten at de er så store at det upraktisk lang tid å lese det inn - eller så store at det ikke er plass i minnet på datamaskinen. Formatene feather og parquet er varianter av det samme og håndteres med pakken Arrow. Det finnes også andre pakker for store data, men Arrow er nå den anbefalte. En annen grunn til det er at disse datasettene tillater sømløs bytte mellom programmeringsspråkene R og Python. Men det går laaaagt utenfor formålet med dette forkurset.\nFor mer spesielle behov går det også an å koble mot databaser som MySQL, Spark, Oracle eller noe helt annet, og en oversikt finnes her.\nEneste du trenger være klar over akkurat nå er at R kan håndtere svært mange forskjellige dataformater og koble mot andre løsninger. Kanskje vil du trenge det en gang - kanskje ikke."
  },
  {
    "objectID": "innlesning_data.html#oppgaver",
    "href": "innlesning_data.html#oppgaver",
    "title": "2  Innlesning av data",
    "section": "2.2 Oppgaver",
    "text": "2.2 Oppgaver\n\nExercise 2.1 Les inn datasettet… i rds-format\n\n\nExercise 2.2 Les inn datasettet… i xlsx-format\n\n\nExercise 2.3 Noen ganger vil datamaskiner være konfigurert slik at filhalene ikke synes. Det betyr jo ikke at de ikke er der, men du ser ikke umiddelbart hva slags fil det er. Finn ut hvordan du endrer dette på din datamaskin. Prøv å skru det av og på. For å finne det ut, søk på internett med søkestrengen “how to display file extension” eller tilsvarende."
  },
  {
    "objectID": "norlag.html#tilgang-og-lagring",
    "href": "norlag.html#tilgang-og-lagring",
    "title": "3  Datasettet NorLAG",
    "section": "3.1 Tilgang og lagring",
    "text": "3.1 Tilgang og lagring\nNorLAG er gule data og har restriksjoner på bruk og lagring. Du er pliktet til å sette deg inn i retningslinjene som du finner på denne siden.\nI denne sammenhengen betyr det i praksis at du bør jobbe på UiO-OneDrive. Altså: ikke lagre data på din personlige datamaskin og ikke en personlig skytjeneste. Merk at det er forskjell på f.eks. OneDrive gjennom UiO og privat.\nFor å få tilgang på datasettet må du gjøre følgende:\n\nOppgi din uio-epostadresse i dette nettskjemaet. Emneansvarlig legge deg inn i systemet.\nDu får tilsendt en lenke fra Sikt med videre instruksjoner om hvordan du signerer en avtale. Les avtalen og signer digitalt.\nLast ned pdf-versjon av den signerte avtalen og behold den for senere referanse. Du kan også gjøre det senere ved å logge inn på Sikt sine sider for data access.\nLaster opp den signerte avtalen i dette skjemaet.\nEmneansvarlig vil dele en mappe med deg i Sharepoint der du kun har lesetilgang. Her ligger tilrettelagte versjoner av datasettet.1 Kopier alle filene over til en lokal mappe i din UiO-OneDrive (se ovenfor).\n\nOBS!! Dere signerer en avtale om bruk av data som er begrenset til å brukes til metodeundervisningen på master i sosiologi ved UiO. Den avtalen har også en begrensning i tid. Les avtalen nøye. Dere har et selvstendig ansvar for å overholde betingelsene, herunder at dataene skal slettes innen angitt dato. Det er fult mulig å bruke disse dataene til senere prosjekter, f.eks. til masteroppgave, men da må det søkes på nytt.2\n\n3.1.1 Innlesning av data\nDatasettet norlag.rds er altså konvertert til R-formatet rds. Når dette er gjort er du klar for både forkurset og SOS4020.\nNest økt vil omhandle innlesning av data: både rds og andre vanlige formater."
  },
  {
    "objectID": "oversikt_datasettet.html#søke-i-datasettet-etter-variable",
    "href": "oversikt_datasettet.html#søke-i-datasettet-etter-variable",
    "title": "4  Få oversikt over datasettet",
    "section": "4.1 Søke i datasettet etter variable",
    "text": "4.1 Søke i datasettet etter variable\nAlle datasett skal komme med en dokumentasjon som sier hva hver variabel inneholder og hvilke verdier som finnes i hver variable, og hva de betyr. Dette leveres gjerne som en separat fil, ganske ofte i pdf eller html format. NSD/Sikt leverer dokumentasjonen for Norlag i html-format. (Ideelt burde det vært i et enkelt maskinlesbart format egnet til å bruke til omkoding og labler for de som ønsker det, men de har valgt en annen løsning).\nDu kan søke i dokumentasjonen på samme måte som i andre filer, men det kan være litt knotete. Et godt alternativ er å søke direkte i datasettet. Funksjonen look_for() søker både i variabelnavn, verdier og labler. Her er et eksempel for hvordan finne variabler som inneholder ordet “yrkesinntekt”. Du kan også søke på kortere eller lengre tekststrenger. (Søker du f.eks. bare på “innt” eller “yrke” så får du opp langt flere variable, så du må kanskje prøve deg litt frem).\n\nlook_for(norlag, \"Yrkesinntekt\")\n\n pos variable       label                   col_type values                 \n 353 inwyrkinnt     Yrkesinntekter NorLAG ~ dbl+lbl  [-5000] Value <0 >-5000\n                                                     [5000] Value >0 <5000  \n                                                     [999999999] Mangler da~\n 371 inpartwyrkinnt Partner: yrkesinntekte~ dbl+lbl  [99999996] Filter: IO ~\n                                                     [99999999] Mangler data\n                                                     [999999999] Deltok ikk~\n\n\nDet er to variable som inneholder teksten “yrkesinntekt”. Den første variabelen har posisjon 353 i datasettet og har variabelnavnet inwyrkinnt. Den andre variabelen har posisjon 371 og har navnet inpartwyrkinnt. Vi fokuserer på den første.\nMerk at når labelen avsluttes med ~ (uttales “tilde”) indikerer det at teksten er avkortet i outputvinduet. Du får opp hele teksten ved å bruke val_label() slik:\n\nvar_label(norlag$inwyrkinnt)\n\n[1] \"Yrkesinntekter NorLAG longitudinell\""
  },
  {
    "objectID": "grafikk.html#kategoriske-variabel",
    "href": "grafikk.html#kategoriske-variabel",
    "title": "5  Grafikk med ggplot",
    "section": "5.1 Kategoriske variabel",
    "text": "5.1 Kategoriske variabel\n\n5.1.1 Stolpediagram\n\nggplot(norlag, aes(x = hc231)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n5.1.2 Kakediagram og satans verk\nGenerelt er ikke kakediagram å anbefale da korrekt tolkning involverer å tolke et areal som inneholder vinkel. Med få kategorier som er rimelig forskjellig kan det gi et ok inntrykk, men ofte ender man opp med å måtte skrive på tallene likevel.\n\npc <- norlag %>% \n  group_by(hc231) %>% \n  summarise(n = n()) %>% \n  mutate(pct = n/sum(n)*100) %>% \n  ungroup()\n\n\nggplot(pc, aes(x = \"\", y = pct, fill = (hc231))) +\n  geom_bar(stat=\"identity\", width=1) +\n  coord_polar(\"y\", start=0) +\n  theme_void()+\n  geom_text( aes(label = paste0( round(pct,1), \"%\"), x = 1.4), \n            position = position_stack(vjust=.5), check_overlap = F) +\n  labs(x = NULL, y = NULL, fill = NULL)+\n  theme(axis.line = element_blank(),\n          axis.text = element_blank(),\n          axis.ticks = element_blank()) +\n  scale_fill_brewer(palette=\"Blues\", direction = -1)"
  },
  {
    "objectID": "grafikk.html#kontinuerlige-variable",
    "href": "grafikk.html#kontinuerlige-variable",
    "title": "5  Grafikk med ggplot",
    "section": "5.2 Kontinuerlige variable",
    "text": "5.2 Kontinuerlige variable\n\n5.2.1 Histogram\n\nggplot(norlag, aes(x = hcPCS12)) +\n  geom_histogram()\n\n\n\n\nDet er også vanlig å fremstille det samme på en “tetthetsskala”, der arealet summeres til 1. Det betyr at arealet for hvert intervall tilsvarer en andel. Visuelt sett er det vel så mye arealet vi oppfatter som høyden på stolpene. Men det er bare skalaen på y-aksen som har endret seg. Visuelt sett, ser histogrammene helt like ut.\n\nggplot(norlag, aes(x = hcPCS12, y = ..density..)) +\n  geom_histogram()\n\n\n\n\n\n\n5.2.2 Density plot\nDensity plot er en måte å fremstille det samme på, men i stedet for å dele inn i intervaller som i histogram lager vi en glattet kurve. Det blir på skalaen “tetthet” som i histogrammet ovenfor.\n\nggplot(norlag, aes(x = hcPCS12)) +\n  geom_density()\n\n\n\n\n\nggplot(norlag, aes(x = hcPCS12)) +\n  geom_histogram(aes(y = ..density..), fill = \"lightgrey\", col = \"grey\") +\n  geom_density(col = \"red\", linewidth = 1) +\n  theme_minimal()\n\n\n\n\nEn fordel med denne fremstillingen er at det er lettere å sammenligne grupper. Her er et eksempel med density plot etter hvor mye man drikker.\n\nggplot(norlag, aes(x = hcPCS12, group = hc231, linetype = hc231)) +\n  geom_density(linewidth = 1)+\n  guides(fill = guide_legend(override.aes = list(shape = 1 ) ) ) +\n  theme_minimal()\n\n\n\n\n\nggplot(norlag, aes(x = hcPCS12)) +\n  geom_density(linewidth = 1)+\n  theme_minimal()+\n  facet_wrap(~hc231, scales=\"free\")\n\n\n\n\n\nggplot(norlag, aes(x = hcPCS12,  fill = iokjonn)) +\n  geom_density(alpha = .3)+\n  guides(fill=guide_legend(title=\"Kjønn\"))+\n  theme_minimal()\n\n\n\n\n\n\n5.2.3 Flere variable samtidig\n\n5.2.3.1 Boksplot\n\nggplot(norlag, aes(x = hcPCS12, group = hc231)) +\n  geom_boxplot()+\n  theme_minimal()+\n  coord_flip()\n\n\n\n\n\n\n5.2.3.2 Scatterplot\n\nglimpse(norlag)\n\nRows: 9,865\nColumns: 13\n$ ref_nr       <dbl> 5, 5, 10, 10, 15, 15, 22, 23, 25, 27, 27, 28, 28, 32, 33,…\n$ round        <dbl> 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, …\n$ iodeltakelse <fct> \"Deltatt T1 og T2\", \"Deltatt T1 og T2\", \"Deltatt T1, T2 o…\n$ ioalder      <dbl> 29, 33, 10, 5, 19, 24, 24, 16, 32, 42, 37, 32, 28, 9, 32,…\n$ iolandb      <fct> NA, Norskfødt, Norskfødt, NA, NA, Norskfødt, NA, NA, NA, …\n$ iokjonn      <fct> Mann, Mann, Kvinne, Kvinne, Kvinne, Kvinne, Mann, Mann, K…\n$ pa001c       <fct> Ja, Ja, Ja, Nei, Nei, Nei, Ja, Nei, Nei, Ja, Ja, Nei, Nei…\n$ pa300        <fct> Partner gjør mest, NA, NA, NA, NA, NA, Jevnt fordelt, NA,…\n$ hc230        <fct> En gang i uken, En gang i uken, En gang i uken, En gang i…\n$ hc231        <fct> 2-3 ganger i måneden, 2-3 ganger i måneden, 2-3 ganger i …\n$ va207        <fct> Ganske viktig, Litt viktig, Ikke viktig, Litt viktig, Lit…\n$ hcMCS12      <dbl> 6350, 6647, 6650, 4891, 4736, 3529, 2694, 6135, 5262, 678…\n$ hcPCS12      <dbl> 7085, 6420, 7149, 7255, 6956, 7368, 7331, 7187, 6283, 624…\n\nggplot(norlag, aes(x = ioalder, y = hcPCS12)) +\n  geom_point(alpha=.3)+\n  theme_minimal()\n\n\n\n\n\nggplot(norlag, aes(x = ioalder, y = hcPCS12)) +\n  geom_jitter(alpha=.1, width = .3)+\n  theme_minimal()\n\n\n\n\n\n\n5.2.3.3 Ridgeplot\nRidgeplot er en annen måte å sammenligne en kontinuerlig fordeling betinget på en gruppering.\n\nlibrary(ggridges)\nggplot( filter(norlag, !is.na(iolandb)),  aes(y = iolandb, x = hcPCS12)) +\n  geom_density_ridges()"
  },
  {
    "objectID": "grafikk.html#andre-greier",
    "href": "grafikk.html#andre-greier",
    "title": "5  Grafikk med ggplot",
    "section": "5.3 Andre greier",
    "text": "5.3 Andre greier"
  },
  {
    "objectID": "grafikk.html#grammar-of-graphics",
    "href": "grafikk.html#grammar-of-graphics",
    "title": "5  Grafikk med ggplot",
    "section": "5.4 Grammar of graphics",
    "text": "5.4 Grammar of graphics\nFunksjonen ggplot er bygget opp som en gramatikk for grafisk fremstilling. Det ligger en teori til grunn som er utledet i boken ved omtrent samme navn: The grammar of graphics. Det er mye som kan sies om dette, men det viktige er at grafikken er bygget opp rundt noen bestanddeler. Når du behersker disse kan du fremstille nær sagt hva som helst av kvantitativ informasjon grafisk.\n\nDet første argumentet i ggplot er data. Altså: hvilket datasett informasjonen hentes fra.\naes() spesifiserer aestethics, som er hva som skal plottes. Først og fremst hva som skal på x-akse og y-akse (og evt. z-akse), men også spesifikasjon av linjer (farge, linjetype) og fyllfarger, gjerne etter en angitt gruppering.\ngeom_* står for geometric og sier noe om hvordan data skal se ut. Det kan være punkter, histogram, stolper, linjer osv.\ncoord_* definerer koordinatsystemet. Stort sett blir dette bestemt av variablene. Men du kan også snu grafen eller definere sirkulært koordinatsystem, eller andre enklere ting.\nfacet_* definerer hvordan du vil dele opp grafikken i undergrupper"
  },
  {
    "objectID": "deskriptive_tabeller.html#quick-and-dirty-oppsummeringer",
    "href": "deskriptive_tabeller.html#quick-and-dirty-oppsummeringer",
    "title": "6  Deskriptive tabeller",
    "section": "6.1 Quick-and-dirty oppsummeringer",
    "text": "6.1 Quick-and-dirty oppsummeringer\n\n6.1.1 Enkeltvariable med $\n\n\n6.1.2 summary"
  },
  {
    "objectID": "deskriptive_tabeller.html#manuelle-tabeller",
    "href": "deskriptive_tabeller.html#manuelle-tabeller",
    "title": "6  Deskriptive tabeller",
    "section": "6.2 Manuelle tabeller",
    "text": "6.2 Manuelle tabeller\nNoen ganger trenger man å lage ganske spesifikke ting.\n\n6.2.1 For datasettet totalt\n\n\n6.2.2 Grupperte statistikker"
  },
  {
    "objectID": "deskriptive_tabeller.html#professjonelle-tabeller-med-gtsummary",
    "href": "deskriptive_tabeller.html#professjonelle-tabeller-med-gtsummary",
    "title": "6  Deskriptive tabeller",
    "section": "6.3 Professjonelle tabeller med gtsummary",
    "text": "6.3 Professjonelle tabeller med gtsummary"
  },
  {
    "objectID": "deskriptive_tabeller.html#noen-andre-muligheter",
    "href": "deskriptive_tabeller.html#noen-andre-muligheter",
    "title": "6  Deskriptive tabeller",
    "section": "6.4 Noen andre muligheter",
    "text": "6.4 Noen andre muligheter"
  },
  {
    "objectID": "kontrollerefor.html#simpsons-paradox",
    "href": "kontrollerefor.html#simpsons-paradox",
    "title": "7  Kontrollere for bakenforliggende variable",
    "section": "7.1 Simpson’s paradox",
    "text": "7.1 Simpson’s paradox"
  },
  {
    "objectID": "linearRegresjon.html#scatterplot",
    "href": "linearRegresjon.html#scatterplot",
    "title": "8  Regresjon: Sammenheng mellom variable",
    "section": "8.1 Scatterplot",
    "text": "8.1 Scatterplot"
  },
  {
    "objectID": "linearRegresjon.html#regresjonslinja",
    "href": "linearRegresjon.html#regresjonslinja",
    "title": "8  Regresjon: Sammenheng mellom variable",
    "section": "8.2 Regresjonslinja",
    "text": "8.2 Regresjonslinja"
  },
  {
    "objectID": "linearRegresjon.html#flere-variable",
    "href": "linearRegresjon.html#flere-variable",
    "title": "8  Regresjon: Sammenheng mellom variable",
    "section": "8.3 Flere variable",
    "text": "8.3 Flere variable"
  },
  {
    "objectID": "linearRegresjon.html#eksport-av-resultater-til-fil",
    "href": "linearRegresjon.html#eksport-av-resultater-til-fil",
    "title": "8  Regresjon: Sammenheng mellom variable",
    "section": "8.4 Eksport av resultater til fil",
    "text": "8.4 Eksport av resultater til fil\nVi vil som regel ha behov for å flytte resultatene over til et tekstbehandlingsprogram. En strategi som går ut på “klipp og lim” eller skjermbilde etc er uaktuelt og unngå det for nærmest enhver pris.1 Resultatene skal skrives til en fil på en effektiv måte. Det er en fordel om tabellene da ser ganske ok ut i utgangspunktet og du kan bruke samme prosedyre for å eksportere til flere typer format hvis behovet skulle melde seg. Det er jo MS Word som er viktigst for dere, mens de øvrige formatene nedenfor er for spesielt interessert - men noen av dere vil kanskje bli det på et senere tidspunkt.\nHer presenteres noen pakker som eksporterer til de viktigste formatene som er:\n\nMS Word - det vanligste tekstbehandlingsprogrammet som de aller fleste av dere bruker.\n\nrtf - rikt tekstformat. Er et enklere format som fungerer på tvers av de fleste programmer. Kan brukes i Word også.\nhtml - for websider\nlatex - for mer tekniske dokumenter, særlig hvis du har mye formler og stæsj\nMarkdown - for dynamiske dokumenter med integrert R-kode og tekst, og kan eksportere ferdig dokument til alle ovennevnte formater2 Det som fungerer med Markdown fungerer også med Quarto for samme formål.\n\n\n8.4.1 Alt 1: Bruke modelsummary()\nEksporterer til bl.a. følgende formater: Word, rtf, html, latex, markdown\nFordel: Kan lett integreres med andre funksjoner, først og fremst “grammar of tables” i pakket gt Ulempe:\n\n\n8.4.2 Alt 2: Bruke stargazer()\nEksporterer til bl.a. følgende formater: rtf, html, latex, markdown\nFordel: Er en stand-alone pakke men gir enkelt veldig fine tabeller som antakeligvis er det du trenger Ulempe: Eksport til Word er ikke den beste, men god nok.\n\n\n8.4.3 Alt 3: Bruke gtsummary()\nEksporterer til bl.a. følgende formater: Word, rtf, html, latex, markdown\nFordel: Kan lett integreres med andre funksjoner, først og fremst “grammar of tables” i pakket gt. Bruker samme rammeverk som for deskriptive tabeller med tbl_summary. Ulempe: Litt mer mikk-makk enn modelsummary og stargazer"
  },
  {
    "objectID": "grunnleggendeDesign.html#tre-nivåer-av-regresjonanalyse",
    "href": "grunnleggendeDesign.html#tre-nivåer-av-regresjonanalyse",
    "title": "9  Design og tolkning",
    "section": "9.1 Tre nivåer av regresjonanalyse",
    "text": "9.1 Tre nivåer av regresjonanalyse\nRichard Berk beskriver i sin lærebok tre nivåer av regresjonsanalyse basert på hvordan dataene ble til. Dette er et godt utgangspunkt som burde klargjøre betydelig, i hvert fall som et først skritt.\n\n9.1.1 Nivå I: Ikke tilfeldig utvalg fra en veldefinert populasjon\nGrunnlaget for statistisk tolkning (sannsynligheter, p-verdier og sånn) er at dataene er en tilfeldig realisering av en underliggende sann verdi. Typisk betyr dette bare at man har trukket et tilfeldig utvalg fra en populasjon. Da vil man få et godt mål på f.eks. gjennomsnittsverdi i populasjonen, men på grunn av tilfeldighet vil det være en feilmargin på denne målingen.\nDet avgjørende er altså at det finnes en veldefinert populasjon som det kan generaliseres til. Grunnen til å bruke begrepet veldefinert er at det må være rimelig spesifisert.\nHvis dataene ikke er fra en veldefinert populasjon kalles dette noen ganger for convenience sample. Altså, at man gjorde et uttrekk av beleilighetsgrunner, men uten at det var en veldefinert populasjon.\nEt eksempel kan være en arbeidsmiljøundersøkelse i en bestemt bedrift. Det skal litt til at disse resultatene skal gjelde utover denne bedriften. Man kan selvsagt argumentere for at erfaringene gjelder med generelt, men en slik slutning vil da hvile først og fremst på disse argumentene - ikke på statistiske utregninger.\nDet kan være veldig nyttig å analysere slike data, og det kan bringe innsikt og kunnskaper. Men med slike data gir det ikke mye mening å regne på statistisk usikkerhet. Hvis man ikke skal si noe utover de dataene man har (ikke generalisere), så er det heller ikke denne typen usikkerhet i målingene.\nSlike ikke-tilfeldige utvalg kan betraktes nærmest som case-studier. En dataanalyse vil gi oss kunnskaper om de erfaringene som gjøre akkurat der. Størrelsen på datasettet kan gi oss mer pålitelig informasjon om dette caset, men hjelper ikke for å generalisere utover caset.\n\n\n9.1.2 Nivå II: Tilfeldig utvalg fra en veldefinert populasjon\nTilfeldig utvalg er akkurat det det høres ut som, og er den foretrukne metoden for alle surveyundersøkelser. Teorien bak er at utvalget vil gjenspeile populasjonen, og avvik fra “de sanne verdiene” skyldes tilfeldigheter. Disse tilfeldighetene er grunnlaget for statistisk tolkning ved at vi kan si noe om samplingfordelingen (se annet kapittel) og dermed har grunnlag for å regne på standardfeil og p-verdier osv. Med andre ord: generalisering til populasjonen.\nSå er det viktig å påpeke at forutsetningen her er at det må være et utvalg fra en veldefinert populasjon. Hvis vi ikke vet hvem resultatene generaliserer til, så blir det jo tullete, og vi er egentlig på nivå 1.\n\n\n9.1.3 Nivå III: Estimering av kausale effekter\nFra et teknisk perspektiv er det ingenting som skiller studier av eksperimenter fra observasjonsstudier. De samme regresjonsmodellene kan estimeres og de samme utregningene av usikkerhet. Hva som bestemmer tolknigen (og hvorvidt modellspesifikasjonen er rimelig etc) avhenger av forskningsdesignet. Kort sagt kreves det et eksperiment. Hvis man har en treatment-gruppe og en kontrollgruppe, så vil \\(\\beta\\) beskrive forskjellen mellom disse gruppene som i andre typer data. Det som gir \\(\\beta\\) en kausal tolkning er om dataene tilfredsstiller kravene til et eksperiment.\nVi kan også regne inn kvasi-eksperimentelle studier eller naturlige eksperimenter her. Enten er disse studiene gode nok til å kvalifisere til å tolke som kausaleffekter - eller så er de det ikke, men da hører de hjemme på nivå II.\n\n\n9.1.4 Mot et nivå IV?\nI Berk sin fremstilling av de tre nivåene får man en følelse av at den vitenskapelige verdien øker ved hvert nivå. Mange vil da også mene akkurat det. Men logisk sett er det litt mer tvetydig enn som så.\nVi har snakket om to dimensjoner: kausalitet (ja/nei) og generalisering (ja/nei). Dette gir fire logisk mulige kombinasjoner.\n\n\n\nTable 9.1: Nivåer av regresjonsanalyse og hvor vanlige de er\n\n\n\n\n\n\n\n\nIkke tilfeldig utvalg fra veldefinert populasjon\nTilfeldig utvalg fra veldefinert populasjon\n\n\n\n\nDeskriptiv\nOverraskende mange\nDet aller meste\n\n\nKausal\nMye, men burde nok vært mer\nGanske sjelden\n\n\n\n\nJeg har ingen empiri for å si hvor vanlig hver enkelt type analyse er. Men jeg tror det nokså omtrentlige angivelsen i tabellen er ganske riktig, basert på egen erfaring fra studier jeg har lest og presentasjoner jeg har sett.\nI Berk sin fremstilling er Nivå III hele nederste rad, men da er det altså ikke gjort skille mellom om resultatene kan generaliseres videre eller ikke. Et slik skille bør man nok gjøre.\nEksperimenter omtales noen ganger - og i noen fagmiljøer - som gullstandarden. Men altså: ethvert eksperiment kan ikke være en gullstandard, ikke engang når formålet er å estimere kausaleffekter. Nivå IV er i så fall det vi ser etter, da nivå III har begrenset gyldighet. I tilsvarende ånd omtaler Berk eksperimenter som bronsestandarden, med den begrunnelse at det i praksis ikke er noe på palleplassene sølv og gull."
  },
  {
    "objectID": "grunnleggendeDesign.html#hva-er-poenget-her-egentlig",
    "href": "grunnleggendeDesign.html#hva-er-poenget-her-egentlig",
    "title": "9  Design og tolkning",
    "section": "9.2 Hva er poenget her, egentlig?",
    "text": "9.2 Hva er poenget her, egentlig?\nPoenget er at tolkning av resultatene handler vel så mye om hvordan dataene har blitt til som hvordan de er analysert. Hvis du har data på nivå I, så finnes det ingen statistiske krumspring du kan gjøre som løfter det til et annet nivå. Det samme gjelder nivå II og nivå III. Du kan fremdeles gjøre svært så nyttige og informative analyser på det nivået du har data på. De statistiske analyseteknikkene er det ellers ikke så stor forskjell på."
  },
  {
    "objectID": "statistiskTolkning.html#tilfeldigheter-og-systematikk",
    "href": "statistiskTolkning.html#tilfeldigheter-og-systematikk",
    "title": "10  Statistisk tolkning",
    "section": "10.1 Tilfeldigheter og systematikk",
    "text": "10.1 Tilfeldigheter og systematikk\nStandardfeilen er ikke det samme som standardavviket, og det er viktig at du vet forskjellen på disse.\n\nStandardavvik: beskriver variasjonen rundt gjennomsnittet i utvalget, altså i dataene du har. Det er litt omtrentlig sagt et mål på hvor langt fra gjennomsnittet datapunktene ligger.\n\nStandardfeilen: beskriver en hypotetisk fordeling av hvordan man kan regne med at mulige estimater kan være fordelt rundt den sanne verdien. Denne fordelingen kalles en samplingfordeling og krever litt mer forklaring - men standardfeilen er estimatet på standardavviket i samplingfordelingen.\n\nHvis du synes at denne forklaringen ikke hjalp, så er det med god grunn. Det er nemlig vanskelig å forstå. Det har en begrunnelse i sannsynlighetsteori som vi ikke skal gå veldig i dypbden på her. Men du trenger å forstå hva samplingfordeling er, og så gir sentralgrenseteoremet det vi trenger for å regne ut slike ting som p-verdier og konfidensintervall.\n\n10.1.1 Samplingfordeling og sentralgrenseteoremet\n\n10.1.1.1 Samplingfordeling\n\n\n10.1.1.2 Sentralgrenseteoremet\n\n\n\n10.1.2 Standardfeil\nStandardfeilen uttrykker usikkerheten ved estimatet. La oss si at du ønsker å si noe om gjennomsnittet i populasjonen, men har bare data om et tilfeldig utvalg fra denne populasjonen. Når du da regner ut gjennomsnittet i utvalget er det din beste gjetning på hva gjennomsnittet er i populasjonen. En slik gjetning kaller vi et estimat. Standardfeilen til estimatet er et mål på usikkerheten ved målemetoden. Usikker målemetode gjør at feilen kan være større.\n\n\n10.1.3 Er man “95% sikker”?\nDet sies ofte at feilmarginen uttrykker hvor sikker man er. Det er jo ikke helt riktig - eller det er riktig under noen spesielle forutsetninger om hva man mener med “sikker”. La oss derfor ta dette med en gang og starter med konfidensintervallet.\nEt 95% konfidensintervall er vårt anslag på hvor god vår målemetode er. Vi har jo regnet ut f.eks. et gjennomsnitt og det er jo greit nok. Usikkerheten kommer fra utvalgsprosedyren og variasjonen i data.\nVi vet ikke hvorvidt vårt estimat ligger nærme eller langt unna den sanne verdien. Det vi derimot vet noe om er påliteligheten i den metoden vi har brukt. Det viktigste her er altså tilfeldig utvalg, og hvis utvalget ikke er tilnærmet tilfeldig trukket, så bryter det hele sammen.\nNår man sier at konfidensintervallet uttrykker at man er “95% sikker” på at den sanne verdien ligger i det intervallet mener man da følgende: Man har brukt en metode (dvs utvalg og utregninger og det hele) som har en feilmargin. Denne feilmarginen er slik at hvis man gjorde estimeringen (altså nytt utvalg hver gang) på samme måte svært mange ganger (f.eks. uendelig mange ganger), så ville 95% av resultatene ligget innenfor et slikt intervall."
  },
  {
    "objectID": "statistiskTolkning.html#konfidensintervaller",
    "href": "statistiskTolkning.html#konfidensintervaller",
    "title": "10  Statistisk tolkning",
    "section": "10.2 Konfidensintervaller",
    "text": "10.2 Konfidensintervaller"
  },
  {
    "objectID": "statistiskTolkning.html#t-test-og-p-verdier",
    "href": "statistiskTolkning.html#t-test-og-p-verdier",
    "title": "10  Statistisk tolkning",
    "section": "10.3 T-test og p-verdier",
    "text": "10.3 T-test og p-verdier\nT-testen er i prinsippet en sammenligning mellom estimatets størrelse og standardfeilen til estimatet.\n\\[\n\\frac{\\mu}{SE(\\mu)} = t\n\\]\nEller sagt på en annen måte: \\[\n\\frac{estimat}{standardfeil} = t\n\\]\nDet betyr at \\(t\\) uttrykker forholdstallet mellom estimatet og standardfeilen. Intuitivt kan man vel forstå at hvis usikkerheten bør være mindre enn estimatet. Men hvor mye mindre?\nFra samplingfordelingen og sentralgrenesteoremet ved vi jo at \\(1.96 \\times SE(\\mu)\\)\nTolkningen av p-verdien er i hvilken grad det er sannsynlig å få det observerte resultatet ved en tilfeldighet hvis NULL-hypotesen er riktig. Dette høres ganske pussig ut. Tanken er at man nesten alltid vil observere noe forskjell fra null, og det kan skje ved en tilfeldighet. Hvis null-hypotesen er riktig er det mindre sannsynlig at vi observerer en veldig stor forskjell. Men hvor stor forskjell er det, egentlig? Løsningen er å se avstanden fra null i lys av standardfeilen. Hvis man bruker en usikker målemetode, så er det mer sannsynlig å observere en stor forskjell ved tilfeldigheter enn om man bruker en veldig nøyaktig målemetode.\nI praksis: Tenk at du observerer en stor forskjell mellom to grupper. Med “stor” mener vi f.eks. at forskjellen er over dobbelt så stor som standardfeilen. Da får vi en p-verdi som er \\(p < 0.05\\). Da kan vi si at hvis nullhypotesen er sann, så er det lite sannsynlig at vi ville fått et slikt resultat på grunn av tilfeldigheter.^(Hvis vi ønsker være pinlig korrekte kan vi også si noe slikt som at hvis man gjorde målingen tusenvis av ganger, så ville 5% av resultatene ligge så langt unna null (eller lengre).)\nSå er logikken videre at vi som hovedregel ikke tror på resultater som er usannsynlige. Så i stedet for å holde fast på nullhypotesen velger vi i stedet å tro på den alternative hypotesen."
  },
  {
    "objectID": "statistiskTolkning.html#statistiske-tester-generelt",
    "href": "statistiskTolkning.html#statistiske-tester-generelt",
    "title": "10  Statistisk tolkning",
    "section": "10.4 Statistiske tester generelt",
    "text": "10.4 Statistiske tester generelt\nDet finnes en hel haug av statistiske tester. Prinsippet er gjerne variasjoner av t-testen og har disse komponentene:\n\nen nullhypotese og et alternativ\nen statistikk, altså et måltall som er et avstandsmål mellom observert resultat og hva man forventer under nullhypotesen\nen statistisk modell for samplingfordelingen som sier noe om fordelingen av tilfeldige feil\nen uttalt beslutningsregel for konklusjonen. Et vanlig mål er at hvis p < 0.05, så forkastes nullhypotesen."
  },
  {
    "objectID": "tidyverse.html#lage-ny-variabel-mutate",
    "href": "tidyverse.html#lage-ny-variabel-mutate",
    "title": "12  Datahåndtering med Tidyverse",
    "section": "12.1 Lage ny variabel: mutate",
    "text": "12.1 Lage ny variabel: mutate\nAlle verbene i tidyverse starter med å angi hvilket objekt man skal gjøre noe med, altså datasettet.\nHer er et eksempel der man lager en ny variable som summen av eksisterende variablene x og z.\n\nnyttobjekt <- mutate(dinedata, nyvariabel = x + z)\n\nHer er et eksempel der man lager to variable samtidig der den andre er x delt på z.\n\nnyttobjekt <- mutate(dinedata, nyvariabel = x / z,\n                     nyvariabel2 = x + z)"
  },
  {
    "objectID": "tidyverse.html#rørlegging-hva-i-alle-dager-betyr",
    "href": "tidyverse.html#rørlegging-hva-i-alle-dager-betyr",
    "title": "12  Datahåndtering med Tidyverse",
    "section": "12.2 Rørlegging: Hva i alle dager betyr %>% ??",
    "text": "12.2 Rørlegging: Hva i alle dager betyr %>% ??\nSymbolet %>% kalles in “pipe” eller på norsk: rørlegging. Det betyr at det som står til venstre flyttes over til høyre. Eller sagt på en annen måte betyr det: “Gjør deretter følgende”. Vi vil bruke denne syntaxen konsekvent fra nå når vi introduserer de ulike “verbene”.\n\nnyttobjekt <- dinedata %>% \n  mutate(nyvariabel = x / z,\n         nyvariabel2 = x + z)\n\nDenne koden sier følgende, linje for linje:\n\nlag en kopi av dinedata og lagre det i nyttobjekt ^deretter gjør du følgende:^\nlag de nye variablene nyvariabel som får verdier fra variablene x delt på y\nog nyvariabel2som summen av x og z"
  },
  {
    "objectID": "tidyverse.html#beholde-og-slette-variable-select",
    "href": "tidyverse.html#beholde-og-slette-variable-select",
    "title": "12  Datahåndtering med Tidyverse",
    "section": "12.3 Beholde og slette variable: select",
    "text": "12.3 Beholde og slette variable: select"
  },
  {
    "objectID": "tidyverse.html#aggregere-summarise",
    "href": "tidyverse.html#aggregere-summarise",
    "title": "12  Datahåndtering med Tidyverse",
    "section": "12.4 Aggregere: summarise",
    "text": "12.4 Aggregere: summarise"
  },
  {
    "objectID": "tidyverse.html#grupperte-utregninger-group_by",
    "href": "tidyverse.html#grupperte-utregninger-group_by",
    "title": "12  Datahåndtering med Tidyverse",
    "section": "12.5 Grupperte utregninger: group_by",
    "text": "12.5 Grupperte utregninger: group_by"
  },
  {
    "objectID": "tidyverse.html#sette-det-hele-sammen",
    "href": "tidyverse.html#sette-det-hele-sammen",
    "title": "12  Datahåndtering med Tidyverse",
    "section": "12.6 Sette det hele sammen",
    "text": "12.6 Sette det hele sammen"
  },
  {
    "objectID": "omkode_factor.html#endre-variabelnavn-med-rename-og-mutate",
    "href": "omkode_factor.html#endre-variabelnavn-med-rename-og-mutate",
    "title": "13  Omkoding av variable",
    "section": "13.1 Endre variabelnavn med rename og mutate",
    "text": "13.1 Endre variabelnavn med rename og mutate"
  },
  {
    "objectID": "omkode_factor.html#kontinuerlige-variable",
    "href": "omkode_factor.html#kontinuerlige-variable",
    "title": "13  Omkoding av variable",
    "section": "13.2 Kontinuerlige variable",
    "text": "13.2 Kontinuerlige variable\nÅ omkode kontinuerlige variable er i utgangspunktet det enkleste. Dette er tall og man kan gjøre normale regneoperasjoner på dem."
  },
  {
    "objectID": "omkode_factor.html#tekstvariable-strings",
    "href": "omkode_factor.html#tekstvariable-strings",
    "title": "13  Omkoding av variable",
    "section": "13.3 Tekstvariable (strings)",
    "text": "13.3 Tekstvariable (strings)"
  },
  {
    "objectID": "omkode_factor.html#factorvariable",
    "href": "omkode_factor.html#factorvariable",
    "title": "13  Omkoding av variable",
    "section": "13.4 Factorvariable",
    "text": "13.4 Factorvariable\nR har en egen variabeltype for kategoriske variable som kalles “factor”. I utgangspunktet er kategoriske variable mer å regne som tekstvariable enn som tall, men i en del beregninger vil softwaren bruke numeriske verdier uansett. Hvis man gjør om en tekst-variabel til en factor-variabel beholdes teksten, men kategoriene numeriske verdier 1, 2, 3, … osv. Disse tallene kan du tenke på som rekkefølgen på kategoriene. For kategoriske variable er det jo ikke noen egentlig rekkefølge, men det kan være grunner til å foretrekke rekkfølgen av andre grunner som vi kommer tilbake til.\nHvis variabelen er ordnet f.eks. på en skala fra 1 til 5 eller annen naturlig rekkefølge1, så kan man også angi dette.\n\n13.4.1 Få oversikt over factor-levels med levels()\n\n\n13.4.2 Enkel omkoding med fct_recode() og fct_collapse()\n\n\n13.4.3 Endre rekkefølgen på faktorene med fct_reorder()"
  },
  {
    "objectID": "omkode_factor.html#betinget-omkoding-med-ifelse-og-case_when",
    "href": "omkode_factor.html#betinget-omkoding-med-ifelse-og-case_when",
    "title": "13  Omkoding av variable",
    "section": "13.5 Betinget omkoding med ifelse() og case_when()",
    "text": "13.5 Betinget omkoding med ifelse() og case_when()\nDu kan lære mer om effektiv håndtering av kategoriske variable med forcats-pakken, som er en del av “tidyverse”."
  },
  {
    "objectID": "omkode_factor.html#factorvariable-med-skikkelig-lang-tekst",
    "href": "omkode_factor.html#factorvariable-med-skikkelig-lang-tekst",
    "title": "13  Omkoding av variable",
    "section": "13.6 Factorvariable med skikkelig lang tekst",
    "text": "13.6 Factorvariable med skikkelig lang tekst\n\nnorlag <- read_stata(\"data/norlag_panel2022.dta\") %>% \n    mutate(across( where(is.labelled) ,  ~replace(., \n                                        . %in% c(997, 998, 999, 99999, 999999), \n                                        NA))) %>%\n  # For hele datasettet fjernes ikke-brukte labler \n  drop_unused_value_labels() %>% \n  # Så gjør alle variable om til mer ordinære R-format. Dvs. gjøre labler om til factor\n  unlabelled()\n\nNoen ganger har man et datasett som allerede er omgjort med factor-variable. Eller du har en eller annen grunn til å ikke gå tilbake til et tidligere steg for å omkode. Men du har factor-levels med skikkelig lang tekst kan det være noe drit å kode om. Kan man gjøre dette på en lurere måte? Minst mulig tårer? Ja, selvsagt.\nI NorLAG er variabelen wr117zz svar på et spørsmål om “Mulighet for å redusert arbeidstid (deltid)”. Når denne variabelen er gjort om til factor kan man se hvilke verdier variabelen har med bruke av funksjonen levels() slik:\n\nlevels(norlag$wr117zz)\n\n[1] \"Nei\"                                                               \n[2] \"Ja\"                                                                \n[3] \"filter: jobber deltid\"                                             \n[4] \"filter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet)\"\n[5] \"filter: ikke i arbeid\"                                             \n\ntable(norlag$wr117zz)\n\n\n                                                               Nei \n                                                              1360 \n                                                                Ja \n                                                              4146 \n                                             filter: jobber deltid \n                                                              1964 \nfilter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet) \n                                                              1171 \n                                             filter: ikke i arbeid \n                                                              6238 \n\n\nLa oss si at vi vil kode om slik at vi får en variabel som bare er om vedkommende har mulighet til å jobbe deltid eller ikke. De som allerede jobber deltid har jo åpenbart mulighet til det, så de skal kodes om til “Ja”. De andre kategoriene er egentlig grunner til at det mangler data, så de skal settes til NA. En mulighet er da å omkode som følger:\n\nnorlag_omkodet <- norlag %>%\n  mutate(redarbtid = replace(wr117zz, wr117zz == \"filter: jobber deltid\", \"Ja\"), \n         redarbtid = replace(redarbtid, redarbtid == \"filter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet)\", NA), \n         redarbtid = replace(redarbtid, redarbtid == \"filter: ikke i arbeid\", NA), \n         redarbtid = replace(redarbtid, redarbtid == \"vil ikke svare\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"vet ikke\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"mangler data\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"Deltok ikke i runden\", NA)) %>% \n  droplevels()\n\nDette funker, men blir ganske mye tekst å skrive, og da kan man også lett gjøre skrivefeil. Husk at faktornivåene må angis helt nøyaktig slik de er skrevet! Merk at den siste funksjone, droplevels(), bare fjerner faktor-levels som ikke er i bruk.\nI output for faktor-levels angir klammeparentesen gir rekkefølgen på disse verdiene. Vi kan bruke denne informasjonen direkte i omkodingen for å unngå å skrive så veldig mye. Når man bruker levels() får man en liten vektor med verdier, og disse kan man altså henvise til med rekkefølgen. Her er et eksempel for bare å bytte ut de som jobber deltid til “Ja”:\n\nnorlag_omkodet <- norlag %>%\n  mutate(redarbtid = replace(wr117zz, wr117zz == levels(wr117zz)[3], \"Ja\")) %>% \n  droplevels()\n\nTrikset her er altså å bruke levels() og vise til hvilket nummer i rekkefølgen. Da unngår vi også faren for skrivefeil.\nVi vil også kode om alle de andre verdiene, nummer 4-9 til NA. Det kan vi gjøre på samme måte, men vi behøver ikke skrive en ny linje for hver verdi. Den logiske operatoren == kan man bruke når man skal sjekke om to verdier er like. Hvis vi skal se om en verdi er lik en av flere mulige kan vi bruke %in% og så en liste med verdier. levels() gir en liste med verdier, så da kan vi angi den direkte og alle verdiene 4 til 9 ved å skrive 4:9. Samlet blir det da slik:\n\nnorlag_omkodet <- norlag %>%\n  mutate(redarbtid = replace(wr117zz, wr117zz == levels(wr117zz)[3], \"Ja\"), \n         redarbtid = replace(redarbtid, redarbtid %in% levels(wr117zz)[4:9], NA)) %>% \n  droplevels()\n\nmemisc::codebook(norlag_omkodet$redarbtid)\n\n================================================================================\n\n   norlag_omkodet$redarbtid\n\n--------------------------------------------------------------------------------\n\n   Storage mode: integer\n   Factor with 2 levels\n\n   Levels and labels     N Valid Total\n                                      \n    1 'Nei'           1360  18.2   4.1\n    2 'Ja'            6110  81.8  18.5\n   NA                25614        77.4"
  },
  {
    "objectID": "omkode_factor.html#spesielle-problemstillinger-ved-veldig-mange-kategorier",
    "href": "omkode_factor.html#spesielle-problemstillinger-ved-veldig-mange-kategorier",
    "title": "13  Omkoding av variable",
    "section": "13.7 Spesielle problemstillinger ved veldig mange kategorier",
    "text": "13.7 Spesielle problemstillinger ved veldig mange kategorier\nFor disse eksemplene skal vi bruke et litt annet datasett, nemlig et lite uttrekk fra European Social Survey. Her er det 3 variable: yrkeskode, kjønn og politisk interesse.\n\npolit <- read.csv2(\"data/politics.csv\", colClasses = \"character\")\n\nglimpse(polit)\n\nRows: 49,519\nColumns: 3\n$ isco08  <chr> \"3333\", \"7122\", \"4221\", \"4311\", \"6130\", \"7212\", \"5131\", \"5223\"…\n$ gndr    <chr> \"1\", \"1\", \"2\", \"1\", \"2\", \"1\", \"1\", \"2\", \"1\", \"2\", \"1\", \"2\", \"1…\n$ polintr <chr> \"3\", \"2\", \"4\", \"3\", \"2\", \"2\", \"4\", \"3\", \"3\", \"4\", \"2\", \"2\", \"1…\n\n\nVi kan sjekke hvor mange kategorier det er ved å lage en tabell over kodene og se hvor mange det er. Det er imidlertid upraktisk da den tabellen tar veldig mye plass. Koden nedenfor gjør en enklere opptelling ved å trekke ut unike verdier og telle hvor mange det er:\n\nantall_koder <- polit %>%  \n  pull(isco08) %>%   # trekker ut en vektor med kun en variabel \n  unique() %>%       # beholder kun unike verdier \n  length()           # lengden på gjenværende vektor \n\nantall_koder\n\n[1] 561\n\n\nDet er altså 561 unike yrkeskoder i datasettet.\n\n13.7.1 Hierarkisk strukturerte tall som tekststrenger\nNoen ganger er det hundrevis av verdier. Et slik eksempel er yrkesklassifisering der hver type yrke har en spesifikk kode. Det finnes mange typer yrker, så det er omlag 800 koder. For de fleste typer analyser er dette altfor detaljert og du trenger å gruppere til færre kategorier. SSB har en kodeliste offentlig tilgjengelig. Kort fortalt er det en kode med 4 siffer, der det første sifferet er en grov gruppering, og de etterfølgende sifrene innebærer en økt detaljeringsgrad innenfor grupperingen angitt ved første siffer.\nHvis du skulle omkodet yrker slik som forklart i et tidligere avsnitt om omkoding ville det tatt veldig lang tid, men det ville også være veldig lett å gjøre feil. Det vil rett og slett være et mareritt å de-bugge koden for å finne feil eller kvalitetssjekke. Altså: en slik tilnærming er helt uaktuelt. En langt bedre tilnærming er å bare trekke ut det første sifferet fra koden. Funksjonen str_sub() gjør akkurat slike ting ved å angi hvilken del av tekststrengen du vil trekke ut, angitt ved posisjonen du starter ved og slutter ved. Her er det altså første posisjon.\n\npolit <- polit %>% \n  mutate(occupation = str_sub(isco08, start = 1, end = 1)) \n\npolit %>% \n  select(gndr, occupation) %>% \n  tbl_summary(by = gndr)\n\nRegistered S3 method overwritten by 'sass':\n  method    from  \n  print.css memisc\n\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1, N = 23,0201\n      2, N = 26,4991\n    \n  \n  \n    occupation\n\n\n        \n1,847 (8.0%)\n2,947 (11%)\n        0\n5 (<0.1%)\n1 (<0.1%)\n        1\n2,185 (9.5%)\n1,350 (5.1%)\n        2\n3,665 (16%)\n5,018 (19%)\n        3\n2,736 (12%)\n3,250 (12%)\n        4\n1,071 (4.7%)\n2,862 (11%)\n        5\n2,418 (11%)\n5,569 (21%)\n        6\n704 (3.1%)\n445 (1.7%)\n        7\n4,162 (18%)\n1,158 (4.4%)\n        8\n2,495 (11%)\n966 (3.6%)\n        9\n1,732 (7.5%)\n2,933 (11%)\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\n\n\n13.7.2 Bruke kataloger for kodeverk\nSometimes, such long list of unique codes have a standard grouping that are not hierarchical. One such example is the ordc class schema as developed by the HISTCLASS-project homepage. This is a coding schema for isco-codes to classes, and a catalogue is available from the homepage. As there are about 800 unique values and they are stored in Excel-format with corresponding grouping for each code. The first lines in Excel-file looks lik this:\n\nThis file can be read into R using read_excel(), where the first line is typically read as variable names. But the first lines are not to be used, and neither are several columns.\nTo read it into R, we need to skip the lines not needed and change the variable names. In this example, we only need the isco-kodes and the ordc_yrk codes. Variable names should not include spaces, so we include an argument for ensuring universal valid variable names. That substitutes white space with punctuation. We also specify col_types = \"text\" to avoid the values being interpreted as numeric.\n\nisco <- readxl::read_excel(path = \"data/3_codes_isco88_ordc.xlsx\", skip = 4, .name_repair = \"universal\", col_types = \"text\") %>% \n  select(2,9) \nhead(isco)\n\n# A tibble: 6 × 2\n  ISCO.88.code ORDC_YRK\n  <chr>        <chr>   \n1 1237         1       \n2 2141         1       \n3 2310         1       \n4 2351         1       \n5 2442         1       \n6 2443         1       \n\n\nNow, we can merge the data with this catalogue. So that every record in the catalogue is merged to each record with the same code. To do this, we use left_join(), and store in a new object.\n\nisco <- isco %>% \n  rename(isco08 = ISCO.88.code)\n\npolit2 <- left_join(polit, isco, by = \"isco08\")\n\nhead(polit2)\n\n  isco08 gndr polintr occupation ORDC_YRK\n1   3333    1       3          3     <NA>\n2   7122    1       2          7       10\n3   7122    1       2          7       10\n4   4221    2       4          4        8\n5   4311    1       3          4     <NA>\n6   6130    2       2          6       12\n\n\nWhat happened here is that the recoding happened almost automatically by adding a new column with the new variable.\nNow, you can make e.g. a cross-tabulation of social class by gender.\n\npolit2 %>% \n  select(ORDC_YRK, gndr) %>% \n  tbl_summary(by = gndr)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      1, N = 29,2851\n      2, N = 33,9501\n    \n  \n  \n    ORDC_YRK\n\n\n        1\n448 (2.4%)\n364 (2.0%)\n        10\n5,887 (32%)\n3,222 (17%)\n        11\n3,757 (20%)\n5,563 (30%)\n        12\n1,222 (6.6%)\n1,187 (6.4%)\n        2\n1,367 (7.4%)\n1,333 (7.1%)\n        3\n30 (0.2%)\n13 (<0.1%)\n        4\n561 (3.0%)\n1,251 (6.7%)\n        5\n2,000 (11%)\n2,669 (14%)\n        6\n1,681 (9.1%)\n1,850 (9.9%)\n        7\n180 (1.0%)\n267 (1.4%)\n        8\n1,129 (6.1%)\n726 (3.9%)\n        9\n134 (0.7%)\n105 (0.6%)\n        996\n84 (0.5%)\n109 (0.6%)\n        997\n5 (<0.1%)\n1 (<0.1%)\n        Unknown\n10,800\n15,290\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "omkode_factor.html#gjøre-samme-ting-med-mange-variable-med-across",
    "href": "omkode_factor.html#gjøre-samme-ting-med-mange-variable-med-across",
    "title": "13  Omkoding av variable",
    "section": "13.8 Gjøre samme ting med mange variable med across()",
    "text": "13.8 Gjøre samme ting med mange variable med across()"
  },
  {
    "objectID": "import_metadata.html#hvordan-fungerer-koden-ovenfor-en-intro-til-mer-avansert-databehandling",
    "href": "import_metadata.html#hvordan-fungerer-koden-ovenfor-en-intro-til-mer-avansert-databehandling",
    "title": "Appendix A — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "A.1 Hvordan fungerer koden ovenfor?? En intro til mer avansert databehandling",
    "text": "A.1 Hvordan fungerer koden ovenfor?? En intro til mer avansert databehandling\n\nA.1.1 Sjekk datastruktur og bruk av filter\n\n\nA.1.2 Omkode bruker-spesifiserte missing-verdier til NA\n\n\nA.1.3 Kode om på tvers av mange variable med across\n\n\nA.1.4 Fjerne nivåer som ikke brukes: drop_unused_value_labels\n\n\nA.1.5 Gjør om til factor med unlabelled"
  },
  {
    "objectID": "import_metadata.html#for-spesielt-interesserte-jobbe-med-labelled-data",
    "href": "import_metadata.html#for-spesielt-interesserte-jobbe-med-labelled-data",
    "title": "Appendix A — Import av data fra Sikt - håndtering av formater med metadata",
    "section": "A.2 For spesielt interesserte: jobbe med labelled-data",
    "text": "A.2 For spesielt interesserte: jobbe med labelled-data"
  }
]